
\bx{TODO: extend the related work}
{\bf A - Knowledge Graph Search.} Many efforts have been made for searching and browsing large knowledge graphs. 
Wang et al. ~\cite{Wang2015QUT} proposed a Bayesian probability model combined with random walks to find the most similar concepts for a given query entity.
Wu et al. ~\cite{YinghuiWu} discovered that the background knowledge graph can be described by many small-sized patterns. 
They developed an effective mining algorithm to summarize the large knowledge graph according to small-sized patterns.
Yang et al. ~\cite{Yang2014vldb} found that due to the lack of insight about the background knowledge graph, it is often hard for a user to precisely formulate a query. They developed a user-friendly knowledge graph search engine to support query formation and transformation. 
Jayaram et al. ~\cite{GQBE} proposed a knowledge graph query system called {\em GQBE}. Different from other graph query systems, {\em GQBE} focuses on entity tuple query which consists of a list of entity tuples.
Zhang et al. ~\cite{tongtao2018Gaia} developed a comprehensive multi-modality knowledge extraction and hypothesis generation system which supports three types of queries, including (1) class-based queries %which aim to find all instances of a known class in the knowledge graph; (e.g. find all "politician") 
(2) zero-hop queries %which aim to find all instances of an entity; (e.g. find all entities with name "Barack Obama") 
and (3) graph-queries. % which aim to find a graph. 

\noindent {\bf B - Fact Checking on Knowledge Graph. } In 2015, GL Ciampaglia et al. \cite{ciampaglia2015computational} show that the complexities of human fact checking can be approximated quite well by finding the shortest path between concept nodes under properly defined semantic proximity metrics on knowledge graphs. The authors evaluate tens of thousands of claims on knowledge graphs extracted from Wikipedia. Many research works follow this direction with different techniques. Baoxu et al. \cite{shi2016discriminative} model the fact checking problem as a link-prediction task in a knowledge graph, and present a discriminative path-based method for fact checking in knowledge graphs. Shiralkar et al. \cite{shiralkar2017finding} adopts k-shortest paths approach to construct a knowledge stream (KS) between two entities as the background knowledge for fact checking. Lin et al. \cite{lin2018fact} introduce ontological patterns in fact checking for semantic and topological constraints. These constraints are represented as subgraph patterns which are used for query in the knowledge graph. In order to obtain the ground truth of contextualized claim, Tchechmedjiev et al. release a large, up-to-date and queryable corpus of structured information about claims and related metadata for fact checking research, named ClaimsKG \cite{tchechmedjiev2019claimskg}. 


\noindent {\bf C - Knowledge Graph Reasoning.} Generally speaking, there are two types of knowledge graph reasoning methods, including (1) embedding based approaches and (2) multi-hop approaches. For the former, 
the main idea is to learn a low dimensional vector for each entity and predicate in the embedding space, and use these embedding vectors as the input of the reasoning tasks (e.g.,~\cite{transE}, ~\cite{rotatE}, ~\cite{entity-predicate}, ~\cite{pprop}).
For the latter, %\hh{1-2 sentenses on its key ideas and cite William cohen's random walk based method. William Wang's meta-reasoning method, etc.}
the main idea is to learn missing rules from a set of relational paths sampled from the knowledge graph (e.g.,~\cite{williamCohen}, ~\cite{willianWang}, ~\cite{das-etal-2017-chains}). Many effective reasoning methods have been developed for predicting the missing relation (i.e., link prediction) or the missing entity (i.e., entity prediction). 
In link prediction, given the `subject' and the `object' of {\em a triple}, it predicts the existence and/or the type of relation. 
For example,
{\em TransE}~\cite{transE} learns the low dimensional embedding of both entities and predicates in the knowledge graph; %. The relationship between two entities can be predicated by the translation between the embeddings of entities.
{\em TransR}~\cite{Lin2015TransR} learns the embedding of entities and predicates in two separate spaces. 
The learned embedding (either by {\em TransE} or {\em TransR}) can be used for both link predication and entity predication. 
%In ~\cite{SimplE}, \lliu{xxxxxxxxxx}. 
In entity prediction, given the `subject' and the `predicate' of {\em a triple}, it predicts the missing `object'. For example, 
%\hh{a few representative work, 1-2 sentences for each of them} 
{\em GQEs}~\cite{entity-predicate} embeds the graph nodes in a low dimensional space, and treats the logical operators as learned geometric operations.


In recent years, knowledge graph reasoning has demonstrated strong potential for computational fact checking. Given {\em a claim} in the form of a triple of the knowledge graph, it reasons whether the claim is authentic or falsified. For example, 
in ~\cite{Shiralkar2017}, the authors focused on checking the truthfulness of a given triple/claim, by first transforming the knowledge graph into a weighted directed graph, and then extracting a so-called knowledge stream based on maximum flow algorithm. %First, they transformed the knowledge graph into a line graph to model the co-occurrence of different predicates, and they used a TF-IDF method to calculate the similarity between different predicates. Then, they transferred the knowledge graph into a directed weighted graph and used a minimum cost maximum flow algorithm to find the knowledge stream between the give subject and object. If the truth score of the knowledge stream is too low, they thought that the query is false.
It is worth mentioning that the extracted knowledge stream can be viewed as an edge-specific knowledge segment in \gchecker. 
In ~\cite{Shi2016dpp}, an alternative method was developed to detect fake claims by learning the discriminative paths of specific predicates. Different from \cite{Shiralkar2017}, this is a supervised reasoning method since 
it requires different training datasets for different predicates. 
If the predicate in the claim does not exist in the training data, which is likely to be the case for detecting falsified claims in emerging news, the algorithm becomes inapplicable.
 As mentioned before, these methods belong to point-wise reasoning. Therefore, %Thus, although being effective in detecting a single falsified claim, 
 they might fall short in detecting the semantic inconsistency between multiple claims which can be solved by knowledge graph comparative reasoning.

%However, all the above methods focus on fact checking for a single claim, link predication or entity predication , and thus is incapable of detecting the semantic inconsistencies between different claims.


\hide{

\begin{table*}[]
	\centering
	\caption{Summary of Existing KG Search and Comparative Reasoning Systems}
	\vspace{-0.5\baselineskip}
	\resizebox{\textwidth}{!}{
	\begin{tabular}{|c|c|c|c|}
		\hline
		Name & Input                                              & Output         &       KG Systems    \\ \hline
		\tt{F1} & A single query node                                & Top-{\em k} Entities  & ~\cite{Tong2006rdwalk} ~\cite{Lin2015TransR} ~\cite{Mikolov2013DRW} \\ \hline
		\tt{F1'} & A single query node                             & A subgraph with most relevant entities and edges w.r.t the query node & None \\ \hline
		\tt{F2} & A Single query edge                                & Knowledge segment & ~\cite{Shiralkar2017} ~\cite{Shi2016dpp} ~\cite{lei2018} \\ \hline
		\tt{F3} & Two or more query edges                        & commonality and inconsistency & None \\ \hline
		\tt{F4} & A query graph                               & A matching subgraph  & ~\cite{Su2015KDD} ~\cite{lei2018} ~\cite{Zou2011GAS} ~\cite{Yahya2016RQE} \\ \hline
		\tt{F4'} & A query graph                               & A semantic matching subgraph/Knowledge Segment  & None \\ \hline
		%~\cite{Faloutsos2004} ~\cite{Tong2006CSP} ~\cite{Su2015KDD} ~\cite{Tong2007FBP} ~\cite{lei2018} \\ \hline
		%multiple query nodes                               & \thead{Connection Pathways \\ for Marked Nodes} & ~\cite{Koren2006MEP} ~\cite{Tong2006CSP}  \\ \hline
		\tt{F5} & Multiple query nodes               & Grouping and connection pathways & None \\ \hline
		\tt{F6} & A single node/edge and multiple KG               & Commonality and differences in different KGs & None \\ \hline
		\end{tabular}
	}
\label{table:existing:kgsys}
\vspace{-0.8\baselineskip}
\end{table*}
}


%\hh{have u checked this tutorial? \url{https://sites.cs.ucsb.edu/~william/papers/Part3_KB_Reasoning.pdf}? seems that we have already consider these tasks, link prediction, entitiy prediction, fact checking. just make sure we do not miss important aspect of kg reason from existing work}
%\lliu{Hi professor, I have checked this tutorial before. I will add more work about kg reason here.}
%\hh{check this paper~\cite{Leman2013SIAM} -- some components of their system might be related to KG search and reasoning}

%In ~\cite{qi2018ICDE}, the authors proposed a graph summarization framework to facilitate knowledge graph search. They first summarize the knowledge graph into a concreate graph according to some frequent graph pattern, then they find the (approximate) answers according to the query. 
%\hh{a little bit more details, e.g., what is the main functions (in input/output format)?}
%In ~\cite{Su2015KDD}, they used the feedback information to enhance the knowledge graph query performance.
%In ~\cite{slq2014vldb}, they proposed a system SLQ.
