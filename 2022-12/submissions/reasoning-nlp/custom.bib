@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI Blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{garbacea2022constrained,
  title={Why is constrained neural language generation particularly challenging?},
  author={Garbacea, Cristina and Mei, Qiaozhu},
  journal={arXiv preprint arXiv:2206.05395},
  year={2022}
}

@article{yang2021survey,
  title={A survey of knowledge enhanced pre-trained models},
  author={Yang, Jian and Xiao, Gang and Shen, Yulong and Jiang, Wei and Hu, Xinyu and Zhang, Ying and Peng, Jinghui},
  journal={arXiv preprint arXiv:2110.00269},
  year={2021}
}

@inproceedings{cao-etal-2020-unsupervised-dual,
    title = "Unsupervised Dual Paraphrasing for Two-stage Semantic Parsing",
    author = "Cao, Ruisheng  and
      Zhu, Su  and
      Yang, Chenyu  and
      Liu, Chen  and
      Ma, Rao  and
      Zhao, Yanbin  and
      Chen, Lu  and
      Yu, Kai",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.608",
    doi = "10.18653/v1/2020.acl-main.608",
    pages = "6806--6817",
}
@inproceedings{sun-etal-2018-logician,
    title = "Logician and Orator: Learning from the Duality between Language and Knowledge in Open Domain",
    author = "Sun, Mingming  and
      Li, Xu  and
      Li, Ping",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1236",
    doi = "10.18653/v1/D18-1236",
    pages = "2119--2130",
}

@inproceedings{Davis1977MetaLevelKO,
  title={Meta-Level Knowledge: Overview and Applications},
  author={Randall Davis and Bruce G. Buchanan},
  booktitle={IJCAI},
  year={1977}
}

@article{yu2022survey,
  title={A survey of knowledge-enhanced text generation},
  author={Yu, Wenhao and Zhu, Chenguang and Li, Zaitang and Hu, Zhiting and Wang, Qingyun and Ji, Heng and Jiang, Meng},
  journal={ACM Computing Surveys (CSUR)},
  year={2022},
  publisher={ACM New York, NY}
}

@inproceedings{liu-etal-2022-multi,
    title = "Multi-Stage Prompting for Knowledgeable Dialogue Generation",
    author = "Liu, Zihan  and
      Patwary, Mostofa  and
      Prenger, Ryan  and
      Prabhumoye, Shrimai  and
      Ping, Wei  and
      Shoeybi, Mohammad  and
      Catanzaro, Bryan",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.104",
    doi = "10.18653/v1/2022.findings-acl.104",
    pages = "1317--1337",
    abstract = "Existing knowledge-grounded dialogue systems typically use finetuned versions of a pretrained language model (LM) and large-scale knowledge bases. These models typically fail to generalize on topics outside of the knowledge base, and require maintaining separate potentially large checkpoints each time finetuning is needed. In this paper, we aim to address these limitations by leveraging the inherent knowledge stored in the pretrained LM as well as its powerful generation ability. We propose a multi-stage prompting approach to generate knowledgeable responses from a single pretrained LM. We first prompt the LM to generate knowledge based on the dialogue context. Then, we further prompt it to generate responses based on the dialogue context and the previously generated knowledge. Results show that our knowledge generator outperforms the state-of-the-art retrieval-based model by 5.8{\%} when combining knowledge relevance and correctness. In addition, our multi-stage prompting outperforms the finetuning-based dialogue model in terms of response knowledgeability and engagement by up to 10{\%} and 5{\%}, respectively. Furthermore, we scale our model up to 530 billion parameters and demonstrate that larger LMs improve the generation correctness score by up to 10{\%}, and response relevance, knowledgeability and engagement by up to 10{\%}. Our code is available at: https://github.com/NVIDIA/Megatron-LM.",
}


@inproceedings{cao-etal-2021-knowledgeable,
    title = "Knowledgeable or Educated Guess? Revisiting Language Models as Knowledge Bases",
    author = "Cao, Boxi  and
      Lin, Hongyu  and
      Han, Xianpei  and
      Sun, Le  and
      Yan, Lingyong  and
      Liao, Meng  and
      Xue, Tong  and
      Xu, Jin",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.146",
    doi = "10.18653/v1/2021.acl-long.146",
    pages = "1860--1874",
    abstract = "Previous literatures show that pre-trained masked language models (MLMs) such as BERT can achieve competitive factual knowledge extraction performance on some datasets, indicating that MLMs can potentially be a reliable knowledge source. In this paper, we conduct a rigorous study to explore the underlying predicting mechanisms of MLMs over different extraction paradigms. By investigating the behaviors of MLMs, we find that previous decent performance mainly owes to the biased prompts which overfit dataset artifacts. Furthermore, incorporating illustrative cases and external contexts improve knowledge prediction mainly due to entity type guidance and golden answer leakage. Our findings shed light on the underlying predicting mechanisms of MLMs, and strongly question the previous conclusion that current MLMs can potentially serve as reliable factual knowledge bases.",
}


@inproceedings{zeng-etal-2022-neighbors,
    title = "Neighbors Are Not Strangers: Improving Non-Autoregressive Translation under Low-Frequency Lexical Constraints",
    author = "Zeng, Chun  and
      Chen, Jiangjie  and
      Zhuang, Tianyi  and
      Xu, Rui  and
      Yang, Hao  and
      Ying, Qin  and
      Tao, Shimin  and
      Xiao, Yanghua",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.424",
    pages = "5777--5790",
}

@inproceedings{shi-etal-2021-enhancing,
    title = "Enhancing Descriptive Image Captioning with Natural Language Inference",
    author = "Shi, Zhan  and 
    Liu, Hui  and 
    Zhu, Xiaodan", 
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-short.36",
    doi = "10.18653/v1/2021.acl-short.36",
    pages = "269--277",
}

@inproceedings{bao-etal-2022-textit,
    title = "{latent-GLAT}: Glancing at Latent Variables for Parallel Text Generation",
    author = "Bao, Yu  and
      Zhou, Hao  and
      Huang, Shujian  and
      Wang, Dongqi  and
      Qian, Lihua  and
      Dai, Xinyu  and
      Chen, Jiajun  and
      Li, Lei",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.575",
    doi = "10.18653/v1/2022.acl-long.575",
    pages = "8398--8409",
}

@inproceedings{
Zhou2020Understanding,
title={Understanding Knowledge Distillation in Non-autoregressive Machine Translation},
author={Chunting Zhou and Jiatao Gu and Graham Neubig},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=BygFVAEKDH}
}

@article{reiter2019natural,
  title={Natural language generation challenges for explainable AI},
  author={Reiter, Ehud},
  journal={arXiv preprint arXiv:1911.08794},
  year={2019}
}

@article{ye2022unreliability,
  title={The Unreliability of Explanations in Few-Shot In-Context Learning},
  author={Ye, Xi and Durrett, Greg},
  journal={arXiv preprint arXiv:2205.03401},
  year={2022}
}

@inproceedings{chen-etal-2022-e,
    title = "{E}-{KAR}: A Benchmark for Rationalizing Natural Language Analogical Reasoning",
    author = "Chen, Jiangjie  and
      Xu, Rui  and
      Fu, Ziquan  and
      Shi, Wei  and
      Li, Zhongqiao  and
      Zhang, Xinbo  and
      Sun, Changzhi  and
      Li, Lei  and
      Xiao, Yanghua  and
      Zhou, Hao",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.311",
    doi = "10.18653/v1/2022.findings-acl.311",
    pages = "3941--3955",
}

@inproceedings{maynez-etal-2020-faithfulness,
    title = "On Faithfulness and Factuality in Abstractive Summarization",
    author = "Maynez, Joshua  and
      Narayan, Shashi  and
      Bohnet, Bernd  and
      McDonald, Ryan",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.173",
    doi = "10.18653/v1/2020.acl-main.173",
    pages = "1906--1919",
}

@inproceedings{ladhak-etal-2022-faithful,
    title = "Faithful or Extractive? On Mitigating the Faithfulness-Abstractiveness Trade-off in Abstractive Summarization",
    author = "Ladhak, Faisal  and
      Durmus, Esin  and
      He, He  and
      Cardie, Claire  and
      McKeown, Kathleen",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.100",
    doi = "10.18653/v1/2022.acl-long.100",
    pages = "1410--1421",
}

@inproceedings{honovich-etal-2021-q2,
    title = "$Q^{2}$: {E}valuating Factual Consistency in Knowledge-Grounded Dialogues via Question Generation and Question Answering",
    author = "Honovich, Or  and
      Choshen, Leshem  and
      Aharoni, Roee  and
      Neeman, Ella  and
      Szpektor, Idan  and
      Abend, Omri",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.619",
    doi = "10.18653/v1/2021.emnlp-main.619",
    pages = "7856--7870",
}

@inproceedings{devaraj-etal-2022-evaluating,
    title = "Evaluating Factuality in Text Simplification",
    author = "Devaraj, Ashwin  and
      Sheffield, William  and
      Wallace, Byron  and
      Li, Junyi Jessy",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.506",
    doi = "10.18653/v1/2022.acl-long.506",
    pages = "7331--7345",
}

@inproceedings{cao-etal-2022-hallucinated,
    title = "Hallucinated but Factual! Inspecting the Factuality of Hallucinations in Abstractive Summarization",
    author = "Cao, Meng  and
      Dong, Yue  and
      Cheung, Jackie",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.236",
    doi = "10.18653/v1/2022.acl-long.236",
    pages = "3340--3354",
}
@inproceedings{NIPS2013_1cecc7a7,
 author = {Bordes, Antoine and Usunier, Nicolas and Garcia-Duran, Alberto and Weston, Jason and Yakhnenko, Oksana},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C.J. Burges and L. Bottou and M. Welling and Z. Ghahramani and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Translating Embeddings for Modeling Multi-relational Data},
 url = {https://proceedings.neurips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf},
 volume = {26},
 year = {2013}
}

@article{Chen_Bao_Sun_Zhang_Chen_Zhou_Xiao_Li_2022, title={LOREN: Logic-Regularized Reasoning for Interpretable Fact Verification}, volume={36}, url={https://ojs.aaai.org/index.php/AAAI/article/view/21291}, DOI={10.1609/aaai.v36i10.21291}, abstractNote={Given a natural language statement, how to verify its veracity against a large-scale textual knowledge source like Wikipedia? Most existing neural models make predictions without giving clues about which part of a false claim goes wrong. In this paper, we propose LOREN, an approach for interpretable fact verification. We decompose the verification of the whole claim at phrase-level, where the veracity of the phrases serves as explanations and can be aggregated into the final verdict according to logical rules. The key insight of LOREN is to represent claim phrase veracity as three-valued latent variables, which are regularized by aggregation logical rules. The final claim verification is based on all latent variables. Thus, LOREN enjoys the additional benefit of interpretability --- it is easy to explain how it reaches certain results with claim phrase veracity. Experiments on a public fact verification benchmark show that LOREN is competitive against previous approaches while enjoying the merit of faithful and accurate interpretability. The resources of LOREN are available at: https://github.com/jiangjiechen/LOREN.}, number={10}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Chen, Jiangjie and Bao, Qiaoben and Sun, Changzhi and Zhang, Xinbo and Chen, Jiaze and Zhou, Hao and Xiao, Yanghua and Li, Lei}, year={2022}, month={Jun.}, pages={10482-10491} }

@article{elazar-etal-2021-measuring,
    title = "Measuring and Improving Consistency in Pretrained Language Models",
    author = {Elazar, Yanai  and
      Kassner, Nora  and
      Ravfogel, Shauli  and
      Ravichander, Abhilasha  and
      Hovy, Eduard  and
      Sch{\"u}tze, Hinrich  and
      Goldberg, Yoav},
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "9",
    year = "2021",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2021.tacl-1.60",
    doi = "10.1162/tacl_a_00410",
    pages = "1012--1031",
}

@inproceedings{kim-etal-2020-will,
    title = "Will {I} Sound Like Me? Improving Persona Consistency in Dialogues through Pragmatic Self-Consciousness",
    author = "Kim, Hyunwoo  and
      Kim, Byeongchang  and
      Kim, Gunhee",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.65",
    doi = "10.18653/v1/2020.emnlp-main.65",
    pages = "904--916",
}

@inproceedings{xiao-wang-2021-hallucination,
    title = "On Hallucination and Predictive Uncertainty in Conditional Language Generation",
    author = "Xiao, Yijun  and
      Wang, William Yang",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.236",
    doi = "10.18653/v1/2021.eacl-main.236",
    pages = "2734--2744",
}

@inproceedings{raunak-etal-2021-curious,
    title = "The Curious Case of Hallucinations in Neural Machine Translation",
    author = "Raunak, Vikas  and
      Menezes, Arul  and
      Junczys-Dowmunt, Marcin",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.92",
    doi = "10.18653/v1/2021.naacl-main.92",
    pages = "1172--1183",
}

@inproceedings{ziems-etal-2022-moral,
    title = "The Moral Integrity Corpus: A Benchmark for Ethical Dialogue Systems",
    author = "Ziems, Caleb  and
      Yu, Jane  and
      Wang, Yi-Chia  and
      Halevy, Alon  and
      Yang, Diyi",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.261",
    doi = "10.18653/v1/2022.acl-long.261",
    pages = "3755--3773",
}

@inproceedings{vanderlyn-etal-2021-seemed,
    title = "{``}It seemed like an annoying woman{''}: On the Perception and Ethical Considerations of Affective Language in Text-Based Conversational Agents",
    author = {Vanderlyn, Lindsey  and
      Weber, Gianna  and
      Neumann, Michael  and
      V{\"a}th, Dirk  and
      Meyer, Sarina  and
      Vu, Ngoc Thang},
    booktitle = "Proceedings of the 25th Conference on Computational Natural Language Learning",
    month = nov,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.conll-1.4",
    doi = "10.18653/v1/2021.conll-1.4",
    pages = "44--57",
}

@inproceedings{xu-etal-2020-xiaomingbot,
    title = "{X}iaomingbot: {A} {M}ultilingual {R}obot {N}ews {R}eporter",
    author = "Xu, Runxin  and
      Cao, Jun  and
      Wang, Mingxuan  and
      Chen, Jiaze  and
      Zhou, Hao  and
      Zeng, Ying  and
      Wang, Yuping  and
      Chen, Li  and
      Yin, Xiang  and
      Zhang, Xijin  and
      Jiang, Songcheng  and
      Wang, Yuxuan  and
      Li, Lei",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-demos.1",
    doi = "10.18653/v1/2020.acl-demos.1",
    pages = "1--8",
}

@article {gkatzia-et-al-2017,
	title = {Data-to-Text Generation Improves Decision-Making Under Uncertainty},
	abstract = {Decision-making is often dependent on uncertain data, e.g. data associated with confidence scores or probabilities. This article presents a comparison of different information presentations for uncertain data and, for the first time, measures their effects on human decision-making, in the domain of weather forecast generation. We use a game-based setup to evaluate the different systems. We show that the use of Natural Language Generation (NLG) enhances decision-making under uncertainty, compared to state-of-the-art graphical-based representation methods.
In a task-based study with 442 adults, we found that presentations using NLG led to 24\% better decision-making on average than the graphical presentations, and to 44\% better decision-making when NLG is combined with graphics. We also show that women achieve significantly better results when presented with NLG output (an 87\% increase on average compared to graphical presentations). Finally, we present a further analysis of demographic data and its impact on decision-making, and we discuss implications for future NLG systems.},
	doi = {10.1109/MCI.2017.2708998},
	issn = {1556-603X},
	issue = {3},
	journal = {IEEE Computational Intelligence Magazine},
	pages = {10-17},
	publicationstatus = {Published},
	publisher = {Institute of Electrical and Electronics Engineers},
	url = {http://researchrepository.napier.ac.uk/Output/687579},
	volume = {12},
	keyword = {004 Data processing & computer science, QA75 Electronic computers. Computer science, Information science, Information Society, Natural language processing, Decision making, Data analysis, Games, Pragmatics, Uncertainty, Weather forecasting},
	year = {2017},
	author = {Gkatzia, Dimitra and Lemon, Oliver and Rieser, Verena}
}




@article{thoppilan2022lamda,
  title={Lamda: Language models for dialog applications},
  author={Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
  journal={arXiv preprint arXiv:2201.08239},
  year={2022}
}

@article{wu2016google,
  title={Google's neural machine translation system: Bridging the gap between human and machine translation},
  author={Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and others},
  journal={arXiv preprint arXiv:1609.08144},
  year={2016}
}

@article{weizenbaum1966eliza,
  title={ELIZA—a computer program for the study of natural language communication between man and machine},
  author={Weizenbaum, Joseph},
  journal={Communications of the ACM},
  volume={9},
  number={1},
  pages={36--45},
  year={1966},
  publisher={ACM New York, NY, USA}
}

@article{xiao2022survey,
  title={A Survey on Non-Autoregressive Generation for Neural Machine Translation and Beyond},
  author={Xiao, Yisheng and Wu, Lijun and Guo, Junliang and Li, Juntao and Zhang, Min and Qin, Tao and Liu, Tie-yan},
  journal={arXiv preprint arXiv:2204.09269},
  year={2022}
}

@inproceedings{qian-etal-2021-glancing,
    title = "Glancing Transformer for Non-Autoregressive Neural Machine Translation",
    author = "Qian, Lihua  and
      Zhou, Hao  and
      Bao, Yu  and
      Wang, Mingxuan  and
      Qiu, Lin  and
      Zhang, Weinan  and
      Yu, Yong  and
      Li, Lei",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.155",
    doi = "10.18653/v1/2021.acl-long.155",
    pages = "1993--2003",
}

@inproceedings{NEURIPS2020_1457c0d6,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}

@book{wittgenstein1958blue,
  title={The blue and brown books},
  author={Wittgenstein, Ludwig},
  volume={34},
  year={1958},
  publisher={Blackwell Oxford}
}

@inproceedings{hosseini-etal-2021-understanding,
    title = "Understanding by Understanding Not: Modeling Negation in Language Models",
    author = "Hosseini, Arian  and
      Reddy, Siva  and
      Bahdanau, Dzmitry  and
      Hjelm, R Devon  and
      Sordoni, Alessandro  and
      Courville, Aaron",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.102",
    doi = "10.18653/v1/2021.naacl-main.102",
    pages = "1301--1312",
}

@inproceedings{wiegreffe-etal-2021-measuring,
    title = "{M}easuring Association Between Labels and Free-Text Rationales",
    author = "Wiegreffe, Sarah  and
      Marasovi{\'c}, Ana  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.804",
    doi = "10.18653/v1/2021.emnlp-main.804",
    pages = "10266--10284",
}

@inproceedings{hossain-etal-2020-analysis,
    title = "An Analysis of Natural Language Inference Benchmarks through the Lens of Negation",
    author = "Hossain, Md Mosharaf  and
      Kovatchev, Venelin  and
      Dutta, Pranoy  and
      Kao, Tiffany  and
      Wei, Elizabeth  and
      Blanco, Eduardo",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.732",
    doi = "10.18653/v1/2020.emnlp-main.732",
    pages = "9106--9118",
}

@article{barker2012being,
  title={Being positive about negative facts},
  author={Barker, Stephen and Jago, Mark},
  journal={Philosophy and Phenomenological research},
  pages={117--138},
  year={2012},
  publisher={JSTOR}
}

@inproceedings{zhao-etal-2019-moverscore,
    title = "{M}over{S}core: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance",
    author = "Zhao, Wei  and
      Peyrard, Maxime  and
      Liu, Fei  and
      Gao, Yang  and
      Meyer, Christian M.  and
      Eger, Steffen",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1053",
    doi = "10.18653/v1/D19-1053",
    pages = "563--578",
}

@inproceedings{liu-etal-2020-multi,
    title = "Multi-Step Inference for Reasoning Over Paragraphs",
    author = "Liu, Jiangming  and
      Gardner, Matt  and
      Cohen, Shay B.  and
      Lapata, Mirella",
    booktitle = "Proceedings of the 2020 Conference on EMNLP",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.245",
    doi = "10.18653/v1/2020.emnlp-main.245",
    pages = "3040--3050",
}


@article{malinowski2007many,
  title={Many-valued logic and its philosophy.},
  author={Malinowski, Grzegorz},
  journal={The Many Valued and Nonmonotonic Turn in Logic},
  volume={8},
  pages={13--94},
  year={2007}
}


@inproceedings{DBLP:journals/corr/KingmaW13,
  author    = {Diederik P. Kingma and
               Max Welling},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Auto-Encoding Variational Bayes},
  booktitle = {2nd International Conference on Learning Representations, {ICLR} 2014,
               Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
  year      = {2014},
  url       = {http://arxiv.org/abs/1312.6114},
  timestamp = {Thu, 04 Apr 2019 13:20:07 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaW13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{amizadeh2020neuro,
  title={Neuro-Symbolic Visual Reasoning: Disentangling" Visual" from" Reasoning"},
  author={Amizadeh, Saeed and Palangi, Hamid and Polozov, Oleksandr and Huang, Yichen and Koishida, Kazuhito},
  journal={ICML},
  year={2020}
}


@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@inproceedings{2020unifiedqa,
    title = "{UNIFIEDQA}: Crossing Format Boundaries with a Single {QA} System",
    author = "Khashabi, Daniel  and
      Min, Sewon  and
      Khot, Tushar  and
      Sabharwal, Ashish  and
      Tafjord, Oyvind  and
      Clark, Peter  and
      Hajishirzi, Hannaneh",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.findings-emnlp.171",
    doi = "10.18653/v1/2020.findings-emnlp.171",
    pages = "1896--1907",
}

@inproceedings{gardner2017allennlp,
    title = "{A}llen{NLP}: A Deep Semantic Natural Language Processing Platform",
    author = "Gardner, Matt  and
      Grus, Joel  and
      Neumann, Mark  and
      Tafjord, Oyvind  and
      Dasigi, Pradeep  and
      Liu, Nelson F.  and
      Peters, Matthew  and
      Schmitz, Michael  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of Workshop for {NLP} Open Source Software ({NLP}-{OSS})",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-2501",
    doi = "10.18653/v1/W18-2501",
    pages = "1--6",
}

@inproceedings{li2018ensure,
    title = "Ensure the Correctness of the Summary: Incorporate Entailment Knowledge into Abstractive Sentence Summarization",
    author = "Li, Haoran  and
      Zhu, Junnan  and
      Zhang, Jiajun  and
      Zong, Chengqing",
    booktitle = "Proceedings of the 27th International Conference on Computational Linguistics",
    month = aug,
    year = "2018",
    address = "Santa Fe, New Mexico, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/C18-1121",
    pages = "1430--1441",
}

@inproceedings{angeli2015leveraging,
    title = "Leveraging Linguistic Structure For Open Domain Information Extraction",
    author = "Angeli, Gabor  and
      Johnson Premkumar, Melvin Jose  and
      Manning, Christopher D.",
    booktitle = "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = jul,
    year = "2015",
    address = "Beijing, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P15-1034",
    doi = "10.3115/v1/P15-1034",
    pages = "344--354",
}


@article{zhu2020boosting,
  title={Boosting factual correctness of abstractive summarization with knowledge graph},
  author={Zhu, Chenguang and Hinthorn, William and Xu, Ruochen and Zeng, Qingkai and Zeng, Michael and Huang, Xuedong and Jiang, Meng},
  journal={arXiv preprint arXiv:2003.08612},
  year={2020}
}

@inproceedings{thorne-etal-2018-fever,
    title = "{FEVER}: a Large-scale Dataset for Fact Extraction and {VER}ification",
    author = "Thorne, James  and
      Vlachos, Andreas  and
      Christodoulopoulos, Christos  and
      Mittal, Arpit",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-1074",
    doi = "10.18653/v1/N18-1074",
    pages = "809--819",
}


@inproceedings{velickovic2018graph,
  author    = {Petar Velickovic and
               Guillem Cucurull and
               Arantxa Casanova and
               Adriana Romero and
               Pietro Li{\`{o}} and
               Yoshua Bengio},
  title     = {Graph Attention Networks},
  booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2018},
  url       = {https://openreview.net/forum?id=rJXMpikCZ},
  timestamp = {Thu, 25 Jul 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/VelickovicCCRLB18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{zhou-etal-2019-gear,
    title = "{GEAR}: Graph-based Evidence Aggregating and Reasoning for Fact Verification",
    author = "Zhou, Jie  and
      Han, Xu  and
      Yang, Cheng  and
      Liu, Zhiyuan  and
      Wang, Lifeng  and
      Li, Changcheng  and
      Sun, Maosong",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1085",
    doi = "10.18653/v1/P19-1085",
    pages = "892--901",
}

@inproceedings{kang18acl,
  title = {Adversarial Training for Textual Entailment with Knowledge-Guided Examples},
  author = {Dongyeop Kang and Tushar Khot and Ashish Sabharwal and Eduard Hovy},
  booktitle = {The 56th Annual Meeting of the Association for Computational Linguistics (ACL)},
  address = {Melbourne, Australia},
  month = {July},
  year = {2018}
}

@inproceedings{rajpurkar2018know,
  title={Know What You Don’t Know: Unanswerable Questions for SQuAD},
  author={Rajpurkar, Pranav and Jia, Robin and Liang, Percy},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  pages={784--789},
  year={2018}
}

@inproceedings{bowman-etal-2015-large,
    title = "A large annotated corpus for learning natural language inference",
    author = "Bowman, Samuel R.  and
      Angeli, Gabor  and
      Potts, Christopher  and
      Manning, Christopher D.",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D15-1075",
    doi = "10.18653/v1/D15-1075",
    pages = "632--642",
}

@InProceedings{N18-1101,
  author = "Williams, Adina
            and Nangia, Nikita
            and Bowman, Samuel",
  title = "A Broad-Coverage Challenge Corpus for 
           Sentence Understanding through Inference",
  booktitle = "Proceedings of the 2018 Conference of 
               the North American Chapter of the 
               Association for Computational Linguistics:
               Human Language Technologies, Volume 1 (Long
               Papers)",
  year = "2018",
  publisher = "Association for Computational Linguistics",
  pages = "1112--1122",
  location = "New Orleans, Louisiana",
  url = "http://aclweb.org/anthology/N18-1101"
}


@inproceedings{chen2019enhancing,
    title = "Enhancing Neural Data-To-Text Generation Models with External Background Knowledge",
    author = "Chen, Shuang  and
      Wang, Jinpeng  and
      Feng, Xiaocheng  and
      Jiang, Feng  and
      Qin, Bing  and
      Lin, Chin-Yew",
    booktitle = "Proceedings of the 2019 Conference on EMNLP-IJCNLP",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1299",
    doi = "10.18653/v1/D19-1299",
    pages = "3022--3032",
}


@inproceedings{zellers2019defending,
  title={Defending against neural fake news},
  author={Zellers, Rowan and Holtzman, Ari and Rashkin, Hannah and Bisk, Yonatan and Farhadi, Ali and Roesner, Franziska and Choi, Yejin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9051--9062},
  year={2019}
}

@inproceedings{DBLP:conf/iclr/JangGP17,
  author    = {Eric Jang and
               Shixiang Gu and
               Ben Poole},
  title     = {Categorical Reparameterization with Gumbel-Softmax},
  booktitle = {5th International Conference on Learning Representations, {ICLR} 2017,
               Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2017},
  url       = {https://openreview.net/forum?id=rkE3y85ee},
  timestamp = {Thu, 25 Jul 2019 14:26:04 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/JangGP17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{NEURIPS2018_4c7a167b,
 author = {Camburu, Oana-Maria and Rockt\"{a}schel, Tim and Lukasiewicz, Thomas and Blunsom, Phil},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {e-SNLI: Natural Language Inference with Natural Language Explanations},
 url = {https://proceedings.neurips.cc/paper/2018/file/4c7a167bb329bd92580a99ce422d6fa6-Paper.pdf},
 volume = {31},
 year = {2018}
}



@inproceedings{aggarwal-etal-2021-explanations,
    title = "{E}xplanations for {C}ommonsense{QA}: {N}ew {D}ataset and {M}odels",
    author = "Aggarwal, Shourya  and
      Mandowara, Divyanshu  and
      Agrawal, Vishwajeet  and
      Khandelwal, Dinesh  and
      Singla, Parag  and
      Garg, Dinesh",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.238",
    doi = "10.18653/v1/2021.acl-long.238",
    pages = "3050--3065",
}

@inproceedings{
    bhagavatula2020abductive,
    title={Abductive Commonsense Reasoning},
    author={Chandra Bhagavatula and Ronan Le Bras and Chaitanya Malaviya and Keisuke Sakaguchi and Ari Holtzman and Hannah Rashkin and Doug Downey and Wen-tau Yih and Yejin Choi},
    booktitle={International Conference on Learning Representations},
    year={2020},
    url={https://openreview.net/forum?id=Byg1v1HKDB}
}

@article{feldman1982connectionist,
  title={Connectionist models and their properties},
  author={Feldman, Jerome A and Ballard, Dana H},
  journal={Cognitive science},
  volume={6},
  number={3},
  pages={205--254},
  year={1982},
  publisher={Elsevier}
}

@inproceedings{li-etal-2020-ca,
    title = "{CA}-{EHN}: Commonsense Analogy from {E}-{H}ow{N}et",
    author = "Li, Peng-Hsuan  and
      Yang, Tsan-Yu  and
      Ma, Wei-Yun",
    booktitle = "Proceedings of the 12th Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2020.lrec-1.365",
    pages = "2984--2990",
    abstract = "Embedding commonsense knowledge is crucial for end-to-end models to generalize inference beyond training corpora. However, existing word analogy datasets have tended to be handcrafted, involving permutations of hundreds of words with only dozens of pre-defined relations, mostly morphological relations and named entities. In this work, we model commonsense knowledge down to word-level analogical reasoning by leveraging E-HowNet, an ontology that annotates 88K Chinese words with their structured sense definitions and English translations. We present CA-EHN, the first commonsense word analogy dataset containing 90,505 analogies covering 5,656 words and 763 relations. Experiments show that CA-EHN stands out as a great indicator of how well word representations embed commonsense knowledge. The dataset is publicly available at \url{https://github.com/ckiplab/CA-EHN}.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@inproceedings{gladkova-etal-2016-analogy,
    title = "Analogy-based detection of morphological and semantic relations with word embeddings: what works and what doesn{'}t.",
    author = "Gladkova, Anna  and
      Drozd, Aleksandr  and
      Matsuoka, Satoshi",
    booktitle = "Proceedings of the {NAACL} Student Research Workshop",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N16-2002",
    doi = "10.18653/v1/N16-2002",
    pages = "8--15",
}

@inproceedings{mikolov-etal-2013-linguistic,
    title = "Linguistic Regularities in Continuous Space Word Representations",
    author = "Mikolov, Tomas  and
      Yih, Wen-tau  and
      Zweig, Geoffrey",
    booktitle = "Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2013",
    address = "Atlanta, Georgia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N13-1090",
    pages = "746--751",
}

@article{turney2003combining,
  title={Combining independent modules in lexical multiple-choice problems},
  author={Turney, Peter D and Littman, Michael L and Bigham, Jeffrey and Shnayder, Victor},
  journal={Recent Advances in Natural Language Processing III: Selected Papers from RANLP},
  volume={2003},
  pages={101--110},
  year={2003}
}

@inproceedings{li-etal-2018-analogical,
    title = "Analogical Reasoning on {C}hinese Morphological and Semantic Relations",
    author = "Li, Shen  and
      Zhao, Zhe  and
      Hu, Renfen  and
      Li, Wensi  and
      Liu, Tao  and
      Du, Xiaoyong",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-2023",
    doi = "10.18653/v1/P18-2023",
    pages = "138--143",
    abstract = "Analogical reasoning is effective in capturing linguistic regularities. This paper proposes an analogical reasoning task on Chinese. After delving into Chinese lexical knowledge, we sketch 68 implicit morphological relations and 28 explicit semantic relations. A big and balanced dataset CA8 is then built for this task, including 17813 questions. Furthermore, we systematically explore the influences of vector representations, context features, and corpora on analogical reasoning. With the experiments, CA8 is proved to be a reliable benchmark for evaluating Chinese word embeddings.",
}

@article{wales1969so,
  title={What is so difficult about negation?},
  author={Wales, RJ and Grieve, R},
  journal={Perception \& Psychophysics},
  volume={6},
  number={6},
  pages={327--332},
  year={1969},
  publisher={Springer}
}

@article{wu2020controllable,
  title={A controllable model of grounded response generation},
  author={Wu, Zeqiu and Galley, Michel and Brockett, Chris and Zhang, Yizhe and Gao, Xiang and Quirk, Chris and Koncel-Kedziorski, Rik and Gao, Jianfeng and Hajishirzi, Hannaneh and Ostendorf, Mari and others},
  journal={arXiv preprint arXiv:2005.00613},
  year={2020}
}


@inproceedings{goodrich2019assessing,
  title={Assessing the factual accuracy of generated text},
  author={Goodrich, Ben and Rao, Vinay and Liu, Peter J and Saleh, Mohammad},
  booktitle={Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={166--175},
  year={2019}
}

@inproceedings{dhingra2019handling,
    title = "Handling Divergent Reference Texts when Evaluating Table-to-Text Generation",
    author = "Dhingra, Bhuwan  and
      Faruqui, Manaal  and
      Parikh, Ankur  and
      Chang, Ming-Wei  and
      Das, Dipanjan  and
      Cohen, William",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1483",
    doi = "10.18653/v1/P19-1483",
    pages = "4884--4895",
}


@article{wang2019logic,
  title={Logic rules powered knowledge graph embedding},
  author={Wang, Pengwei and Dou, Dejing and Wu, Fangzhao and de Silva, Nisansa and Jin, Lianwen},
  journal={arXiv preprint arXiv:1903.03772},
  year={2019}
}

@inproceedings{sorokin2017context,
    title = "Context-Aware Representations for Knowledge Base Relation Extraction",
    author = "Sorokin, Daniil  and
      Gurevych, Iryna",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D17-1188",
    doi = "10.18653/v1/D17-1188",
    pages = "1784--1789",
}

@inproceedings{yao2019docred,
    title = "{D}oc{RED}: A Large-Scale Document-Level Relation Extraction Dataset",
    author = "Yao, Yuan  and
      Ye, Deming  and
      Li, Peng  and
      Han, Xu  and
      Lin, Yankai  and
      Liu, Zhenghao  and
      Liu, Zhiyuan  and
      Huang, Lixin  and
      Zhou, Jie  and
      Sun, Maosong",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1074",
    doi = "10.18653/v1/P19-1074",
    pages = "764--777",
}

@inproceedings{kang2018adventureat,
    title = "{A}dv{E}ntu{R}e: Adversarial Training for Textual Entailment with Knowledge-Guided Examples",
    author = "Kang, Dongyeop  and
      Khot, Tushar  and
      Sabharwal, Ashish  and
      Hovy, Eduard",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-1225",
    doi = "10.18653/v1/P18-1225",
    pages = "2418--2428",
}


@inproceedings{raiman2018deeptype,
  title={Deeptype: multilingual entity linking by neural type system evolution},
  author={Raiman, Jonathan Raphael and Raiman, Olivier Michel},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{kryscinskifactcc2019,
    title = "Evaluating the Factual Consistency of Abstractive Text Summarization",
    author = "Kryscinski, Wojciech  and
      McCann, Bryan  and
      Xiong, Caiming  and
      Socher, Richard",
    booktitle = "Proceedings of the 2020 Conference on EMNLP",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.750",
    doi = "10.18653/v1/2020.emnlp-main.750",
    pages = "9332--9346",
}

@inproceedings{aralikatte2019rewarding,
    title = "Rewarding Coreference Resolvers for Being Consistent with World Knowledge",
    author = "Aralikatte, Rahul  and
      Lent, Heather  and
      Gonzalez, Ana Valeria  and
      Herschcovich, Daniel  and
      Qiu, Chen  and
      Sandholm, Anders  and
      Ringaard, Michael  and
      S{\o}gaard, Anders",
    booktitle = "Proceedings of the 2019 Conference on EMNLP-IJCNLP",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1118",
    doi = "10.18653/v1/D19-1118",
    pages = "1229--1235",
}


@inproceedings{cao2018faithful,
  title={Faithful to the original: Fact aware neural abstractive summarization},
  author={Cao, Ziqiang and Wei, Furu and Li, Wenjie and Li, Sujian},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{falke2019ranking,
    title = "Ranking Generated Summaries by Correctness: An Interesting but Challenging Application for Natural Language Inference",
    author = "Falke, Tobias  and
      Ribeiro, Leonardo F. R.  and
      Utama, Prasetya Ajie  and
      Dagan, Ido  and
      Gurevych, Iryna",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1213",
    doi = "10.18653/v1/P19-1213",
    pages = "2214--2220",
}


@inproceedings{ceylan2016open,
  title={Open-world probabilistic databases},
  author={Ceylan, Ismail Ilkan and Darwiche, Adnan and Van den Broeck, Guy},
  booktitle={Fifteenth International Conference on the Principles of Knowledge Representation and Reasoning},
  year={2016}
}


@article{reiter1978closed,
  title={On closed world databases. In “Logic and Databases”, H. Gallaire and J. Minker eds},
  author={Reiter, Raymond},
  year={1978},
  publisher={Plenum Press}
}


@article{ringgaard2017sling,
  title={SLING: A framework for frame semantic parsing},
  author={Ringgaard, Michael and Gupta, Rahul and Pereira, Fernando CN},
  journal={arXiv preprint arXiv:1710.07032},
  year={2017}
}


@article{tian2019sticking,
  title={Sticking to the Facts: Confident Decoding for Faithful Data-to-Text Generation},
  author={Tian, Ran and Narayan, Shashi and Sellam, Thibault and Parikh, Ankur P},
  journal={arXiv preprint arXiv:1910.08684},
  year={2019}
}

@inproceedings{bunescu2007learning,
  title={Learning to extract relations from the web using minimal supervision},
  author={Bunescu, Razvan and Mooney, Raymond},
  booktitle={Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics},
  pages={576--583},
  year={2007}
}

@inproceedings{mintz2009distant,
  title={Distant supervision for relation extraction without labeled data},
  author={Mintz, Mike and Bills, Steven and Snow, Rion and Jurafsky, Dan},
  booktitle={Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP},
  pages={1003--1011},
  year={2009}
}

@inproceedings{hoffmann2011knowledge,
  title={Knowledge-based weak supervision for information extraction of overlapping relations},
  author={Hoffmann, Raphael and Zhang, Congle and Ling, Xiao and Zettlemoyer, Luke and Weld, Daniel S},
  booktitle={Proceedings of the 49th annual meeting of the association for computational linguistics: human language technologies},
  pages={541--550},
  year={2011}
}

@inproceedings{surdeanu2012multi,
  title={Multi-instance multi-label learning for relation extraction},
  author={Surdeanu, Mihai and Tibshirani, Julie and Nallapati, Ramesh and Manning, Christopher D},
  booktitle={Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning},
  pages={455--465},
  year={2012}
}


@inproceedings{DBLP:conf/tto/StammbachA20,
  author    = {Dominik Stammbach and
               Elliott Ash},
  editor    = {Emiliano De Cristofaro and
               Preslav Nakov},
  title     = {e-FEVER: Explanations and Summaries forAutomated Fact Checking},
  booktitle = {Proceedings of the 2020 Truth and Trust Online Conference {(TTO} 2020),
               Virtual, October 15-17, 2020},
  pages     = {32--43},
  publisher = {Hacks Hackers},
  year      = {2020},
  url       = {https://truthandtrustonline.com/wp-content/uploads/2020/10/TTO04.pdf},
  timestamp = {Tue, 03 Nov 2020 16:50:40 +0100},
  biburl    = {https://dblp.org/rec/conf/tto/StammbachA20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{wiseman:2017dp,
    title = "Challenges in Data-to-Document Generation",
    author = "Wiseman, Sam  and
      Shieber, Stuart  and
      Rush, Alexander",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D17-1239",
    doi = "10.18653/v1/D17-1239",
    pages = "2253--2263",
}

@inproceedings{papineni2002bleu,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P02-1040",
    doi = "10.3115/1073083.1073135",
    pages = "311--318",
}

@inproceedings{lin2004rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W04-1013",
    pages = "74--81",
}


@inproceedings{xiong2019pretrained,
  author    = {Wenhan Xiong and
               Jingfei Du and
               William Yang Wang and
               Veselin Stoyanov},
  title     = {Pretrained Encyclopedia: Weakly Supervised Knowledge-Pretrained Language
               Model},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020},
  url       = {https://openreview.net/forum?id=BJlzm64tDH},
  timestamp = {Thu, 07 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/XiongDWS20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{stammbach2020fever,
  title={e-fever: Explanations and summaries for automated fact checking},
  author={Stammbach, Dominik and Ash, Elliott},
  booktitle={Proceedings of the 2020 Truth and Trust Online Conference (TTO 2020)},
  pages={32},
  year={2020},
  organization={Hacks Hackers}
}

@inproceedings{thorne-vlachos-2021-evidence,
    title = "Evidence-based Factual Error Correction",
    author = "Thorne, James  and
      Vlachos, Andreas",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.256",
    doi = "10.18653/v1/2021.acl-long.256",
    pages = "3298--3309",
    abstract = "This paper introduces the task of factual error correction: performing edits to a claim so that the generated rewrite is better supported by evidence. This extends the well-studied task of fact verification by providing a mechanism to correct written texts that are refuted or only partially supported by evidence. We demonstrate that it is feasible to train factual error correction systems from existing fact checking datasets which only contain labeled claims accompanied by evidence, but not the correction. We achieve this by employing a two-stage distant supervision approach that incorporates evidence into masked claims when generating corrections. Our approach, based on the T5 transformer and using retrieved evidence, achieved better results than existing work which used a pointer copy network and gold evidence, producing accurate factual error corrections for 5x more instances in human evaluation and a .125 increase in SARI score. The evaluation is conducted on a dataset of 65,000 instances based on a recent fact verification shared task and we release it to enable further work on the task.",
}


@inproceedings{yang2019xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  booktitle={Advances in neural information processing systems},
  pages={5753--5763},
  year={2019}
}


@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}


@article{evans2003two,
  title={In two minds: dual-process accounts of reasoning},
  author={Evans, Jonathan St BT},
  journal={Trends in cognitive sciences},
  volume={7},
  number={10},
  pages={454--459},
  year={2003},
  publisher={Elsevier}
}


@article{evans1984heuristic,
  title={Heuristic and analytic processes in reasoning},
  author={Evans, Jonathan St BT},
  journal={British Journal of Psychology},
  volume={75},
  number={4},
  pages={451--468},
  year={1984},
  publisher={Wiley Online Library}
}

@inproceedings{ding2019cognitive,
    title = "Cognitive Graph for Multi-Hop Reading Comprehension at Scale",
    author = "Ding, Ming  and
      Zhou, Chang  and
      Chen, Qibin  and
      Yang, Hongxia  and
      Tang, Jie",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1259",
    doi = "10.18653/v1/P19-1259",
    pages = "2694--2703",
}


@article{sloman1996empirical,
  title={The empirical case for two systems of reasoning.},
  author={Sloman, Steven A},
  journal={Psychological bulletin},
  volume={119},
  number={1},
  pages={3},
  year={1996},
  publisher={American Psychological Association}
}

@inproceedings{lee2020languagema,
    title = "Language Models as Fact Checkers?",
    author = "Lee, Nayeon  and
      Li, Belinda Z.  and
      Wang, Sinong  and
      Yih, Wen-tau  and
      Ma, Hao  and
      Khabsa, Madian",
    booktitle = "Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER)",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.fever-1.5",
    doi = "10.18653/v1/2020.fever-1.5",
    pages = "36--41",
}

@inproceedings{liu2020fine,
    title = "Fine-grained Fact Verification with Kernel Graph Attention Network",
    author = "Liu, Zhenghao  and
      Xiong, Chenyan  and
      Sun, Maosong  and
      Liu, Zhiyuan",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.655",
    doi = "10.18653/v1/2020.acl-main.655",
    pages = "7342--7351",
}

@inproceedings{maccartney2007natural,
    title = "Natural Logic for Textual Inference",
    author = "MacCartney, Bill  and
      Manning, Christopher D.",
    booktitle = "Proceedings of the {ACL}-{PASCAL} Workshop on Textual Entailment and Paraphrasing",
    month = jun,
    year = "2007",
    address = "Prague",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W07-1431",
    pages = "193--200",
}


@article{lakoff1970linguistics,
  title={Linguistics and natural logic},
  author={Lakoff, George},
  journal={Synthese},
  volume={22},
  number={1-2},
  pages={151--271},
  year={1970},
  publisher={Springer}
}


@article{ran2019option,
  title={Option comparison network for multiple-choice reading comprehension},
  author={Ran, Qiu and Li, Peng and Hu, Weiwei and Zhou, Jie},
  journal={arXiv preprint arXiv:1903.03033},
  year={2019}
}


@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}
@article{hakami2017compositional,
  title={Compositional approaches for representing relations between words: A comparative study},
  author={Hakami, Huda and Bollegala, Danushka},
  journal={Knowledge-Based Systems},
  volume={136},
  pages={172--182},
  year={2017},
  publisher={Elsevier}
}
@inproceedings{ushio-etal-2021-bert,
    title = "{BERT} is to {NLP} what {A}lex{N}et is to {CV}: Can Pre-Trained Language Models Identify Analogies?",
    author = "Ushio, Asahi  and
      Espinosa Anke, Luis  and
      Schockaert, Steven  and
      Camacho-Collados, Jose",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.280",
    doi = "10.18653/v1/2021.acl-long.280",
    pages = "3609--3624",
    abstract = "Analogies play a central role in human commonsense reasoning. The ability to recognize analogies such as {``}eye is to seeing what ear is to hearing{''}, sometimes referred to as analogical proportions, shape how we structure knowledge and understand language. Surprisingly, however, the task of identifying such analogies has not yet received much attention in the language model era. In this paper, we analyze the capabilities of transformer-based language models on this unsupervised task, using benchmarks obtained from educational settings, as well as more commonly used datasets. We find that off-the-shelf language models can identify analogies to a certain extent, but struggle with abstract and complex relations, and results are highly sensitive to model architecture and hyperparameters. Overall the best results were obtained with GPT-2 and RoBERTa, while configurations using BERT were not able to outperform word embedding models. Our results raise important questions for future work about how, and to what extent, pre-trained language models capture knowledge about abstract semantic relations.",
}

@inproceedings{beck2018graph,
    title = "Graph-to-Sequence Learning using Gated Graph Neural Networks",
    author = "Beck, Daniel  and
      Haffari, Gholamreza  and
      Cohn, Trevor",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-1026",
    doi = "10.18653/v1/P18-1026",
    pages = "273--283",
}

@inproceedings{mihaylov-frank-2018-knowledgeable,
    title = "Knowledgeable Reader: Enhancing Cloze-Style Reading Comprehension with External Commonsense Knowledge",
    author = "Mihaylov, Todor  and
      Frank, Anette",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-1076",
    doi = "10.18653/v1/P18-1076",
    pages = "821--832",
}

@InProceedings{P18-2023,
  author =  "Li, Shen
    and Zhao, Zhe
    and Hu, Renfen
    and Li, Wensi
    and Liu, Tao
    and Du, Xiaoyong",
  title =   "Analogical Reasoning on Chinese Morphological and Semantic Relations",
  booktitle =   "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
  year =  "2018",
  publisher =   "Association for Computational Linguistics",
  pages =   "138--143",
  location =  "Melbourne, Australia",
  url =   "http://aclweb.org/anthology/P18-2023"
}
@article{bojanowski2017enriching,
  title={Enriching word vectors with subword information},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={Transactions of the Association for Computational Linguistics},
  volume={5},
  pages={135--146},
  year={2017},
  publisher={MIT Press}
}
@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}
@inproceedings{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  booktitle={Advances in neural information processing systems},
  pages={3111--3119},
  year={2013}
}

@inproceedings{unilm,
    title={Unified Language Model Pre-training for Natural Language Understanding and Generation},
    author={Dong, Li and Yang, Nan and Wang, Wenhui and Wei, Furu and Liu, Xiaodong and Wang, Yu and Gao, Jianfeng and Zhou, Ming and Hon, Hsiao-Wuen},
    year={2019},
    booktitle = "33rd Conference on Neural Information Processing Systems (NeurIPS 2019)"
}


@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Wolf, Thomas  and
      Debut, Lysandre  and
      Sanh, Victor  and
      Chaumond, Julien  and
      Delangue, Clement  and
      Moi, Anthony  and
      Cistac, Pierric  and
      Rault, Tim  and
      Louf, Remi  and
      Funtowicz, Morgan  and
      Davison, Joe  and
      Shleifer, Sam  and
      von Platen, Patrick  and
      Ma, Clara  and
      Jernite, Yacine  and
      Plu, Julien  and
      Xu, Canwen  and
      Le Scao, Teven  and
      Gugger, Sylvain  and
      Drame, Mariama  and
      Lhoest, Quentin  and
      Rush, Alexander",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-demos.6",
    doi = "10.18653/v1/2020.emnlp-demos.6",
    pages = "38--45",
    abstract = "Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. Transformers is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. Transformers is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at https://github.com/huggingface/transformers.",
}

@inproceedings{chen-etal-2017-enhanced,
    title = "Enhanced {LSTM} for Natural Language Inference",
    author = "Chen, Qian  and
      Zhu, Xiaodan  and
      Ling, Zhen-Hua  and
      Wei, Si  and
      Jiang, Hui  and
      Inkpen, Diana",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P17-1152",
    doi = "10.18653/v1/P17-1152",
    pages = "1657--1668",
}

@inproceedings{DBLP:conf/nips/ZhouHZLSXT20,
  author    = {Wangchunshu Zhou and
               Jinyi Hu and
               Hanlin Zhang and
               Xiaodan Liang and
               Maosong Sun and
               Chenyan Xiong and
               Jian Tang},
  editor    = {Hugo Larochelle and
               Marc'Aurelio Ranzato and
               Raia Hadsell and
               Maria{-}Florina Balcan and
               Hsuan{-}Tien Lin},
  title     = {Towards Interpretable Natural Language Understanding with Explanations
               as Latent Variables},
  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
               on Neural Information Processing Systems 2020, NeurIPS 2020, December
               6-12, 2020, virtual},
  year      = {2020},
  url       = {https://proceedings.neurips.cc/paper/2020/hash/4be2c8f27b8a420492f2d44463933eb6-Abstract.html},
  timestamp = {Tue, 19 Jan 2021 15:57:13 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/ZhouHZLSXT20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{wang2020neural,
  title={Neural question generation with answer pivot},
  author={Wang, Bingning and Wang, Xiaochuan and Tao, Ting and Zhang, Qi and Xu, Jingfang},
  booktitle={AAAI},
  volume={34},
  number={05},
  pages={9138--9145},
  year={2020}
}


@inproceedings{petroni2020how,
    title={How Context Affects Language Models' Factual Predictions},
    author={Fabio Petroni and Patrick Lewis and Aleksandra Piktus and Tim Rockt{\"a}schel and Yuxiang Wu and Alexander H. Miller and Sebastian Riedel},
    booktitle={Automated Knowledge Base Construction},
    year={2020},
    url={https://openreview.net/forum?id=025X0zPfn},
    doi={10.24432/C5201W}
}


@inproceedings{bindris2018fact,
  title={Fact Checking from Natural Text with Probabilistic Soft Logic},
  author={Bindris, Nouf and Sudhahar, Saatviga and Cristianini, Nello},
  booktitle={International Symposium on Intelligent Data Analysis},
  pages={52--61},
  year={2018},
  organization={Springer}
}


@article{hua2016understand,
  title={Understand short texts by harvesting and analyzing semantic knowledge},
  author={Hua, Wen and Wang, Zhongyuan and Wang, Haixun and Zheng, Kai and Zhou, Xiaofang},
  journal={IEEE transactions on Knowledge and data Engineering},
  volume={29},
  number={3},
  pages={499--512},
  year={2016},
  publisher={IEEE}
}

@inproceedings{jiang-etal-2021-exploring-listwise,
    title = "Exploring Listwise Evidence Reasoning with T5 for Fact Verification",
    author = "Jiang, Kelvin  and
      Pradeep, Ronak  and
      Lin, Jimmy",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-short.51",
    doi = "10.18653/v1/2021.acl-short.51",
    pages = "402--410",
    abstract = "This work explores a framework for fact verification that leverages pretrained sequence-to-sequence transformer models for sentence selection and label prediction, two key sub-tasks in fact verification. Most notably, improving on previous pointwise aggregation approaches for label prediction, we take advantage of T5 using a listwise approach coupled with data augmentation. With this enhancement, we observe that our label prediction stage is more robust to noise and capable of verifying complex claims by jointly reasoning over multiple pieces of evidence. Experimental results on the FEVER task show that our system attains a FEVER score of 75.87{\%} on the blind test set. This puts our approach atop the competitive FEVER leaderboard at the time of our work, scoring higher than the second place submission by almost two points in label accuracy and over one point in FEVER score.",
}
@article{pi2022logigan,
  title={LogiGAN: Learning Logical Reasoning via Adversarial Pre-training},
  author={Pi, Xinyu and Zhong, Wanjun and Gao, Yan and Duan, Nan and Lou, Jian-Guang},
  journal={arXiv preprint arXiv:2205.08794},
  year={2022}
}

@inproceedings{wu-etal-2021-unified,
    title = "Unified Dual-view Cognitive Model for Interpretable Claim Verification",
    author = "Wu, Lianwei  and
      Rao, Yuan  and
      Lan, Yuqian  and
      Sun, Ling  and
      Qi, Zhaoyin",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.5",
    doi = "10.18653/v1/2021.acl-long.5",
    pages = "59--68",
    abstract = "Recent studies constructing direct interactions between the claim and each single user response (a comment or a relevant article) to capture evidence have shown remarkable success in interpretable claim verification. Owing to different single responses convey different cognition of individual users (i.e., audiences), the captured evidence belongs to the perspective of individual cognition. However, individuals{'} cognition of social things is not always able to truly reflect the objective. There may be one-sided or biased semantics in their opinions on a claim. The captured evidence correspondingly contains some unobjective and biased evidence fragments, deteriorating task performance. In this paper, we propose a Dual-view model based on the views of Collective and Individual Cognition (CICD) for interpretable claim verification. From the view of the collective cognition, we not only capture the word-level semantics based on individual users, but also focus on sentence-level semantics (i.e., the overall responses) among all users and adjust the proportion between them to generate global evidence. From the view of individual cognition, we select the top-$k$ articles with high degree of difference and interact with the claim to explore the local key evidence fragments. To weaken the bias of individual cognition-view evidence, we devise inconsistent loss to suppress the divergence between global and local evidence for strengthening the consistent shared evidence between the both. Experiments on three benchmark datasets confirm that CICD achieves state-of-the-art performance.",
}

@inproceedings{chen-etal-2020-logical,
    title = "Logical Natural Language Generation from Open-Domain Tables",
    author = "Chen, Wenhu  and
      Chen, Jianshu  and
      Su, Yu  and
      Chen, Zhiyu  and
      Wang, William Yang",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.708",
    doi = "10.18653/v1/2020.acl-main.708",
    pages = "7929--7942",
}

@inproceedings{zhong-etal-2020-logicalfactchecker,
    title = "{L}ogical{F}act{C}hecker: Leveraging Logical Operations for Fact Checking with Graph Module Network",
    author = "Zhong, Wanjun  and
      Tang, Duyu  and
      Feng, Zhangyin  and
      Duan, Nan  and
      Zhou, Ming  and
      Gong, Ming  and
      Shou, Linjun  and
      Jiang, Daxin  and
      Wang, Jiahai  and
      Yin, Jian",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.539",
    doi = "10.18653/v1/2020.acl-main.539",
    pages = "6053--6065",
}

@inproceedings{shu-etal-2021-logic,
    title = "Logic-Consistency Text Generation from Semantic Parses",
    author = "Shu, Chang  and
      Zhang, Yusen  and
      Dong, Xiangyu  and
      Shi, Peng  and
      Yu, Tao  and
      Zhang, Rui",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.388",
    doi = "10.18653/v1/2021.findings-acl.388",
    pages = "4414--4426",
}

@inproceedings{ciucci2012three,
  title={Three-valued logics for incomplete information and epistemic logic},
  author={Ciucci, Davide and Dubois, Didier},
  booktitle={European Workshop on Logics in Artificial Intelligence},
  pages={147--159},
  year={2012},
  organization={Springer}
}


@book{kleene1952introduction,
  author = {Stephen Cole Kleene},
  publisher = {Van Nostrand, New York},
  title = {Introduction to Metamathematics},
  year = 1952
}

@inproceedings{he-etal-2022-pre,
    title = "Can Pre-trained Language Models Interpret Similes as Smart as Human?",
    author = "He, Qianyu  and
      Cheng, Sijie  and
      Li, Zhixu  and
      Xie, Rui  and
      Xiao, Yanghua",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.543",
    doi = "10.18653/v1/2022.acl-long.543",
    pages = "7875--7887",
}

@inproceedings{wang-etal-2020-leveraging,
    title = "Leveraging Declarative Knowledge in Text and First-Order Logic for Fine-Grained Propaganda Detection",
    author = "Wang, Ruize  and
      Tang, Duyu  and
      Duan, Nan  and
      Zhong, Wanjun  and
      Wei, Zhongyu  and
      Huang, Xuanjing  and
      Jiang, Daxin  and
      Zhou, Ming",
    booktitle = "Proceedings of the 2020 Conference on EMNLP",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.320",
    doi = "10.18653/v1/2020.emnlp-main.320",
    pages = "3895--3903",
}

@inproceedings{kukich-1983-design,
    title = "Design of a Knowledge-Based Report Generator",
    author = "Kukich, Karen",
    booktitle = "21st Annual Meeting of the Association for Computational Linguistics",
    month = jun,
    year = "1983",
    address = "Cambridge, Massachusetts, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P83-1022",
    doi = "10.3115/981311.981340",
    pages = "145--150",
}
@article{Speer_Chin_Havasi_2017, title={ConceptNet 5.5: An Open Multilingual Graph of General Knowledge}, volume={31}, url={https://ojs.aaai.org/index.php/AAAI/article/view/11164}, DOI={10.1609/aaai.v31i1.11164}, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Speer, Robyn and Chin, Joshua and Havasi, Catherine}, year={2017}, month={Feb.} }
@book{mckeown1992text,
  title={Text generation},
  author={McKeown, Kathleen},
  year={1992},
  publisher={Cambridge University Press}
}
@inproceedings{liu-etal-2021-explainaboard,
    title = "{E}xplaina{B}oard: An Explainable Leaderboard for {NLP}",
    author = "Liu, Pengfei  and
      Fu, Jinlan  and
      Xiao, Yang  and
      Yuan, Weizhe  and
      Chang, Shuaichen  and
      Dai, Junqi  and
      Liu, Yixin  and
      Ye, Zihuiwen  and
      Neubig, Graham",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-demo.34",
    doi = "10.18653/v1/2021.acl-demo.34",
    pages = "280--289",
}
@inproceedings{10.5555/1785162.1785216,
author = {Auer, S\"{o}ren and Bizer, Christian and Kobilarov, Georgi and Lehmann, Jens and Cyganiak, Richard and Ives, Zachary},
title = {DBpedia: A Nucleus for a Web of Open Data},
year = {2007},
isbn = {3540762973},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {DBpedia is a community effort to extract structured information from Wikipedia and to make this information available on the Web. DBpedia allows you to ask sophisticated queries against datasets derived from Wikipedia and to link other datasets on the Web to Wikipedia data. We describe the extraction of the DBpedia datasets, and how the resulting information is published on the Web for human-andmachine-consumption. We describe some emerging applications from the DBpedia community and show how website authors can facilitate DBpedia content within their sites. Finally, we present the current status of interlinking DBpedia with other open datasets on the Web and outline how DBpedia could serve as a nucleus for an emerging Web of open data.},
booktitle = {Proceedings of the 6th International The Semantic Web and 2nd Asian Conference on Asian Semantic Web Conference},
pages = {722–735},
numpages = {14},
location = {Busan, Korea},
series = {ISWC'07/ASWC'07}
}

@article{vrandevcic2014wikidata,
  title={Wikidata: a free collaborative knowledgebase},
  author={Vrande{\v{c}}i{\'c}, Denny and Kr{\"o}tzsch, Markus},
  journal={Communications of the ACM},
  volume={57},
  number={10},
  pages={78--85},
  year={2014},
  publisher={ACM}
}
@inproceedings{liu-etal-2022-testing,
    title = "Testing the Ability of Language Models to Interpret Figurative Language",
    author = "Liu, Emmy  and
      Cui, Chenxuan  and
      Zheng, Kenneth  and
      Neubig, Graham",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.330",
    pages = "4437--4452",
}

@inproceedings{ye-etal-2020-coreferential,
    title = "{C}oreferential {R}easoning {L}earning for {L}anguage {R}epresentation",
    author = "Ye, Deming  and
      Lin, Yankai  and
      Du, Jiaju  and
      Liu, Zhenghao  and
      Li, Peng  and
      Sun, Maosong  and
      Liu, Zhiyuan",
    booktitle = "Proceedings of the 2020 Conference on EMNLP",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.582",
    doi = "10.18653/v1/2020.emnlp-main.582",
    pages = "7170--7186",
}

@inproceedings{shi-etal-2021-refine-imitate,
    title = "Refine and Imitate: Reducing Repetition and Inconsistency in Persuasion Dialogues via Reinforcement Learning and Human Demonstration",
    author = "Shi, Weiyan  and
      Li, Yu  and
      Sahay, Saurav  and
      Yu, Zhou",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.295",
    doi = "10.18653/v1/2021.findings-emnlp.295",
    pages = "3478--3492",
}

@misc{yuan2021bartscore,
      title={BARTScore: Evaluating Generated Text as Text Generation}, 
      author={Weizhe Yuan and Graham Neubig and Pengfei Liu},
      year={2021},
      eprint={2106.11520},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{guo2020incorporating,
  title={Incorporating bert into parallel sequence decoding with adapters},
  author={Guo, Junliang and Zhang, Zhirui and Xu, Linli and Wei, Hao-Ran and Chen, Boxing and Chen, Enhong},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={10843--10854},
  year={2020}
}
@article{alkhamissi2022review,
  title={A review on language models as knowledge bases},
  author={AlKhamissi, Badr and Li, Millicent and Celikyilmaz, Asli and Diab, Mona and Ghazvininejad, Marjan},
  journal={arXiv preprint arXiv:2204.06031},
  year={2022}
}
@inproceedings{gu-etal-2016-incorporating,
    title = "Incorporating Copying Mechanism in Sequence-to-Sequence Learning",
    author = "Gu, Jiatao  and
      Lu, Zhengdong  and
      Li, Hang  and
      Li, Victor O.K.",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-1154",
    doi = "10.18653/v1/P16-1154",
    pages = "1631--1640",
}
@inproceedings{logan-etal-2019-baracks,
    title = "{B}arack{'}s Wife Hillary: Using Knowledge Graphs for Fact-Aware Language Modeling",
    author = "Logan, Robert  and
      Liu, Nelson F.  and
      Peters, Matthew E.  and
      Gardner, Matt  and
      Singh, Sameer",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1598",
    doi = "10.18653/v1/P19-1598",
    pages = "5962--5971",
}

@article{kipf2016semi,
  title={Semi-supervised classification with graph convolutional networks},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1609.02907},
  year={2016}
}

@inproceedings{wu-etal-2020-diverse,
    title = "Diverse and Informative Dialogue Generation with Context-Specific Commonsense Knowledge Awareness",
    author = "Wu, Sixing  and
      Li, Ying  and
      Zhang, Dawei  and
      Zhou, Yang  and
      Wu, Zhonghai",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.515",
    doi = "10.18653/v1/2020.acl-main.515",
    pages = "5811--5820",
    abstract = "Generative dialogue systems tend to produce generic responses, which often leads to boring conversations. For alleviating this issue, Recent studies proposed to retrieve and introduce knowledge facts from knowledge graphs. While this paradigm works to a certain extent, it usually retrieves knowledge facts only based on the entity word itself, without considering the specific dialogue context. Thus, the introduction of the context-irrelevant knowledge facts can impact the quality of generations. To this end, this paper proposes a novel commonsense knowledge-aware dialogue generation model, ConKADI. We design a Felicitous Fact mechanism to help the model focus on the knowledge facts that are highly relevant to the context; furthermore, two techniques, Context-Knowledge Fusion and Flexible Mode Fusion are proposed to facilitate the integration of the knowledge in the ConKADI. We collect and build a large-scale Chinese dataset aligned with the commonsense knowledge for dialogue generation. Extensive evaluations over both an open-released English dataset and our Chinese dataset demonstrate that our approach ConKADI outperforms the state-of-the-art approach CCM, in most experiments.",
}


@inproceedings{NEURIPS2020_1091660f,
 author = {Tang, Kaihua and Huang, Jianqiang and Zhang, Hanwang},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {1513--1524},
 publisher = {Curran Associates, Inc.},
 title = {Long-Tailed Classification by Keeping the Good and Removing the Bad Momentum Causal Effect},
 url = {https://proceedings.neurips.cc/paper/2020/file/1091660f3dff84fd648efe31391c5524-Paper.pdf},
 volume = {33},
 year = {2020}
}

@InProceedings{10.1007/978-3-030-88480-2_28,
	author="Shen, Xinyao
	and Chen, Jiangjie
	and Xiao, Yanghua",
	editor="Wang, Lu
	and Feng, Yansong
	and Hong, Yu
	and He, Ruifang",
	title="Diversified Paraphrase Generation with Commonsense Knowledge Graph",
	booktitle="Natural Language Processing and Chinese Computing",
	year="2021",
	publisher="Springer International Publishing",
	address="Cham",
	pages="353--364",
	abstract="Paraphrases refer to text with different expressions conveying the same meaning, which is usually modeled as a sequence-to-sequence (Seq2Seq) learning problem. Traditional Seq2Seq models mainly concentrate on fidelity while ignoring the diversity of paraphrases. Although recent studies begin to focus on the diversity of generated paraphrases, they either adopt inflexible control mechanisms or restrict to synonyms and topic knowledge. In this paper, we propose KnowledgE-Enhanced Paraphraser (KEEP) for diversified paraphrase generation, which leverages a commonsense knowledge graph to explicitly enrich the expressions of paraphrases. Specifically, KEEP retrieves word-level and phrase-level knowledge from an external knowledge graph, and learns to choose more related ones using graph attention mechanism. Extensive experiments on benchmarks of paraphrase generation show the strengths especially in the diversity of our proposed model compared with several strong baselines.",
	isbn="978-3-030-88480-2"
}

@inproceedings{zhou-etal-2019-going,
    title = "{``}Going on a vacation{''} takes longer than {``}Going for a walk{''}: A Study of Temporal Commonsense Understanding",
    author = "Zhou, Ben  and
      Khashabi, Daniel  and
      Ning, Qiang  and
      Roth, Dan",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1332",
    doi = "10.18653/v1/D19-1332",
    pages = "3363--3369",
}
@inproceedings{maccartney2009extended,
    title = "An extended model of natural logic",
    author = "MacCartney, Bill  and
      Manning, Christopher D.",
    booktitle = "Proceedings of the Eight International Conference on Computational Semantics",
    month = jan,
    year = "2009",
    address = "Tilburg, The Netherlands",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W09-3714",
    pages = "140--156",
}

@inproceedings{niu2021counterfactual,
  title={Counterfactual vqa: A cause-effect look at language bias},
  author={Niu, Yulei and Tang, Kaihua and Zhang, Hanwang and Lu, Zhiwu and Hua, Xian-Sheng and Wen, Ji-Rong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12700--12710},
  year={2021}
}

@inproceedings{shen2019mixture,
  title={Mixture models for diverse machine translation: Tricks of the trade},
  author={Shen, Tianxiao and Ott, Myle and Auli, Michael and Ranzato, Marc’Aurelio},
  booktitle={International conference on machine learning},
  pages={5719--5728},
  year={2019},
  organization={PMLR}
}

@inproceedings{lewis-etal-2020-bart,
    title = "{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
    author = "Lewis, Mike  and
      Liu, Yinhan  and
      Goyal, Naman  and
      Ghazvininejad, Marjan  and
      Mohamed, Abdelrahman  and
      Levy, Omer  and
      Stoyanov, Veselin  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.703",
    doi = "10.18653/v1/2020.acl-main.703",
    pages = "7871--7880",
}
@article{Bisk_Zellers_Le_bras_Gao_Choi_2020, title={PIQA: Reasoning about Physical Commonsense in Natural Language}, volume={34}, url={https://ojs.aaai.org/index.php/AAAI/article/view/6239}, DOI={10.1609/aaai.v34i05.6239}, number={05}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Bisk, Yonatan and Zellers, Rowan and Le bras, Ronan and Gao, Jianfeng and Choi, Yejin}, year={2020}, month={Apr.}, pages={7432-7439} }
@inproceedings{sap-etal-2019-social,
    title = "Social {IQ}a: Commonsense Reasoning about Social Interactions",
    author = "Sap, Maarten  and
      Rashkin, Hannah  and
      Chen, Derek  and
      Le Bras, Ronan  and
      Choi, Yejin",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1454",
    doi = "10.18653/v1/D19-1454",
    pages = "4463--4473",
    abstract = "We introduce Social IQa, the first large-scale benchmark for commonsense reasoning about social situations. Social IQa contains 38,000 multiple choice questions for probing emotional and social intelligence in a variety of everyday situations (e.g., Q: {``}Jordan wanted to tell Tracy a secret, so Jordan leaned towards Tracy. Why did Jordan do this?{''} A: {``}Make sure no one else could hear{''}). Through crowdsourcing, we collect commonsense questions along with correct and incorrect answers about social interactions, using a new framework that mitigates stylistic artifacts in incorrect answers by asking workers to provide the right answer to a different but related question. Empirical results show that our benchmark is challenging for existing question-answering models based on pretrained language models, compared to human performance ({\textgreater}20{\%} gap). Notably, we further establish Social IQa as a resource for transfer learning of commonsense knowledge, achieving state-of-the-art performance on multiple commonsense reasoning tasks (Winograd Schemas, COPA).",
}
@inproceedings{wang-etal-2020-heterogeneous,
    title = "Heterogeneous Graph Neural Networks for Extractive Document Summarization",
    author = "Wang, Danqing  and
      Liu, Pengfei  and
      Zheng, Yining  and
      Qiu, Xipeng  and
      Huang, Xuanjing",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.553",
    doi = "10.18653/v1/2020.acl-main.553",
    pages = "6209--6219",
}
@inproceedings{huang-etal-2020-knowledge,
    title = "Knowledge Graph-Augmented Abstractive Summarization with Semantic-Driven Cloze Reward",
    author = "Huang, Luyang  and
      Wu, Lingfei  and
      Wang, Lu",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.457",
    doi = "10.18653/v1/2020.acl-main.457",
    pages = "5094--5107",
}
@inproceedings{wang-etal-2019-paperrobot,
    title = "{P}aper{R}obot: Incremental Draft Generation of Scientific Ideas",
    author = "Wang, Qingyun  and
      Huang, Lifu  and
      Jiang, Zhiying  and
      Knight, Kevin  and
      Ji, Heng  and
      Bansal, Mohit  and
      Luan, Yi",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1191",
    doi = "10.18653/v1/P19-1191",
    pages = "1980--1991",
}
@inproceedings{10.1145/3488560.3498431,
    author = {Shen, Xinyao and Chen, Jiangjie and Chen, Jiaze and Zeng, Chun and Xiao, Yanghua},
    title = {Diversified Query Generation Guided by Knowledge Graph},
    year = {2022},
    isbn = {9781450391320},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3488560.3498431},
    doi = {10.1145/3488560.3498431},
    abstract = {Relevant articles recommendation plays an important role in online news platforms. Directly displaying recalled articles by a search engine lacks a deep understanding of the article contents. Generating clickable queries, on the other hand, summarizes an article in various aspects, which can be henceforth utilized to better connect relevant articles. Most existing approaches for generating article queries, however, do not consider the diversity of queries or whether they are appealing enough, which are essential for boosting user experience and platform drainage. To this end, we propose a Knowledge-Enhanced Diversified QuerY Generator (KEDY), which leverages an external knowledge graph (KG) as guidance. We diversify the query generation with the information of semantic neighbors of the entities in articles. We further constrain the diversification process with entity popularity knowledge to build appealing queries that users may be more interested in. The information within KG is propagated towards more popular entities with popularity-guided graph attention. We collect a news-query dataset from the search logs of a real-world search engine. Extensive experiments demonstrate our proposed KEDY can generate more diversified and insightful related queries than several strong baselines.},
    booktitle = {Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining},
    pages = {897–907},
    numpages = {11},
    keywords = {knowledge graph, query generation, information retrieval},
    location = {Virtual Event, AZ, USA},
    series = {WSDM '22}
}


@inproceedings{hanselowski-etal-2018-ukp,
    title = "{UKP}-Athene: Multi-Sentence Textual Entailment for Claim Verification",
    author = "Hanselowski, Andreas  and
      Zhang, Hao  and
      Li, Zile  and
      Sorokin, Daniil  and
      Schiller, Benjamin  and
      Schulz, Claudia  and
      Gurevych, Iryna",
    booktitle = "Proceedings of the First Workshop on Fact Extraction and {VER}ification ({FEVER})",
    month = nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-5516",
    doi = "10.18653/v1/W18-5516",
    pages = "103--108",
}

@inproceedings{NEURIPS2020_6b493230,
 author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K\"{u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt\"{a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {9459--9474},
 publisher = {Curran Associates, Inc.},
 title = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
 url = {https://proceedings.neurips.cc/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf},
 volume = {33},
 year = {2020}
}



@inproceedings{bender2020climbingtn,
    title = "Climbing towards {NLU}: {On} Meaning, Form, and Understanding in the Age of Data",
    author = "Bender, Emily M.  and
      Koller, Alexander",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.463",
    doi = "10.18653/v1/2020.acl-main.463",
    pages = "5185--5198",
}

@inproceedings{zhong2020reasoning,
    title = "Reasoning Over Semantic-Level Graph for Fact Checking",
    author = "Zhong, Wanjun  and
      Xu, Jingjing  and
      Tang, Duyu  and
      Xu, Zenan  and
      Duan, Nan  and
      Zhou, Ming  and
      Wang, Jiahai  and
      Yin, Jian",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.549",
    doi = "10.18653/v1/2020.acl-main.549",
    pages = "6170--6180",
}


@InProceedings{pmlr-v119-guu20a,
  title = 	 {Retrieval Augmented Language Model Pre-Training},
  author =       {Guu, Kelvin and Lee, Kenton and Tung, Zora and Pasupat, Panupong and Chang, Mingwei},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {3929--3938},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/guu20a/guu20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/guu20a.html},
  abstract = 	 {Language model pre-training has been shown to capture a surprising amount of world knowledge, crucial for NLP tasks such as question answering. However, this knowledge is stored implicitly in the parameters of a neural network, requiring ever-larger networks to cover more facts. To capture knowledge in a more modular and interpretable way, we augment language model pre-training with a latent knowledge retriever, which allows the model to retrieve and attend over documents from a large corpus such as Wikipedia, used during pre-training, fine-tuning and inference. For the first time, we show how to pre-train such a knowledge retriever in an unsupervised manner, using masked language modeling as the learning signal and backpropagating through a retrieval step that considers millions of documents. We demonstrate the effectiveness of Retrieval-Augmented Language Model pre-training (REALM) by fine-tuning on the challenging task of Open-domain Question Answering (Open-QA). We compare against state-of-the-art models for both explicit and implicit knowledge storage on three popular Open-QA benchmarks, and find that we outperform all previous methods by a significant margin (4-16% absolute accuracy), while also providing qualitative benefits such as interpretability and modularity.}
}



@inproceedings{kang2018adventureat,
    title = "{A}dv{E}ntu{R}e: Adversarial Training for Textual Entailment with Knowledge-Guided Examples",
    author = "Kang, Dongyeop  and
      Khot, Tushar  and
      Sabharwal, Ashish  and
      Hovy, Eduard",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-1225",
    doi = "10.18653/v1/P18-1225",
    pages = "2418--2428",
}


@inproceedings{Zellers2019DefendingAN,
  title={Defending Against Neural Fake News},
  author={Rowan Zellers and Ari Holtzman and Hannah Rashkin and Yonatan Bisk and Ali Farhadi and F. Roesner and Yejin Choi},
  booktitle={NeurIPS},
  year={2019}
}

@inproceedings{yoneda2018uclmr,
    title = "{UCL} Machine Reading Group: Four Factor Framework For Fact Finding ({H}exa{F})",
    author = "Yoneda, Takuma  and
      Mitchell, Jeff  and
      Welbl, Johannes  and
      Stenetorp, Pontus  and
      Riedel, Sebastian",
    booktitle = "Proceedings of the First Workshop on Fact Extraction and {VER}ification ({FEVER})",
    month = nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-5515",
    doi = "10.18653/v1/W18-5515",
    pages = "97--102",
}

@inproceedings{lin-etal-2020-commongen,
    title = "{C}ommon{G}en: A Constrained Text Generation Challenge for Generative Commonsense Reasoning",
    author = "Lin, Bill Yuchen  and
      Zhou, Wangchunshu  and
      Shen, Ming  and
      Zhou, Pei  and
      Bhagavatula, Chandra  and
      Choi, Yejin  and
      Ren, Xiang",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.165",
    doi = "10.18653/v1/2020.findings-emnlp.165",
    pages = "1823--1840",
}

@article{chakrabarty-etal-2022-rocket,
    title = "It{'}s not Rocket Science: Interpreting Figurative Language in Narratives",
    author = "Chakrabarty, Tuhin  and
      Choi, Yejin  and
      Shwartz, Vered",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "10",
    year = "2022",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2022.tacl-1.34",
    doi = "10.1162/tacl_a_00478",
    pages = "589--606",
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@article{zhang2022survey,
  title={A survey of controllable text generation using transformer-based pre-trained language models},
  author={Zhang, Hanqing and Song, Haolin and Li, Shaoyu and Zhou, Ming and Song, Dawei},
  journal={arXiv preprint arXiv:2201.05337},
  year={2022}
}

@inproceedings{Nie2019CombiningFE,
  title={Combining Fact Extraction and Verification with Neural Semantic Matching Networks},
  author={Yixin Nie and H. Chen and Mohit Bansal},
  booktitle={AAAI},
  year={2019}
}

@inproceedings{samarinas-etal-2021-improving,
    title = "Improving Evidence Retrieval for Automated Explainable Fact-Checking",
    author = "Samarinas, Chris  and
      Hsu, Wynne  and
      Lee, Mong Li",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-demos.10",
    doi = "10.18653/v1/2021.naacl-demos.10",
    pages = "84--91",
    abstract = "Automated fact-checking on a large-scale is a challenging task that has not been studied systematically until recently. Large noisy document collections like the web or news articles make the task more difficult. We describe a three-stage automated fact-checking system, named Quin+, using evidence retrieval and selection methods. We demonstrate that using dense passage representations leads to much higher evidence recall in a noisy setting. We also propose two sentence selection approaches, an embedding-based selection using a dense retrieval model, and a sequence labeling approach for context-aware selection. Quin+ is able to verify open-domain claims using results from web search engines.",
}
@inproceedings{DBLP:journals/corr/BahdanauCB14,
  author    = {Dzmitry Bahdanau and
               Kyunghyun Cho and
               Yoshua Bengio},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Neural Machine Translation by Jointly Learning to Align and Translate},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1409.0473},
  timestamp = {Wed, 17 Jul 2019 10:40:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/BahdanauCB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Liu_Wan_He_Peng_Yu_2021, title={KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense Reasoning}, volume={35}, url={https://ojs.aaai.org/index.php/AAAI/article/view/16796}, abstractNote={Generative commonsense reasoning which aims to empower machines to generate sentences with the capacity of reasoning over a set of concepts is a critical bottleneck for text generation. Even the state-of-the-art pre-trained language generation models struggle at this task and often produce implausible and anomalous sentences. One reason is that they rarely consider incorporating the knowledge graph which can provide rich relational information among the commonsense concepts. To promote the ability of commonsense reasoning for text generation, we propose a novel knowledge graph augmented pre-trained language generation model KG-BART, which encompasses the complex relations of concepts through the knowledge graph and produces more logical and natural sentences as output. Moreover, KG-BART can leverage the graph attention to aggregate the rich concept semantics that enhances the model generalization on unseen concept sets. Experiments on benchmark CommonGen dataset verify the effectiveness of our proposed approach by comparing with several strong pre-trained language generation models, particularly KG-BART outperforms BART by 5.80, 4.60, in terms of BLEU-3, 4. Moreover, we also show that the generated context by our model can work as background scenarios to benefit downstream commonsense QA tasks.}, number={7}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Liu, Ye and Wan, Yao and He, Lifang and Peng, Hao and Yu, Philip S.}, year={2021}, month={May}, pages={6418-6425} }

@inproceedings{susanto-etal-2020-lexically,
    title = "Lexically Constrained Neural Machine Translation with {L}evenshtein Transformer",
    author = "Susanto, Raymond Hendy  and
      Chollampatt, Shamil  and
      Tan, Liling",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.325",
    doi = "10.18653/v1/2020.acl-main.325",
    pages = "3536--3543",
    abstract = "This paper proposes a simple and effective algorithm for incorporating lexical constraints in neural machine translation. Previous work either required re-training existing models with the lexical constraints or incorporating them during beam search decoding with significantly higher computational overheads. Leveraging the flexibility and speed of a recently proposed Levenshtein Transformer model (Gu et al., 2019), our method injects terminology constraints at inference time without any impact on decoding speed. Our method does not require any modification to the training procedure and can be easily applied at runtime with custom dictionaries. Experiments on English-German WMT datasets show that our approach improves an unconstrained baseline and previous approaches.",
}
@article{10.1162/tacl_a_00368,
    author = {Xu, Weijia and Carpuat, Marine},
    title = "{EDITOR: An Edit-Based Transformer with Repositioning for Neural Machine Translation with Soft Lexical Constraints}",
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {9},
    pages = {311-328},
    year = {2021},
    month = {03},
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00368},
    url = {https://doi.org/10.1162/tacl\_a\_00368},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00368/1923848/tacl\_a\_00368.pdf},
}

@inproceedings{lu-etal-2021-neurologic,
    title = "{N}euro{L}ogic Decoding: (Un)supervised Neural Text Generation with Predicate Logic Constraints",
    author = "Lu, Ximing  and
      West, Peter  and
      Zellers, Rowan  and
      Le Bras, Ronan  and
      Bhagavatula, Chandra  and
      Choi, Yejin",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.339",
    doi = "10.18653/v1/2021.naacl-main.339",
    pages = "4288--4299",
}

@inproceedings{post-vilar-2018-fast,
    title = "Fast Lexically Constrained Decoding with Dynamic Beam Allocation for Neural Machine Translation",
    author = "Post, Matt  and
      Vilar, David",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1119",
    doi = "10.18653/v1/N18-1119",
    pages = "1314--1324",
}
@inproceedings{hokamp-liu-2017-lexically,
    title = "Lexically Constrained Decoding for Sequence Generation Using Grid Beam Search",
    author = "Hokamp, Chris  and
      Liu, Qun",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1141",
    doi = "10.18653/v1/P17-1141",
    pages = "1535--1546",
}
@inproceedings{
Dathathri2020Plug,
title={Plug and Play Language Models: A Simple Approach to Controlled Text Generation},
author={Sumanth Dathathri and Andrea Madotto and Janice Lan and Jane Hung and Eric Frank and Piero Molino and Jason Yosinski and Rosanne Liu},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=H1edEyBKDS}
}
@inproceedings{
liu2022knowledge,
title={Knowledge Infused Decoding},
author={Ruibo Liu and Guoqing Zheng and Shashank Gupta and Radhika Gaonkar and Chongyang Gao and Soroush Vosoughi and Milad Shokouhi and Ahmed Hassan Awadallah},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=upnDJ7itech}
}
@inproceedings{betz-etal-2021-critical,
    title = "Critical Thinking for Language Models",
    author = "Betz, Gregor  and
      Voigt, Christian  and
      Richardson, Kyle",
    booktitle = "Proceedings of the 14th International Conference on Computational Semantics (IWCS)",
    month = jun,
    year = "2021",
    address = "Groningen, The Netherlands (online)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.iwcs-1.7",
    pages = "63--75",
}
@inproceedings{petroni-etal-2021-kilt,
    title = "{KILT}: a Benchmark for Knowledge Intensive Language Tasks",
    author = {Petroni, Fabio  and
      Piktus, Aleksandra  and
      Fan, Angela  and
      Lewis, Patrick  and
      Yazdani, Majid  and
      De Cao, Nicola  and
      Thorne, James  and
      Jernite, Yacine  and
      Karpukhin, Vladimir  and
      Maillard, Jean  and
      Plachouras, Vassilis  and
      Rockt{\"a}schel, Tim  and
      Riedel, Sebastian},
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.200",
    doi = "10.18653/v1/2021.naacl-main.200",
    pages = "2523--2544",
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
}

@article{sun2019ernie,
  title={Ernie: Enhanced representation through knowledge integration},
  author={Sun, Yu and Wang, Shuohuan and Li, Yukun and Feng, Shikun and Chen, Xuyi and Zhang, Han and Tian, Xin and Zhu, Danxiang and Tian, Hao and Wu, Hua},
  journal={arXiv preprint arXiv:1904.09223},
  year={2019}
}

@inproceedings{
    he2021deberta,
    title={DeBERTa: Decoding-enhanced BERT with Disentangled Attention},
    author={Pengcheng He and Xiaodong Liu and Jianfeng Gao and Weizhu Chen},
    booktitle={International Conference on Learning Representations},
    year={2021},
    url={https://openreview.net/forum?id=XPZIaotutsD}
}

@inproceedings{lee2020languagema,
    title = "Language Models as Fact Checkers?",
    author = "Lee, Nayeon  and
      Li, Belinda Z.  and
      Wang, Sinong  and
      Yih, Wen-tau  and
      Ma, Hao  and
      Khabsa, Madian",
    booktitle = "Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER)",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.fever-1.5",
    doi = "10.18653/v1/2020.fever-1.5",
    pages = "36--41",
}

@article{10.1145/3448250, 
author = {Bengio, Yoshua and Lecun, Yann and Hinton, Geoffrey}, title = {Deep Learning for AI}, year = {2021}, issue_date = {July 2021}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, volume = {64}, number = {7}, issn = {0001-0782}, url = {https://doi.org/10.1145/3448250}, doi = {10.1145/3448250}, abstract = {How can neural networks learn the rich internal representations required for difficult tasks such as recognizing objects or understanding language?}, journal = {Commun. ACM}, month = jun, pages = {58–65}, numpages = {8} }

@inproceedings{sellam-etal-2020-bleurt,
    title = "{BLEURT}: Learning Robust Metrics for Text Generation",
    author = "Sellam, Thibault  and
      Das, Dipanjan  and
      Parikh, Ankur",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.704",
    doi = "10.18653/v1/2020.acl-main.704",
    pages = "7881--7892",
}


@article{shao2021cpt,
  title={CPT: A Pre-Trained Unbalanced Transformer for Both Chinese Language Understanding and Generation}, 
  author={Yunfan Shao and Zhichao Geng and Yitao Liu and Junqi Dai and Fei Yang and Li Zhe and Hujun Bao and Xipeng Qiu},
  journal={arXiv preprint arXiv:2109.05729},
  year={2021}
}

@inproceedings{bender2020climbingtn,
    title = "Climbing towards {NLU}: {On} Meaning, Form, and Understanding in the Age of Data",
    author = "Bender, Emily M.  and
      Koller, Alexander",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.463",
    doi = "10.18653/v1/2020.acl-main.463",
    pages = "5185--5198",
}

@misc{zhang2021mengzi,
      title={Mengzi: Towards Lightweight yet Ingenious Pre-trained Models for Chinese}, 
      author={Zhuosheng Zhang and Hanqing Zhang and Keming Chen and Yuhang Guo and Jingyun Hua and Yulong Wang and Ming Zhou},
      year={2021},
      eprint={2110.06696},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{jhamtani-clark-2020-learning,
    title = "Learning to Explain: Datasets and Models for Identifying Valid Reasoning Chains in Multihop Question-Answering",
    author = "Jhamtani, Harsh  and
      Clark, Peter",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.10",
    doi = "10.18653/v1/2020.emnlp-main.10",
    pages = "137--150",
}

@article{gentner2012analogical,
  title={Analogical reasoning},
  author={Gentner, Dedre and Smith, Linsey},
  journal={Encyclopedia of human behavior},
  volume={2},
  pages={130--136},
  year={2012}
}

@inproceedings{jiang2019evaluatingbf,
    title = "Evaluating {BERT} for natural language inference: A case study on the {C}ommitment{B}ank",
    author = "Jiang, Nanjiang  and
      de Marneffe, Marie-Catherine",
    booktitle = "Proceedings of the 2019 Conference on EMNLP-IJCNLP",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1630",
    doi = "10.18653/v1/D19-1630",
    pages = "6086--6091",
}

@article{celikyilmaz2020evaluation,
  title={Evaluation of text generation: A survey},
  author={Celikyilmaz, Asli and Clark, Elizabeth and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2006.14799},
  year={2020}
}

@inproceedings{
    Zhang2020BERTScore,
    title={BERTScore: Evaluating Text Generation with BERT},
    author={Tianyi Zhang and Varsha Kishore and Felix Wu and Kilian Q. Weinberger and Yoav Artzi},
    booktitle={International Conference on Learning Representations},
    year={2020},
    url={https://openreview.net/forum?id=SkeHuCVFDr}
}

@inproceedings{tan-etal-2021-gcrc,
    title = "{GCRC}: A New Challenging {MRC} Dataset from {G}aokao {C}hinese for Explainable Evaluation",
    author = "Tan, Hongye  and
      Wang, Xiaoyue  and
      Ji, Yu  and
      Li, Ru  and
      Li, Xiaoli  and
      Hu, Zhiwei  and
      Zhao, Yunxiao  and
      Han, Xiaoqi",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.113",
    doi = "10.18653/v1/2021.findings-acl.113",
    pages = "1319--1330",
}

@inproceedings{zhang2020semanticsawarebf,
  author    = {Zhuosheng Zhang and
               Yuwei Wu and
               Hai Zhao and
               Zuchao Li and
               Shuailiang Zhang and
               Xi Zhou and
               Xiang Zhou},
  title     = {Semantics-Aware {BERT} for Language Understanding},
  booktitle = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}
               2020, The Thirty-Second Innovative Applications of Artificial Intelligence
               Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational
               Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,
               February 7-12, 2020},
  pages     = {9628--9635},
  publisher = {{AAAI} Press},
  year      = {2020},
  url       = {https://aaai.org/ojs/index.php/AAAI/article/view/6510},
  timestamp = {Fri, 04 Sep 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/aaai/0001WZLZZZ20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{anderson2016spice,
  title={Spice: Semantic propositional image caption evaluation},
  author={Anderson, Peter and Fernando, Basura and Johnson, Mark and Gould, Stephen},
  booktitle={European conference on computer vision},
  pages={382--398},
  year={2016},
  organization={Springer}
}
@article{goel1997design,
  title={Design, analogy, and creativity},
  author={Goel, Ashok K},
  journal={IEEE expert},
  volume={12},
  number={3},
  pages={62--70},
  year={1997},
  publisher={IEEE}
}


@article{thagard1992analogy,
  title={Analogy, explanation, and education},
  author={Thagard, Paul},
  journal={Journal of Research in science Teaching},
  volume={29},
  number={6},
  pages={537--544},
  year={1992},
  publisher={Wiley Online Library}
}

@inproceedings{Sun2020ERNIE2A,
  title={ERNIE 2.0: A Continual Pre-training Framework for Language Understanding},
  author={Y. Sun and Shuohuan Wang and Yukun Li and Shikun Feng and Hao Tian and H. Wu and Haifeng Wang},
  booktitle={AAAI},
  year={2020}
}


@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}

@inproceedings{
Schulz2020Restricting,
title={Restricting the Flow: Information Bottlenecks for Attribution},
author={Karl Schulz and Leon Sixt and Federico Tombari and Tim Landgraf},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=S1xWh1rYwB}
}

@inproceedings{yin-ordonez-2017-obj2text,
    title = "{O}bj2{T}ext: Generating Visually Descriptive Language from Object Layouts",
    author = "Yin, Xuwang  and
      Ordonez, Vicente",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1017",
    doi = "10.18653/v1/D17-1017",
    pages = "177--187",
}

@inproceedings{gupta-etal-2022-mitigating,
    title = "Mitigating Gender Bias in Distilled Language Models via Counterfactual Role Reversal",
    author = "Gupta, Umang  and
      Dhamala, Jwala  and
      Kumar, Varun  and
      Verma, Apurv  and
      Pruksachatkun, Yada  and
      Krishna, Satyapriya  and
      Gupta, Rahul  and
      Chang, Kai-Wei  and
      Ver Steeg, Greg  and
      Galstyan, Aram",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.55",
    doi = "10.18653/v1/2022.findings-acl.55",
    pages = "658--678",
}

@inproceedings{xia-etal-2020-demoting,
    title = "Demoting Racial Bias in Hate Speech Detection",
    author = "Xia, Mengzhou  and
      Field, Anjalie  and
      Tsvetkov, Yulia",
    booktitle = "Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.socialnlp-1.2",
    doi = "10.18653/v1/2020.socialnlp-1.2",
    pages = "7--14",
}

@inproceedings{liu-etal-2020-gender,
    title = "Does Gender Matter? Towards Fairness in Dialogue Systems",
    author = "Liu, Haochen  and
      Dacon, Jamell  and
      Fan, Wenqi  and
      Liu, Hui  and
      Liu, Zitao  and
      Tang, Jiliang",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2020.coling-main.390",
    doi = "10.18653/v1/2020.coling-main.390",
    pages = "4403--4416",
}

@inproceedings{DBLP:conf/ai/Shi0Z21,
  author    = {Zhan Shi and
               Hui Liu and
               Xiaodan Zhu},
  editor    = {Luiza Antonie and
               Pooya Moradian Zadeh},
  title     = {Descriptive Image Captioning with Salient Retrieval Priors},
  booktitle = {Proceedings of the 34th Canadian Conference on Artificial Intelligence,
               Canadian {AI} 2021, online, May 2021},
  publisher = {Canadian Artificial Intelligence Association},
  year      = {2021},
  url       = {https://caiac.pubpub.org/pub/zllzroe5},
  timestamp = {Tue, 19 Apr 2022 16:07:09 +0200},
  biburl    = {https://dblp.org/rec/conf/ai/Shi0Z21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{10.5555/3305890.3306024,
author = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
title = {Axiomatic Attribution for Deep Networks},
year = {2017},
publisher = {JMLR.org},
abstract = {We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms— Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisfied by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modification to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.},
booktitle = {Proceedings of the 34th International Conference on Machine Learning - Volume 70},
pages = {3319–3328},
numpages = {10},
location = {Sydney, NSW, Australia},
series = {ICML'17}
}

@inproceedings{lime,
  author    = {Marco Tulio Ribeiro and
               Sameer Singh and
               Carlos Guestrin},
  title     = {"Why Should {I} Trust You?": Explaining the Predictions of Any Classifier},
  booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} International Conference on
               Knowledge Discovery and Data Mining, San Francisco, CA, USA, August
               13-17, 2016},
  pages     = {1135--1144},
  year      = {2016},
}

@inproceedings{NEURIPS2021_d0f5edad,
 author = {Hu, Zhiting and Li, Li Erran},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {24941--24955},
 publisher = {Curran Associates, Inc.},
 title = {A Causal Lens for Controllable Text Generation},
 url = {https://proceedings.neurips.cc/paper/2021/file/d0f5edad9ac19abed9e235c0fe0aa59f-Paper.pdf},
 volume = {34},
 year = {2021}
}


@article{li2018vqae,
  title={VQA-E: Explaining, Elaborating, and Enhancing Your Answers for Visual Questions},
  author={Li, Qing and Tao, Qingyi and Joty, Shafiq and Cai, Jianfei and Luo, Jiebo},
  journal={ECCV},
  year={2018}
}
@inproceedings{wiegreffe-marasovic-2021-review,
 author = {Wiegreffe, Sarah and Marasovic, Ana},
 booktitle = {Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks},
 editor = {J. Vanschoren and S. Yeung},
 pages = {},
 title = {Teach Me to Explain: A Review of Datasets for Explainable Natural Language Processing},
 url = {https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/698d51a19d8a121ce581499d7b701668-Paper-round1.pdf},
 volume = {1},
 year = {2021}
}

@incollection{minnameier2010abduction,
  title={Abduction, Induction, and Analogy},
  author={Minnameier, Gerhard},
  booktitle={Model-based reasoning in science and technology},
  pages={107--119},
  year={2010},
  publisher={Springer}
}

@book{johnson2006we,
  title={How we reason},
  author={Johnson-Laird, Philip Nicholas},
  year={2006},
  publisher={Oxford University Press, USA}
}

@article{peirce1896lessons,
  title={Lessons from the history of science},
  author={Peirce, Charles S},
  journal={C. Hartshorne},
  volume={660},
  year={1896}
}

@article{gick1983schema,
  title={Schema induction and analogical transfer},
  author={Gick, Mary L and Holyoak, Keith J},
  journal={Cognitive psychology},
  volume={15},
  number={1},
  pages={1--38},
  year={1983},
  publisher={Elsevier}
}

@article{gentner1983structure,
  title={Structure-mapping: A theoretical framework for analogy},
  author={Gentner, Dedre},
  journal={Cognitive science},
  volume={7},
  number={2},
  pages={155--170},
  year={1983},
  publisher={Elsevier}
}

@article{bartha2013analogy,
  title={Analogy and analogical reasoning},
  author={Bartha, Paul},
  year={2013}
}


@inproceedings{nguyen2015deep,
  title={Deep neural networks are easily fooled: High confidence predictions for unrecognizable images},
  author={Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={427--436},
  year={2015}
}


@article{sourek2015lifted,
  title={Lifted relational neural networks},
  author={Sourek, Gustav and Aschenbrenner, Vojtech and Zelezny, Filip and Kuzelka, Ondrej},
  journal={arXiv preprint arXiv:1508.05128},
  year={2015}
}

@inproceedings{cui-etal-2020-revisiting,
    title = "Revisiting Pre-Trained Models for {C}hinese Natural Language Processing",
    author = "Cui, Yiming  and
      Che, Wanxiang  and
      Liu, Ting  and
      Qin, Bing  and
      Wang, Shijin  and
      Hu, Guoping",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.findings-emnlp.58",
    pages = "657--668",
}

@inproceedings{ijcai2020-501,
  title     = {LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning},
  author    = {Liu, Jian and Cui, Leyang and Liu, Hanmeng and Huang, Dandan and Wang, Yile and Zhang, Yue},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Christian Bessiere},
  pages     = {3622--3628},
  year      = {2020},
  month     = {7},
  note      = {Main track},
  doi       = {10.24963/ijcai.2020/501},
  url       = {https://doi.org/10.24963/ijcai.2020/501},
}



@inproceedings{dong2018neural,
  author    = {Honghua Dong and
               Jiayuan Mao and
               Tian Lin and
               Chong Wang and
               Lihong Li and
               Denny Zhou},
  title     = {Neural Logic Machines},
  booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
               New Orleans, LA, USA, May 6-9, 2019},
  publisher = {OpenReview.net},
  year      = {2019},
  url       = {https://openreview.net/forum?id=B1xY-hRctX},
  timestamp = {Thu, 25 Jul 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/DongMLWLZ19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{manhaeve2018deepproblog,
  title={Deepproblog: Neural probabilistic logic programming},
  author={Manhaeve, Robin and Dumancic, Sebastijan and Kimmig, Angelika and Demeester, Thomas and De Raedt, Luc},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3749--3759},
  year={2018}
}

@inproceedings{deyoung-etal-2020-eraser,
    title = "{ERASER}: {A} Benchmark to Evaluate Rationalized {NLP} Models",
    author = "DeYoung, Jay  and
      Jain, Sarthak  and
      Rajani, Nazneen Fatema  and
      Lehman, Eric  and
      Xiong, Caiming  and
      Socher, Richard  and
      Wallace, Byron C.",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.408",
    doi = "10.18653/v1/2020.acl-main.408",
    pages = "4443--4458",
}


@article{lamb2020graph,
  title={Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective},
  author={Lamb, Luis and Garcez, Artur and Gori, Marco and Prates, Marcelo and Avelar, Pedro and Vardi, Moshe},
  journal={arXiv preprint arXiv:2003.00330},
  year={2020}
}


@inproceedings{qu2019probabilistic,
  title={Probabilistic logic neural networks for reasoning},
  author={Qu, Meng and Tang, Jian},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7712--7722},
  year={2019}
}


@inproceedings{harsha2020probabilistic,
  title={Probabilistic Logic Graph Attention Networks for Reasoning},
  author={Harsha Vardhan, L Vivek and Jia, Guo and Kok, Stanley},
  booktitle={Companion Proceedings of the Web Conference 2020},
  pages={669--673},
  year={2020}
}


@inproceedings{zhang2020efficient,
  author    = {Yuyu Zhang and
               Xinshi Chen and
               Yuan Yang and
               Arun Ramamurthy and
               Bo Li and
               Yuan Qi and
               Le Song},
  title     = {Efficient Probabilistic Logic Reasoning with Graph Neural Networks},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020},
  url       = {https://openreview.net/forum?id=rJg76kStwH},
  timestamp = {Thu, 03 Dec 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/conf/iclr/ZhangCYRLQS20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{rajani-etal-2019-explain,
    title = "Explain Yourself! Leveraging Language Models for Commonsense Reasoning",
    author = "Rajani, Nazneen Fatema  and
      McCann, Bryan  and
      Xiong, Caiming  and
      Socher, Richard",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1487",
    doi = "10.18653/v1/P19-1487",
    pages = "4932--4942",
}

@inproceedings{camburu-etal-2020-make,
    title = "Make Up Your Mind! Adversarial Generation of Inconsistent Natural Language Explanations",
    author = "Camburu, Oana-Maria  and
      Shillingford, Brendan  and
      Minervini, Pasquale  and
      Lukasiewicz, Thomas  and
      Blunsom, Phil",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.382",
    doi = "10.18653/v1/2020.acl-main.382",
    pages = "4157--4165",
    abstract = "To increase trust in artificial intelligence systems, a promising research direction consists of designing neural models capable of generating natural language explanations for their predictions. In this work, we show that such models are nonetheless prone to generating mutually inconsistent explanations, such as {''}Because there is a dog in the image.{''} and {''}Because there is no dog in the [same] image.{''}, exposing flaws in either the decision-making process of the model or in the generation of the explanations. We introduce a simple yet effective adversarial framework for sanity checking models against the generation of inconsistent natural language explanations. Moreover, as part of the framework, we address the problem of adversarial attacks with full target sequences, a scenario that was not previously addressed in sequence-to-sequence attacks. Finally, we apply our framework on a state-of-the-art neural natural language inference model that provides natural language explanations for its predictions. Our framework shows that this model is capable of generating a significant number of inconsistent explanations.",
}

@inproceedings{lei-etal-2016-rationalizing,
    title = "Rationalizing Neural Predictions",
    author = "Lei, Tao  and
      Barzilay, Regina  and
      Jaakkola, Tommi",
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D16-1011",
    doi = "10.18653/v1/D16-1011",
    pages = "107--117",
}


@inproceedings{wang2020integrating,
  title={Integrating Deep Learning with Logic Fusion for Information Extraction.},
  author={Wang, Wenya and Pan, Sinno Jialin},
  booktitle={AAAI},
  pages={9225--9232},
  year={2020}
}

@inproceedings{zhao-etal-2019-uer,
    title = "{UER}: An Open-Source Toolkit for Pre-training Models",
    author = "Zhao, Zhe  and
      Chen, Hui  and
      Zhang, Jinbin  and
      Zhao, Xin  and
      Liu, Tao  and
      Lu, Wei  and
      Chen, Xi  and
      Deng, Haotang  and
      Ju, Qi  and
      Du, Xiaoyong",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-3041",
    doi = "10.18653/v1/D19-3041",
    pages = "241--246",
}

@inproceedings{sun-etal-2021-probabilistic,
    title = "Probabilistic Graph Reasoning for Natural Proof Generation",
    author = "Sun, Changzhi  and
      Zhang, Xinbo  and
      Chen, Jiangjie  and
      Gan, Chun  and
      Wu, Yuanbin  and
      Chen, Jiaze  and
      Zhou, Hao  and
      Li, Lei",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.277",
    doi = "10.18653/v1/2021.findings-acl.277",
    pages = "3140--3151",
}

@inproceedings{tafjord-etal-2021-proofwriter,
    title = "{P}roof{W}riter: Generating Implications, Proofs, and Abductive Statements over Natural Language",
    author = "Tafjord, Oyvind  and
      Dalvi, Bhavana  and
      Clark, Peter",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.317",
    doi = "10.18653/v1/2021.findings-acl.317",
    pages = "3621--3634",
}

@inproceedings{zellers2019vcr,
    author = {Zellers, Rowan and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
    title = {From Recognition to Cognition: Visual Commonsense Reasoning},
    booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {June},
    year = {2019}
}

@inproceedings{wang-etal-2019-make,
    title = "Does it Make Sense? And Why? A Pilot Study for Sense Making and Explanation",
    author = "Wang, Cunxiang  and
      Liang, Shuailong  and
      Zhang, Yue  and
      Li, Xiaonan  and
      Gao, Tian",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1393",
    doi = "10.18653/v1/P19-1393",
    pages = "4020--4026",
}

@article{10.24963/ijcai.2020/537, 
year = {2020}, 
title = {{Transformers as Soft Reasoners over Language}}, 
author = {Clark, Peter and Tafjord, Oyvind and Richardson, Kyle}, 
doi = {10.24963/ijcai.2020/537}, 
url = {https://www.ijcai.org/proceedings/2020/0537.pdf}, 
abstract = {{Beginning with McCarthy's Advice Taker (1959), AI has pursued the goal of providing a system with explicit, general knowledge and having the system reason over that knowledge. However, expressing the knowledge in a formal (logical or probabilistic) representation has been a major obstacle to this research. This paper investigates a modern approach to this problem where the facts and rules are provided as natural language sentences, thus bypassing a formal representation. We train transformers to reason (or emulate reasoning) over these sentences using synthetically generated data. Our models, that we call RuleTakers, provide the first empirical demonstration that this kind of soft reasoning over language is learnable, can achieve high (99\%) accuracy, and generalizes to test data requiring substantially deeper chaining than seen during training (95\%+ scores). We also demonstrate that the models transfer well to two hand-authored rulebases, and to rulebases paraphrased into more natural language. These findings are significant as it suggests a new role for transformers, namely as limited "soft theorem provers" operating over explicit theories in language. This in turn suggests new possibilities for explainability, correctability, and counterfactual reasoning in question-answering.}}, 
pages = {3882--3890}
}

@inproceedings{zhang-etal-2020-winowhy,
    title = "{W}ino{W}hy: A Deep Diagnosis of Essential Commonsense Knowledge for Answering {W}inograd Schema Challenge",
    author = "Zhang, Hongming  and
      Zhao, Xinran  and
      Song, Yangqiu",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.508",
    doi = "10.18653/v1/2020.acl-main.508",
    pages = "5736--5745",
}

@inproceedings{
cao2021autoregressive,
title={Autoregressive Entity Retrieval},
author={Nicola De Cao and Gautier Izacard and Sebastian Riedel and Fabio Petroni},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=5k8F6UU39V}
}

@inproceedings{li-etal-2019-logic,
    title = "A Logic-Driven Framework for Consistency of Neural Models",
    author = "Li, Tao  and
      Gupta, Vivek  and
      Mehta, Maitrey  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 2019 Conference on EMNLP-IJCNLP",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1405",
    doi = "10.18653/v1/D19-1405",
    pages = "3924--3935",
}

@inproceedings{ma-shih-2018-extended,
    title = "Extended {H}ow{N}et 2.0 {--} An Entity-Relation Common-Sense Representation Model",
    author = "Ma, Wei-Yun  and
      Shih, Yueh-Yin",
    booktitle = "Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)",
    month = may,
    year = "2018",
    address = "Miyazaki, Japan",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://aclanthology.org/L18-1724",
}

@inproceedings{hu2017toward,
  title={Toward controlled generation of text},
  author={Hu, Zhiting and Yang, Zichao and Liang, Xiaodan and Salakhutdinov, Ruslan and Xing, Eric P},
  booktitle={International Conference on Machine Learning},
  pages={1587--1596},
  year={2017},
  organization={PMLR}
}
@article{creswell2022selection,
  title={Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning},
  author={Creswell, Antonia and Shanahan, Murray and Higgins, Irina},
  journal={arXiv preprint arXiv:2205.09712},
  year={2022}
}
@inproceedings{du-etal-2022-e,
    title = "e-{CARE}: a New Dataset for Exploring Explainable Causal Reasoning",
    author = "Du, Li  and
      Ding, Xiao  and
      Xiong, Kai  and
      Liu, Ting  and
      Qin, Bing",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.33",
    doi = "10.18653/v1/2022.acl-long.33",
    pages = "432--446",
}
@inproceedings{dalvi-etal-2021-explaining,
    title = "Explaining Answers with Entailment Trees",
    author = "Dalvi, Bhavana  and
      Jansen, Peter  and
      Tafjord, Oyvind  and
      Xie, Zhengnan  and
      Smith, Hannah  and
      Pipatanangkura, Leighanna  and
      Clark, Peter",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.585",
    doi = "10.18653/v1/2021.emnlp-main.585",
    pages = "7358--7370",
}

@inproceedings{qin-etal-2019-counterfactual,
    title = "Counterfactual Story Reasoning and Generation",
    author = "Qin, Lianhui  and
      Bosselut, Antoine  and
      Holtzman, Ari  and
      Bhagavatula, Chandra  and
      Clark, Elizabeth  and
      Choi, Yejin",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1509",
    doi = "10.18653/v1/D19-1509",
    pages = "5043--5053",
}
@article{Miao_Zhou_Mou_Yan_Li_2019, title={CGMH: Constrained Sentence Generation by Metropolis-Hastings Sampling}, volume={33}, url={https://ojs.aaai.org/index.php/AAAI/article/view/4659}, DOI={10.1609/aaai.v33i01.33016834}, abstractNote={&lt;p&gt;In real-world applications of natural language generation, there are often constraints on the target sentences in addition to fluency and naturalness requirements. Existing language generation techniques are usually based on recurrent neural networks (RNNs). However, it is non-trivial to impose constraints on RNNs while maintaining generation quality, since RNNs generate sentences sequentially (or with beam search) from the first word to the last. In this paper, we propose CGMH, a novel approach using Metropolis-Hastings sampling for constrained sentence generation. CGMH allows complicated constraints such as the occurrence of multiple keywords in the target sentences, which cannot be handled in traditional RNN-based approaches. Moreover, CGMH works in the inference stage, and does not require parallel corpora for training. We evaluate our method on a variety of tasks, including keywords-to-sentence generation, unsupervised sentence paraphrasing, and unsupervised sentence error correction. CGMH achieves high performance compared with previous supervised methods for sentence generation. Our code is released at https://github.com/NingMiao/CGMH&lt;/p&gt;}, number={01}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Miao, Ning and Zhou, Hao and Mou, Lili and Yan, Rui and Li, Lei}, year={2019}, month={Jul.}, pages={6834-6842} }
@inproceedings{zhang-etal-2020-language-generation,
    title = "Language Generation via Combinatorial Constraint Satisfaction: A Tree Search Enhanced {M}onte-{C}arlo Approach",
    author = "Zhang, Maosen  and
      Jiang, Nan  and
      Li, Lei  and
      Xue, Yexiang",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.115",
    doi = "10.18653/v1/2020.findings-emnlp.115",
    pages = "1286--1298",
}
@inproceedings{sha-2020-gradient,
    title = "Gradient-guided Unsupervised Lexically Constrained Text Generation",
    author = "Sha, Lei",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.701",
    doi = "10.18653/v1/2020.emnlp-main.701",
    pages = "8692--8703",
}
@article{qin2022cold,
  title={COLD decoding: Energy-based constrained text generation with langevin dynamics},
  author={Qin, Lianhui and Welleck, Sean and Khashabi, Daniel and Choi, Yejin},
  journal={arXiv preprint arXiv:2202.11705},
  year={2022}
}
@article{Chen_Gan_Cheng_Zhou_Xiao_Li_2022, title={Unsupervised Editing for Counterfactual Stories}, volume={36}, url={https://ojs.aaai.org/index.php/AAAI/article/view/21290}, DOI={10.1609/aaai.v36i10.21290}, abstractNote={Creating what-if stories requires reasoning about prior statements and possible outcomes of the changed conditions. One can easily generate coherent endings under new conditions, but it would be challenging for current systems to do it with minimal changes to the original story. Therefore, one major challenge is the trade-off between generating a logical story and rewriting with minimal-edits. In this paper, we propose EDUCAT, an editing-based unsupervised approach for counterfactual story rewriting. EDUCAT includes a target position detection strategy based on estimating causal effects of the what-if conditions, which keeps the causal invariant parts of the story. EDUCAT then generates the stories under fluency, coherence and minimal-edits constraints. We also propose a new metric to alleviate the shortcomings of current automatic metrics and better evaluate the trade-off. We evaluate EDUCAT on a public counterfactual story rewriting benchmark. Experiments show that EDUCAT achieves the best trade-off over unsupervised SOTA methods according to both automatic and human evaluation. The resources of EDUCAT are available at: https://github.com/jiangjiechen/EDUCAT.}, number={10}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Chen, Jiangjie and Gan, Chun and Cheng, Sijie and Zhou, Hao and Xiao, Yanghua and Li, Lei}, year={2022}, month={Jun.}, pages={10473-10481} }
@article{jin2021numgpt,
  title={Numgpt: Improving numeracy ability of generative pre-trained models},
  author={Jin, Zhihua and Jiang, Xin and Wang, Xingbo and Liu, Qun and Wang, Yong and Ren, Xiaozhe and Qu, Huamin},
  journal={arXiv preprint arXiv:2109.03137},
  year={2021}
}
@inproceedings{ji-etal-2020-language,
    title = "Language Generation with Multi-Hop Reasoning on Commonsense Knowledge Graph",
    author = "Ji, Haozhe  and
      Ke, Pei  and
      Huang, Shaohan  and
      Wei, Furu  and
      Zhu, Xiaoyan  and
      Huang, Minlie",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.54",
    doi = "10.18653/v1/2020.emnlp-main.54",
    pages = "725--736",
}
@inproceedings{zhang-etal-2020-grounded,
    title = "Grounded Conversation Generation as Guided Traverses in Commonsense Knowledge Graphs",
    author = "Zhang, Houyu  and
      Liu, Zhenghao  and
      Xiong, Chenyan  and
      Liu, Zhiyuan",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.184",
    doi = "10.18653/v1/2020.acl-main.184",
    pages = "2031--2043",
}
@inproceedings{khot-etal-2021-text,
    title = "Text Modular Networks: Learning to Decompose Tasks in the Language of Existing Models",
    author = "Khot, Tushar  and
      Khashabi, Daniel  and
      Richardson, Kyle  and
      Clark, Peter  and
      Sabharwal, Ashish",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.99",
    doi = "10.18653/v1/2021.naacl-main.99",
    pages = "1264--1279",
}
@inproceedings{paranjape-etal-2021-prompting,
    title = "Prompting Contrastive Explanations for Commonsense Reasoning Tasks",
    author = "Paranjape, Bhargavi  and
      Michael, Julian  and
      Ghazvininejad, Marjan  and
      Hajishirzi, Hannaneh  and
      Zettlemoyer, Luke",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.366",
    doi = "10.18653/v1/2021.findings-acl.366",
    pages = "4179--4192",
}
@article{kwiatkowski-etal-2019-natural,
    title = "Natural Questions: A Benchmark for Question Answering Research",
    author = "Kwiatkowski, Tom  and
      Palomaki, Jennimaria  and
      Redfield, Olivia  and
      Collins, Michael  and
      Parikh, Ankur  and
      Alberti, Chris  and
      Epstein, Danielle  and
      Polosukhin, Illia  and
      Devlin, Jacob  and
      Lee, Kenton  and
      Toutanova, Kristina  and
      Jones, Llion  and
      Kelcey, Matthew  and
      Chang, Ming-Wei  and
      Dai, Andrew M.  and
      Uszkoreit, Jakob  and
      Le, Quoc  and
      Petrov, Slav",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "7",
    month = mar,
    year = "2019",
    url = "https://aclanthology.org/Q19-1026",
    doi = "10.1162/tacl_a_00276",
    pages = "452--466",
}
@article{betz2021thinking,
  title={Thinking aloud: Dynamic context generation improves zero-Shot reasoning performance of GPT-2},
  author={Betz, Gregor and Richardson, Kyle and Voigt, Christian},
  journal={arXiv preprint arXiv:2103.13033},
  year={2021}
}
@inproceedings{shwartz-etal-2020-unsupervised,
    title = "Unsupervised Commonsense Question Answering with Self-Talk",
    author = "Shwartz, Vered  and
      West, Peter  and
      Le Bras, Ronan  and
      Bhagavatula, Chandra  and
      Choi, Yejin",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.373",
    doi = "10.18653/v1/2020.emnlp-main.373",
    pages = "4615--4629",
}
@inproceedings{ijcai2020-0537,
  title     = {Transformers as Soft Reasoners over Language},
  author    = {Clark, Peter and Tafjord, Oyvind and Richardson, Kyle},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Christian Bessiere},
  pages     = {3882--3890},
  year      = {2020},
  month     = {7},
  note      = {Main track},
  doi       = {10.24963/ijcai.2020/537},
  url       = {https://doi.org/10.24963/ijcai.2020/537},
}

@inproceedings{bostrom-etal-2021-flexible,
    title = "Flexible Generation of Natural Language Deductions",
    author = "Bostrom, Kaj  and
      Zhao, Xinyu  and
      Chaudhuri, Swarat  and
      Durrett, Greg",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.506",
    doi = "10.18653/v1/2021.emnlp-main.506",
    pages = "6266--6278",
}
@inproceedings{lu-etal-2022-fantastically,
    title = "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity",
    author = "Lu, Yao  and
      Bartolo, Max  and
      Moore, Alastair  and
      Riedel, Sebastian  and
      Stenetorp, Pontus",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.556",
    doi = "10.18653/v1/2022.acl-long.556",
    pages = "8086--8098",
}
@article{zhou2022least,
  title={Least-to-Most Prompting Enables Complex Reasoning in Large Language Models},
  author={Zhou, Denny and Sch{\"a}rli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Bousquet, Olivier and Le, Quoc and Chi, Ed},
  journal={arXiv preprint arXiv:2205.10625},
  year={2022}
}
@inproceedings{
    ouyang2022training,
    title={Training language models to follow instructions with human feedback},
    author={Long Ouyang and Jeffrey Wu and Xu Jiang and Diogo Almeida and Carroll Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Gray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
    booktitle={Advances in Neural Information Processing Systems},
    editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
    year={2022},
    url={https://openreview.net/forum?id=TG8KACxEON}
}
@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}
@article{
wei2022emergent,
title={Emergent Abilities of Large Language Models},
author={Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
journal={Transactions on Machine Learning Research},
year={2022},
url={https://openreview.net/forum?id=yzkSU5zdwD},
note={Survey Certification}
}

@inproceedings{
wei2022chain,
title={Chain of Thought Prompting Elicits Reasoning in Large Language Models},
author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and brian ichter and Fei Xia and Ed H. Chi and Quoc V Le and Denny Zhou},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=\_VjQlMeSB\_J}
}
@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{bhargava2022commonsense,
  title={Commonsense Knowledge Reasoning and Generation with Pre-trained Language Models: A Survey},
  author={Bhargava, Prajjwal and Ng, Vincent},
  journal={arXiv preprint arXiv:2201.12438},
  year={2022}
}

@inproceedings{
paolini2021structured,
title={Structured Prediction as Translation between Augmented Natural Languages},
author={Giovanni Paolini and Ben Athiwaratkun and Jason Krone and Jie Ma and Alessandro Achille and RISHITA ANUBHAI and Cicero Nogueira dos Santos and Bing Xiang and Stefano Soatto},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=US-TP-xnXI}
}
@article{guan-etal-2020-knowledge,
    title = "A Knowledge-Enhanced Pretraining Model for Commonsense Story Generation",
    author = "Guan, Jian  and
      Huang, Fei  and
      Zhao, Zhihao  and
      Zhu, Xiaoyan  and
      Huang, Minlie",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "8",
    year = "2020",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2020.tacl-1.7",
    doi = "10.1162/tacl_a_00302",
    pages = "93--108",
}
@article{hu2018deep,
  title={Deep generative models with learnable knowledge constraints},
  author={Hu, Zhiting and Yang, Zichao and Salakhutdinov, Russ R and Qin, LIANHUI and Liang, Xiaodan and Dong, Haoye and Xing, Eric P},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{hu-etal-2016-harnessing,
    title = "Harnessing Deep Neural Networks with Logic Rules",
    author = "Hu, Zhiting  and
      Ma, Xuezhe  and
      Liu, Zhengzhong  and
      Hovy, Eduard  and
      Xing, Eric",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P16-1228",
    doi = "10.18653/v1/P16-1228",
    pages = "2410--2420",
}

@inproceedings{habernal2018argument,
  title={The Argument Reasoning Comprehension Task: Identification and Reconstruction of Implicit Warrants},
  author={Habernal, Ivan and Wachsmuth, Henning and Gurevych, Iryna and Stein, Benno},
  booktitle={Proceedings of NAACL-HLT},
  pages={1930--1940},
  year={2018}
}

@inproceedings{Liu2020LogiQAAC,
  title={LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning},
  author={Jian Liu and Leyang Cui and Hanmeng Liu and Dandan Huang and Yile Wang and Yue Zhang},
  booktitle={IJCAI},
  year={2020}
}

@inproceedings{sinha2019clutrr,
  title={CLUTRR: A Diagnostic Benchmark for Inductive Reasoning from Text},
  author={Sinha, Koustuv and Sodhani, Shagun and Dong, Jin and Pineau, Joelle and Hamilton, William L},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={4506--4515},
  year={2019}
}

@inproceedings{yang-etal-2018-hotpotqa,
    title = "{H}otpot{QA}: A Dataset for Diverse, Explainable Multi-hop Question Answering",
    author = "Yang, Zhilin  and
      Qi, Peng  and
      Zhang, Saizheng  and
      Bengio, Yoshua  and
      Cohen, William  and
      Salakhutdinov, Ruslan  and
      Manning, Christopher D.",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1259",
    doi = "10.18653/v1/D18-1259",
    pages = "2369--2380",
}

@inproceedings{mihaylov-etal-2018-suit,
    title = "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering",
    author = "Mihaylov, Todor  and
      Clark, Peter  and
      Khot, Tushar  and
      Sabharwal, Ashish",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1260",
    doi = "10.18653/v1/D18-1260",
    pages = "2381--2391",
}

@inproceedings{chen2021commonsense,
  title={Commonsense knowledge aware concept selection for diverse and informative visual storytelling},
  author={Chen, Hong and Huang, Yifei and Takamura, Hiroya and Nakayama, Hideki},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={2},
  pages={999--1008},
  year={2021}
}

@inproceedings{garderes-etal-2020-conceptbert,
    title = "{C}oncept{B}ert: Concept-Aware Representation for Visual Question Answering",
    author = "Gard{\`e}res, Fran{\c{c}}ois  and
      Ziaeefard, Maryam  and
      Abeloos, Baptiste  and
      Lecue, Freddy",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.findings-emnlp.44",
    doi = "10.18653/v1/2020.findings-emnlp.44",
    pages = "489--498",
    abstract = "Visual Question Answering (VQA) is a challenging task that has received increasing attention from both the computer vision and the natural language processing communities. A VQA model combines visual and textual features in order to answer questions grounded in an image. Current works in VQA focus on questions which are answerable by direct analysis of the question and image alone. We present a concept-aware algorithm, ConceptBert, for questions which require common sense, or basic factual knowledge from external structured content. Given an image and a question in natural language, ConceptBert requires visual elements of the image and a Knowledge Graph (KG) to infer the correct answer. We introduce a multi-modal representation which learns a joint Concept-Vision-Language embedding inspired by the popular BERT architecture. We exploit ConceptNet KG for encoding the common sense knowledge and evaluate our methodology on the Outside Knowledge-VQA (OK-VQA) and VQA datasets.",
}

@inproceedings{chen2019deep,
  title={Deep short text classification with knowledge powered attention},
  author={Chen, Jindong and Hu, Yizhou and Liu, Jingping and Xiao, Yanghua and Jiang, Haiyun},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={6252--6259},
  year={2019}
}

@article{geva2021did,
  title={Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies},
  author={Geva, Mor and Khashabi, Daniel and Segal, Elad and Khot, Tushar and Roth, Dan and Berant, Jonathan},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={346--361},
  year={2021},
  publisher={MIT Press}
}

@inproceedings{peters-etal-2018-dissecting,
    title = "Dissecting Contextual Word Embeddings: Architecture and Representation",
    author = "Peters, Matthew E.  and
      Neumann, Mark  and
      Zettlemoyer, Luke  and
      Yih, Wen-tau",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1179",
    doi = "10.18653/v1/D18-1179",
    pages = "1499--1509",
}

@inproceedings{peters-etal-2018-deep,
    title = "Deep Contextualized Word Representations",
    author = "Peters, Matthew E.  and
      Neumann, Mark  and
      Iyyer, Mohit  and
      Gardner, Matt  and
      Clark, Christopher  and
      Lee, Kenton  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1202",
    doi = "10.18653/v1/N18-1202",
    pages = "2227--2237",
}

@inproceedings{ethayarajh-etal-2019-towards,
    title = "Towards Understanding Linear Word Analogies",
    author = "Ethayarajh, Kawin  and
      Duvenaud, David  and
      Hirst, Graeme",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1315",
    doi = "10.18653/v1/P19-1315",
    pages = "3253--3262",
}

@inproceedings{khot2020qasc,
  title={Qasc: A dataset for question answering via sentence composition},
  author={Khot, Tushar and Clark, Peter and Guerquin, Michal and Jansen, Peter and Sabharwal, Ashish},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={05},
  pages={8082--8090},
  year={2020}
}

@article{Dalvi2021ExplainingAW,
  title={Explaining Answers with Entailment Trees},
  author={Bhavana Dalvi and Peter Alexander Jansen and Oyvind Tafjord and Zhengnan Xie and Hannah Smith and Leighanna Pipatanangkura and Peter Clark},
  journal={ArXiv},
  year={2021},
  volume={abs/2104.08661}
}

@inproceedings{jhamtani2020learning,
  title={Learning to Explain: Datasets and Models for Identifying Valid Reasoning Chains in Multihop Question-Answering},
  author={Jhamtani, Harsh and Clark, Peter},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={137--150},
  year={2020}
}

@inproceedings{levy-goldberg-2014-linguistic,
    title = "Linguistic Regularities in Sparse and Explicit Word Representations",
    author = "Levy, Omer  and
      Goldberg, Yoav",
    booktitle = "Proceedings of the Eighteenth Conference on Computational Natural Language Learning",
    month = jun,
    year = "2014",
    address = "Ann Arbor, Michigan",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W14-1618",
    doi = "10.3115/v1/W14-1618",
    pages = "171--180",
}

@inproceedings{lai2017race,
  title={RACE: Large-scale ReAding Comprehension Dataset From Examinations},
  author={Lai, Guokun and Xie, Qizhe and Liu, Hanxiao and Yang, Yiming and Hovy, Eduard},
  booktitle={Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  pages={785--794},
  year={2017}
}

@article{clark2018think,
  title={Think you have solved question answering? try arc, the ai2 reasoning challenge},
  author={Clark, Peter and Cowhey, Isaac and Etzioni, Oren and Khot, Tushar and Sabharwal, Ashish and Schoenick, Carissa and Tafjord, Oyvind},
  journal={arXiv preprint arXiv:1803.05457},
  year={2018}
}

@inproceedings{clark2016combining,
  title={Combining retrieval, statistics, and inference to answer elementary science questions},
  author={Clark, Peter and Etzioni, Oren and Khot, Tushar and Sabharwal, Ashish and Tafjord, Oyvind and Turney, Peter and Khashabi, Daniel},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={30},
  number={1},
  year={2016}
}

@article{schoenick2017moving,
  title={Moving beyond the turing test with the allen ai science challenge},
  author={Schoenick, Carissa and Clark, Peter and Tafjord, Oyvind and Turney, Peter and Etzioni, Oren},
  journal={Communications of the ACM},
  volume={60},
  number={9},
  pages={60--64},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@inproceedings{
gu2018nonautoregressive,
title={Non-Autoregressive Neural Machine Translation},
author={Jiatao Gu and James Bradbury and Caiming Xiong and Victor O.K. Li and Richard Socher},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=B1l8BtlCb},
}

@inproceedings{guo2017effective,
  title={Which is the effective way for Gaokao: Information retrieval or neural networks?},
  author={Guo, Shangmin and Zeng, Xiangrong and He, Shizhu and Liu, Kang and Zhao, Jun},
  booktitle={Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers},
  pages={111--120},
  year={2017}
}

@inproceedings{huang2019geosqa,
  title={GeoSQA: A Benchmark for Scenario-based Question Answering in the Geography Domain at High School Level},
  author={Huang, Zixian and Shen, Yulin and Li, Xiao and Cheng, Gong and Zhou, Lin and Dai, Xinyu and Qu, Yuzhong and others},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={5866--5871},
  year={2019}
}

@inproceedings{yu2020reclor,
        author = {Yu, Weihao and Jiang, Zihang and Dong, Yanfei and Feng, Jiashi},
        title = {ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning},
        booktitle = {International Conference on Learning Representations (ICLR)},
        month = {April},
        year = {2020}
}

@article{zhou2022survey,
  title={A Survey on Neural Open Information Extraction: Current Status and Future Directions},
  author={Zhou, Shaowen and Yu, Bowen and Sun, Aixin and Long, Cheng and Li, Jingyang and Sun, Jian},
  journal={arXiv preprint arXiv:2205.11725},
  year={2022}
}

@article{wang2021lsat,
  title={From LSAT: The Progress and Challenges of Complex Reasoning},
  author={Wang, Siyuan and Liu, Zhongkun and Zhong, Wanjun and Zhou, Ming and Wei, Zhongyu and Chen, Zhumin and Duan, Nan},
  journal={arXiv preprint arXiv:2108.00648},
  year={2021}
}

@article{10.1145/219717.219748,
author = {Miller, George A.},
title = {WordNet: A Lexical Database for English},
year = {1995},
issue_date = {Nov. 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {11},
issn = {0001-0782},
url = {https://doi.org/10.1145/219717.219748},
doi = {10.1145/219717.219748},
abstract = {Because meaningful sentences are composed of meaningful words, any system that hopes to process natural languages as people do must have information about words and their meanings. This information is traditionally provided through dictionaries, and machine-readable dictionaries are now widely available. But dictionary entries evolved for the convenience of human readers, not for machines. WordNet1 provides a more effective combination of traditional lexicographic information and modern computing. WordNet is an online lexical database designed for use under program control. English nouns, verbs, adjectives, and adverbs are organized into sets of synonyms, each representing a lexicalized concept. Semantic relations link the synonym sets [4].},
journal = {Commun. ACM},
month = {nov},
pages = {39–41},
numpages = {3}
}

@article{lee2022generative,
  title={Generative Retrieval for Long Sequences},
  author={Lee, Hyunji and Yang, Sohee and Oh, Hanseok and Seo, Minjoon},
  journal={arXiv preprint arXiv:2204.13596},
  year={2022}
}

@inproceedings{petroni-etal-2019-language,
    title = "Language Models as Knowledge Bases?",
    author = {Petroni, Fabio  and
      Rockt{\"a}schel, Tim  and
      Riedel, Sebastian  and
      Lewis, Patrick  and
      Bakhtin, Anton  and
      Wu, Yuxiang  and
      Miller, Alexander},
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1250",
    doi = "10.18653/v1/D19-1250",
    pages = "2463--2473",
    abstract = "Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as {``}fill-in-the-blank{''} cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.",
}

@inproceedings{47786,
title	= {What do you learn from context? Probing for sentence structure in contextualized word representations},
author	= {Ian Tenney and Patrick Xia and Berlin Chen and Alex Wang and Adam Poliak and R. Thomas McCoy and Najoung Kim and Benjamin Van Durme and Samuel R. Bowman and Dipanjan Das and Ellie Pavlick},
year	= {2019},
URL	= {https://openreview.net/forum?id=SJzSgnRcKX},
booktitle	= {International Conference on Learning Representations}
}



@article{10.1162/tacl_a_00460,
    author = {De Cao, Nicola and Wu, Ledell and Popat, Kashyap and Artetxe, Mikel and Goyal, Naman and Plekhanov, Mikhail and Zettlemoyer, Luke and Cancedda, Nicola and Riedel, Sebastian and Petroni, Fabio},
    title = "{Multilingual Autoregressive Entity Linking}",
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {10},
    pages = {274-290},
    year = {2022},
    month = {03},
    abstract = "{We present mGENRE, a sequence-to- sequence system for the Multilingual Entity
                    Linking (MEL) problem—the task of resolving language-specific mentions to
                    a multilingual Knowledge Base (KB). For a mention in a given language, mGENRE
                    predicts the name of the target entity left-to-right, token-by-token in an
                    autoregressive fashion. The autoregressive formulation allows us to effectively
                    cross-encode mention string and entity names to capture more interactions than
                    the standard dot product between mention and entity vectors. It also enables
                    fast search within a large KB even for mentions that do not appear in mention
                    tables and with no need for large-scale vector indices. While prior MEL works
                    use a single representation for each entity, we match against entity names of as
                    many languages as possible, which allows exploiting language connections between
                    source input and target name. Moreover, in a zero-shot setting on languages with
                    no training data at all, mGENRE treats the target language as a latent variable
                    that is marginalized at prediction time. This leads to over 50\\%
                    improvements in average accuracy. We show the efficacy of our approach through
                    extensive evaluation including experiments on three popular MEL benchmarks where
                    we establish new state-of-the-art results. Source code available at https://github.com/facebookresearch/GENRE.}",
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00460},
    url = {https://doi.org/10.1162/tacl\_a\_00460},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00460/2004070/tacl\_a\_00460.pdf},
}


@inproceedings{huang-etal-2021-document,
    title = "Document-level Entity-based Extraction as Template Generation",
    author = "Huang, Kung-Hsiang  and
      Tang, Sam  and
      Peng, Nanyun",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.426",
    doi = "10.18653/v1/2021.emnlp-main.426",
    pages = "5257--5269",
    abstract = "Document-level entity-based extraction (EE), aiming at extracting entity-centric information such as entity roles and entity relations, is key to automatic knowledge acquisition from text corpora for various domains. Most document-level EE systems build extractive models, which struggle to model long-term dependencies among entities at the document level. To address this issue, we propose a generative framework for two document-level EE tasks: role-filler entity extraction (REE) and relation extraction (RE). We first formulate them as a template generation problem, allowing models to efficiently capture cross-entity dependencies, exploit label semantics, and avoid the exponential computation complexity of identifying N-ary relations. A novel cross-attention guided copy mechanism, TopK Copy, is incorporated into a pre-trained sequence-to-sequence model to enhance the capabilities of identifying key information in the input document. Experiments done on the MUC-4 and SciREX dataset show new state-of-the-art results on REE (+3.26{\%}), binary RE (+4.8{\%}), and 4-ary RE (+2.7{\%}) in F1 score.",
}

@inproceedings{rossiello2021generative,
  title={Generative relation linking for question answering over knowledge bases},
  author={Rossiello, Gaetano and Mihindukulasooriya, Nandana and Abdelaziz, Ibrahim and Bornea, Mihaela and Gliozzo, Alfio and Naseem, Tahira and Kapanipathi, Pavan},
  booktitle={International Semantic Web Conference},
  pages={321--337},
  year={2021},
  organization={Springer}
}

@inproceedings{chen-etal-2019-ensuring,
    title = "Ensuring Readability and Data-fidelity using Head-modifier Templates in Deep Type Description Generation",
    author = "Chen, Jiangjie  and
      Wang, Ao  and
      Jiang, Haiyun  and
      Feng, Suo  and
      Li, Chenguang  and
      Xiao, Yanghua",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1196",
    doi = "10.18653/v1/P19-1196",
    pages = "2036--2046",
}


@inproceedings{lu-etal-2021-text2event,
    title = "{T}ext2{E}vent: Controllable Sequence-to-Structure Generation for End-to-end Event Extraction",
    author = "Lu, Yaojie  and
      Lin, Hongyu  and
      Xu, Jin  and
      Han, Xianpei  and
      Tang, Jialong  and
      Li, Annan  and
      Sun, Le  and
      Liao, Meng  and
      Chen, Shaoyi",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.217",
    doi = "10.18653/v1/2021.acl-long.217",
    pages = "2795--2806",
    abstract = "Event extraction is challenging due to the complex structure of event records and the semantic gap between text and event. Traditional methods usually extract event records by decomposing the complex structure prediction task into multiple subtasks. In this paper, we propose Text2Event, a sequence-to-structure generation paradigm that can directly extract events from the text in an end-to-end manner. Specifically, we design a sequence-to-structure network for unified event extraction, a constrained decoding algorithm for event knowledge injection during inference, and a curriculum learning algorithm for efficient model learning. Experimental results show that, by uniformly modeling all tasks in a single model and universally predicting different labels, our method can achieve competitive performance using only record-level annotations in both supervised learning and transfer learning settings.",
}

@inproceedings{Hwang2021COMETATOMIC2O,
  title={COMET-ATOMIC 2020: On Symbolic and Neural Commonsense Knowledge Graphs},
  author={Jena D. Hwang and Chandra Bhagavatula and Ronan Le Bras and Jeff Da and Keisuke Sakaguchi and Antoine Bosselut and Yejin Choi},
  booktitle={AAAI},
  year={2021}
}

@inproceedings{bosselut-etal-2019-comet,
    title = "{COMET}: Commonsense Transformers for Automatic Knowledge Graph Construction",
    author = "Bosselut, Antoine  and
      Rashkin, Hannah  and
      Sap, Maarten  and
      Malaviya, Chaitanya  and
      Celikyilmaz, Asli  and
      Choi, Yejin",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1470",
    doi = "10.18653/v1/P19-1470",
    pages = "4762--4779",
    abstract = "We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional KBs that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose COMmonsEnse Transformers (COMET) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to 77.5{\%} (ATOMIC) and 91.7{\%} (ConceptNet) precision at top 1, which approaches human performance for these resources. Our findings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods.",
}

@inproceedings{lu-etal-2022-unified,
    title = "Unified Structure Generation for Universal Information Extraction",
    author = "Lu, Yaojie  and
      Liu, Qing  and
      Dai, Dai  and
      Xiao, Xinyan  and
      Lin, Hongyu  and
      Han, Xianpei  and
      Sun, Le  and
      Wu, Hua",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.395",
    doi = "10.18653/v1/2022.acl-long.395",
    pages = "5755--5772",
    abstract = "Information extraction suffers from its varying targets, heterogeneous structures, and demand-specific schemas. In this paper, we propose a unified text-to-structure generation framework, namely UIE, which can universally model different IE tasks, adaptively generate targeted structures, and collaboratively learn general IE abilities from different knowledge sources. Specifically, UIE uniformly encodes different extraction structures via a structured extraction language, adaptively generates target extractions via a schema-based prompt mechanism {--} structural schema instructor, and captures the common IE abilities via a large-scale pretrained text-to-structure model. Experiments show that UIE achieved the state-of-the-art performance on 4 IE tasks, 13 datasets, and on all supervised, low-resource, and few-shot settings for a wide range of entity, relation, event and sentiment extraction tasks and their unification. These results verified the effectiveness, universality, and transferability of UIE.",
}

@inproceedings{li-etal-2021-document,
    title = "Document-Level Event Argument Extraction by Conditional Generation",
    author = "Li, Sha  and
      Ji, Heng  and
      Han, Jiawei",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.69",
    doi = "10.18653/v1/2021.naacl-main.69",
    pages = "894--908",
    abstract = "Event extraction has long been treated as a sentence-level task in the IE community. We argue that this setting does not match human informative seeking behavior and leads to incomplete and uninformative extraction results. We propose a document-level neural event argument extraction model by formulating the task as conditional generation following event templates. We also compile a new document-level event extraction benchmark dataset WikiEvents which includes complete event and coreference annotation. On the task of argument extraction, we achieve an absolute gain of 7.6{\%} F1 and 5.7{\%} F1 over the next best model on the RAMS and WikiEvents dataset respectively. On the more challenging task of informative argument extraction, which requires implicit coreference reasoning, we achieve a 9.3{\%} F1 gain over the best baseline. To demonstrate the portability of our model, we also create the first end-to-end zero-shot event extraction framework and achieve 97{\%} of fully supervised model{'}s trigger extraction performance and 82{\%} of the argument extraction performance given only access to 10 out of the 33 types on ACE.",
}

@inproceedings{huguet-cabot-navigli-2021-rebel-relation,
    title = "{REBEL}: Relation Extraction By End-to-end Language generation",
    author = "Huguet Cabot, Pere-Llu{\'\i}s  and
      Navigli, Roberto",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.204",
    doi = "10.18653/v1/2021.findings-emnlp.204",
    pages = "2370--2381",
    abstract = "Extracting relation triplets from raw text is a crucial task in Information Extraction, enabling multiple applications such as populating or validating knowledge bases, factchecking, and other downstream tasks. However, it usually involves multiple-step pipelines that propagate errors or are limited to a small number of relation types. To overcome these issues, we propose the use of autoregressive seq2seq models. Such models have previously been shown to perform well not only in language generation, but also in NLU tasks such as Entity Linking, thanks to their framing as seq2seq tasks. In this paper, we show how Relation Extraction can be simplified by expressing triplets as a sequence of text and we present REBEL, a seq2seq model based on BART that performs end-to-end relation extraction for more than 200 different relation types. We show our model{'}s flexibility by fine-tuning it on an array of Relation Extraction and Relation Classification benchmarks, with it attaining state-of-the-art performance in most of them.",
}

@ARTICLE{9409694,  author={Li, Chenguang and Liang, Jiaqing and Xiao, Yanghua and Jiang, Haiyun},  journal={IEEE Transactions on Knowledge and Data Engineering},   title={Towards Fine-grained Concept Generation},   year={2021},  volume={},  number={},  pages={1-1},  doi={10.1109/TKDE.2021.3074267}}

@article{10.1016/j.knosys.2022.108371,
author = {Chen, Lihan and Jiang, Sihang and Liu, Jingping and Wang, Chao and Zhang, Sheng and Xie, Chenhao and Liang, Jiaqing and Xiao, Yanghua and Song, Rui},
title = {Rule Mining over Knowledge Graphs via Reinforcement Learning},
year = {2022},
issue_date = {Apr 2022},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {242},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2022.108371},
doi = {10.1016/j.knosys.2022.108371},
journal = {Know.-Based Syst.},
month = {apr},
numpages = {13},
keywords = {Rule mining, Representation learning, Reinforcement learning}
}

@article{PRASADA200066,
title = {Acquiring generic knowledge},
journal = {Trends in Cognitive Sciences},
volume = {4},
number = {2},
pages = {66-72},
year = {2000},
issn = {1364-6613},
doi = {https://doi.org/10.1016/S1364-6613(99)01429-1},
url = {https://www.sciencedirect.com/science/article/pii/S1364661399014291},
author = {Sandeep Prasada},
keywords = {Generic knowledge, Conceptual structure, Common sense, Formal system, Kinds, Induction},
abstract = {Generic knowledge is knowledge about kinds of things. The existence of generic knowledge poses a difficult acquisition problem: how do we acquire knowledge about kinds of things if we have experience with only a limited number of examples of the kinds in question? The problem is exacerbated by the fact that we sometimes acquire generic knowledge on the basis of experience with only a single instance of the kind. In this review, it is argued that there is a formal system for common-sense conception that underlies the acquisition of an important class of generic knowledge. Generic knowledge acquired through the use of the formal system represents the stable knowledge we have about kinds of things. It complements, rather than replaces, the statistical and causal (mechanistic) knowledge acquired through the use of other learning mechanisms.}
}