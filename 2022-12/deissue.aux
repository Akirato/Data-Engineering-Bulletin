\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\vbox {\strut  \hbox to \hsize {\hskip 0\tocindention \begingroup \advance \hsize by -0\tocindention \hbox to \hsize {\vbox {\leftskip \toclhindent \parindent -\toclhindent \rightskip \tocrhindent \parfillskip -\tocrhindent \textbf {\Large  \strut  Letters}\hfil \hbox {}}}\endgroup }\strut  }}
\@writefile{toc}{\vskip \smallskipamount }
\@writefile{toc}{\vbox {\strut  \hbox to \hsize {\hskip 1\tocindention \begingroup \advance \hsize by -1\tocindention \hbox to \hsize {\vbox {\leftskip \toclhindent \parindent -\toclhindent \rightskip \tocrhindent \parfillskip -\tocrhindent Letter from the Editor-in-Chief\unskip \nobreak  \xleaders \hbox to .5em{\hss .\hss }\hfill \penalty 50\xleaders \hbox to .5em{\hss .\hss }\hskip 1em\nobreak  \hbox {}\xleaders \hbox to .5em{\hss .\hss }\hfill {\it  Haixun Wang\/}\nobreak  \hbox to\tocpagenumwidth {\hss 1}}}\endgroup }\strut  }}
\@writefile{toc}{\vbox {\strut  \hbox to \hsize {\hskip 1\tocindention \begingroup \advance \hsize by -1\tocindention \hbox to \hsize {\vbox {\leftskip \toclhindent \parindent -\toclhindent \rightskip \tocrhindent \parfillskip -\tocrhindent Letter from the Special Issue Editor\unskip \nobreak  \xleaders \hbox to .5em{\hss .\hss }\hfill \penalty 50\xleaders \hbox to .5em{\hss .\hss }\hskip 1em\nobreak  \hbox {}\xleaders \hbox to .5em{\hss .\hss }\hfill {\it  Yangqiu Song\/}\nobreak  \hbox to\tocpagenumwidth {\hss 2}}}\endgroup }\strut  }}
\citation{Bollacker2008Freebasecollaboratively,Vrandecic2014Wikidatafree,PellissierTanon2016FreebaseWikidata}
\citation{Sun2022JointLKJoint,Yasunaga2021QAGNNReasoning,Saxena2021QuestionAnswering,Ren2021LEGOLatent,Lin2019KagNetKnowledgeAware}
\citation{abiteboul1995FoundationsDatabases}
\citation{Libkin2004ElementsFinite}
\citation{Kroenke2018Databaseprocessing}
\citation{Vrandecic2014Wikidatafree}
\citation{Carlson2010ArchitectureNeverEnding}
\citation{Libkin2009OpenClosed}
\citation{Ji2022Surveyknowledge,Ruffinelli2020YouCAN}
\citation{Ren2020Query2boxReasoning,Kotnis2021AnsweringComplex,Daza2020MessagePassing}
\citation{Ren2020Query2boxReasoning}
\@writefile{toc}{\vskip \bigskipamount }
\@writefile{toc}{\smallskip \hrule \smallskip }
\@writefile{toc}{\vbox {\strut  \hbox to \hsize {\hskip 0\tocindention \begingroup \advance \hsize by -0\tocindention \hbox to \hsize {\vbox {\leftskip \toclhindent \parindent -\toclhindent \rightskip \tocrhindent \parfillskip -\tocrhindent \textbf {\Large  \strut  Special Issue on Learning and Reasoning on Knowledge Graphs and Applications}\hfil \hbox {}}}\endgroup }\strut  }}
\@writefile{toc}{\vskip \smallskipamount }
\@writefile{toc}{\vbox {\strut  \hbox to \hsize {\hskip 1\tocindention \begingroup \advance \hsize by -1\tocindention \hbox to \hsize {\vbox {\leftskip \toclhindent \parindent -\toclhindent \rightskip \tocrhindent \parfillskip -\tocrhindent Logical Queries on Knowledge Graphs: Emerging Interface of Incomplete Relational Data\unskip \nobreak  \xleaders \hbox to .5em{\hss .\hss }\hfill \penalty 50\xleaders \hbox to .5em{\hss .\hss }\hskip 1em\nobreak  \hbox {}\xleaders \hbox to .5em{\hss .\hss }\hfill {\it  Zihao Wang, Hang Yin, and Yangqiu Song\/}\nobreak  \hbox to\tocpagenumwidth {\hss 3}}}\endgroup }\strut  }}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}\protected@file@percent }
\citation{Marker2002Modeltheory}
\@writefile{toc}{\contentsline {section}{\numberline {2}Preliminaries for Logical Queries}{4}{section.2}\protected@file@percent }
\newlabel{sec:data-query}{{2}{4}{Preliminaries for Logical Queries}{section.2}{}}
\newlabel{def:language}{{1}{4}{Preliminaries for Logical Queries}{theorem.1}{}}
\newlabel{def:structure}{{2}{4}{Preliminaries for Logical Queries}{theorem.2}{}}
\citation{VandenBroeck2017QueryProcessing}
\citation{Bordes2013TranslatingEmbeddings}
\citation{Ren2020Query2boxReasoning,Ren2020BetaEmbeddings,Galkin2022InductiveLogical,Hu2022TypeawareEmbeddings,Wang2021BenchmarkingCombinatorial}
\citation{Toutanova2015Observedlatent}
\citation{Ren2020Query2boxReasoning,Ren2020BetaEmbeddings,Wang2021BenchmarkingCombinatorial}
\citation{Auer2007DBpediaNucleus}
\citation{Choudhary2021SelfSupervisedHyperboloidc}
\citation{Miller1995WordNetlexical}
\citation{Huang2022LinELogical}
\citation{xiong2017deeppath}
\citation{Ren2020Query2boxReasoning,Ren2020BetaEmbeddings,Hu2022TypeawareEmbeddings,Wang2021BenchmarkingCombinatorial}
\citation{Zhang2021Drugrepurposing}
\citation{Choudhary2021ProbabilisticEntity}
\citation{Talmor2018WebKnowledgeBase,Bollacker2008Freebasecollaboratively}
\citation{Ren2022SMOREKnowledgea}
\citation{Hu2020OpenGraph}
\citation{Ren2022SMOREKnowledgea,Galkin2022InductiveLogical}
\citation{Bollacker2008Freebasecollaboratively}
\citation{Ren2022SMOREKnowledgea}
\citation{Miller1995WordNetlexical,Auer2007DBpediaNucleus}
\citation{Galkin2022InductiveLogical}
\citation{Teru2020InductiveRelation}
\citation{Ren2020BetaEmbeddings}
\citation{Liu2021NeuralAnsweringLogical}
\newlabel{def:owa}{{3}{5}{Preliminaries for Logical Queries}{theorem.3}{}}
\newlabel{def:term}{{4}{5}{Preliminaries for Logical Queries}{theorem.4}{}}
\newlabel{def:atomic-formula}{{5}{5}{Preliminaries for Logical Queries}{theorem.5}{}}
\newlabel{def:formula}{{6}{5}{Preliminaries for Logical Queries}{theorem.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Logical Query Answering Datasets and Evaluations}{5}{section.3}\protected@file@percent }
\newlabel{sec:dataset}{{3}{5}{Logical Query Answering Datasets and Evaluations}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Knowledge Graphs}{5}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Logical Queries}{5}{subsection.3.2}\protected@file@percent }
\citation{Kotnis2021AnsweringComplex}
\citation{Arakelyan2021ComplexQuery}
\citation{Ren2020Query2boxReasoning,Ren2020BetaEmbeddings,Wang2021BenchmarkingCombinatorial}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Summation of open source knowledge graphs used in the existing datasets. KGs are sorted by the number of entities.\relax }}{6}{table.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:knowledge-graphs}{{1}{6}{Summation of open source knowledge graphs used in the existing datasets. KGs are sorted by the number of entities.\relax }{table.caption.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Formal definitions of three typical query families. Compared to the first-order logic formula defined formally with Definition\nobreakspace  {}\ref  {def:formula}, three query families are defined using a subset of connectives or quantifiers (indicated by {\fontfamily  {pzd}\fontencoding  {U}\fontseries  {m}\fontshape  {n}\selectfont  \char 51}).\relax }}{6}{table.caption.4}\protected@file@percent }
\newlabel{tab:query-families}{{2}{6}{Formal definitions of three typical query families. Compared to the first-order logic formula defined formally with Definition~\ref {def:formula}, three query families are defined using a subset of connectives or quantifiers (indicated by \cmark ).\relax }{table.caption.4}{}}
\citation{Ren2020BetaEmbeddings,Hamilton2018EmbeddingLogical}
\citation{Ren2020Query2boxReasoning}
\citation{Alivanistos2022QueryEmbedding}
\citation{Hamilton2018EmbeddingLogical}
\citation{Ren2020Query2boxReasoning}
\citation{Ren2020BetaEmbeddings}
\citation{Luus2021LogicEmbeddings}
\citation{Luus2021LogicEmbeddings}
\citation{Hajek1998MetamathematicsFuzzy}
\newlabel{subfig:dbqa}{{1(a)}{7}{Subfigure 1(a)}{subfigure.1.1}{}}
\newlabel{sub@subfig:dbqa}{{(a)}{7}{Subfigure 1(a)\relax }{subfigure.1.1}{}}
\newlabel{subfig:cqd}{{1(b)}{7}{Subfigure 1(b)}{subfigure.1.2}{}}
\newlabel{sub@subfig:cqd}{{(b)}{7}{Subfigure 1(b)\relax }{subfigure.1.2}{}}
\newlabel{subfig:query-emb}{{1(c)}{7}{Subfigure 1(c)}{subfigure.1.3}{}}
\newlabel{sub@subfig:query-emb}{{(c)}{7}{Subfigure 1(c)\relax }{subfigure.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Paradigms for logical query answering on knowledge graphs. The solid line indicates the query answering procedures, and the dashed lines indicate the procedures to obtain the model.\relax }}{7}{figure.caption.5}\protected@file@percent }
\newlabel{fig:old-and-new-paradigms}{{1}{7}{Paradigms for logical query answering on knowledge graphs. The solid line indicates the query answering procedures, and the dashed lines indicate the procedures to obtain the model.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Database Query Answering }}}{7}{figure.caption.5}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Continuous Query Decomposition }}}{7}{figure.caption.5}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Query Embedding }}}{7}{figure.caption.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Evaluation Metrics}{7}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Learning-Based Methods}{7}{section.4}\protected@file@percent }
\newlabel{sec:method}{{4}{7}{Learning-Based Methods}{section.4}{}}
\citation{Marker2002Modeltheory}
\citation{Arakelyan2021ComplexQuery}
\citation{Zhang2022KnowledgeGraph,Ji2022Surveyknowledge}
\citation{Trouillon2016ComplexEmbeddings}
\citation{Ren2020Query2boxReasoning}
\citation{Ji2022Surveyknowledge}
\citation{Ruffinelli2020YouCAN}
\citation{Hajek1998MetamathematicsFuzzy}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Comparison between CQD and QE methods with their training data, query answering algorithms, and solvable queries. $\dag  $ indicates that the actual solvable queries may not be the formally defined logical query family.\relax }}{8}{table.caption.6}\protected@file@percent }
\newlabel{tab:compare-method}{{3}{8}{Comparison between CQD and QE methods with their training data, query answering algorithms, and solvable queries. $\dag $ indicates that the actual solvable queries may not be the formally defined logical query family.\relax }{table.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Continuous Query Decomposition (CQD)}{8}{subsection.4.1}\protected@file@percent }
\newlabel{sec:cqd}{{4.1}{8}{Continuous Query Decomposition (CQD)}{subsection.4.1}{}}
\newlabel{eq:epfo-cqd}{{1}{8}{Continuous Query Decomposition (CQD)}{equation.4.1}{}}
\newlabel{eq:objective-cqd}{{2}{8}{Continuous Query Decomposition (CQD)}{equation.4.2}{}}
\citation{Wang2021BenchmarkingCombinatorial}
\citation{Liu2022MaskReason}
\citation{Kotnis2021AnsweringComplex}
\citation{Kotnis2021AnsweringComplex}
\citation{Wang2021BenchmarkingCombinatorial}
\citation{Liu2022MaskReason}
\citation{Kotnis2021AnsweringComplex}
\citation{Kotnis2021AnsweringComplex}
\citation{Wang2021BenchmarkingCombinatorial}
\citation{Liu2022MaskReason}
\citation{Kotnis2021AnsweringComplex}
\citation{Marker2002Modeltheory}
\citation{Wang2021BenchmarkingCombinatorial}
\citation{Liu2021NeuralAnsweringLogical}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Three ways to represent logical query in the query embedding methods. The example is taken from\nobreakspace  {}\cite  {Kotnis2021AnsweringComplex}. We see the logical query is converted into three formats, including (a) operator tree\nobreakspace  {}\cite  {Wang2021BenchmarkingCombinatorial}, where each node is a set operator; (b) query graph\nobreakspace  {}\cite  {Liu2022MaskReason}, where the nodes are terms and predicates; (c) sequences\nobreakspace  {}\cite  {Kotnis2021AnsweringComplex}, where a logical query is transformed as the concatenation of several multi-hop queries with a special positional encoding.\relax }}{9}{figure.caption.7}\protected@file@percent }
\newlabel{fig:query-representation}{{2}{9}{Three ways to represent logical query in the query embedding methods. The example is taken from~\cite {Kotnis2021AnsweringComplex}. We see the logical query is converted into three formats, including (a) operator tree~\cite {Wang2021BenchmarkingCombinatorial}, where each node is a set operator; (b) query graph~\cite {Liu2022MaskReason}, where the nodes are terms and predicates; (c) sequences~\cite {Kotnis2021AnsweringComplex}, where a logical query is transformed as the concatenation of several multi-hop queries with a special positional encoding.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Query Embedding (QE)}{9}{subsection.4.2}\protected@file@percent }
\newlabel{sec:qe}{{4.2}{9}{Query Embedding (QE)}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Logical Queries as Operator Trees}{9}{subsubsection.4.2.1}\protected@file@percent }
\newlabel{sec:qe-optree}{{4.2.1}{9}{Logical Queries as Operator Trees}{subsubsection.4.2.1}{}}
\citation{Ren2020Query2boxReasoning}
\citation{Liu2021NeuralAnsweringLogical}
\citation{Zhang2021ConECone}
\citation{Choudhary2021SelfSupervisedHyperboloidc}
\citation{Zaheer2017DeepSets}
\citation{Zhang2021ConECone}
\citation{Liu2021NeuralAnsweringLogical}
\citation{Ren2020BetaEmbeddings}
\citation{Choudhary2021ProbabilisticEntity}
\citation{Yang2022GammaEGamma}
\citation{Choudhary2021ProbabilisticEntity,Yang2022GammaEGamma}
\citation{Ren2020BetaEmbeddings,Yang2022GammaEGamma}
\citation{Choudhary2021ProbabilisticEntity}
\citation{Ren2020BetaEmbeddings,Yang2022GammaEGamma}
\citation{Huang2022LinELogical}
\citation{Bai2022Query2ParticlesKnowledge}
\citation{Katsaras1977Fuzzyvector}
\citation{Hajek1998MetamathematicsFuzzy}
\citation{Luus2021LogicEmbeddings,Chen2022FuzzyLogic}
\citation{Chen2022FuzzyLogic}
\citation{Schlichtkrull2018ModelingRelational}
\citation{Luus2021LogicEmbeddings}
\citation{Luus2021LogicEmbeddings}
\citation{Amayuelas2022NeuralMethods}
\citation{tolstikhin2021mlp}
\citation{Zhu2022NeuralSymbolicModelsa}
\citation{Zhu2021NeuralBellmanForda}
\citation{Xu2022NeuralSymbolicEntangleda}
\citation{Cohen2020TensorLogProbabilistic}
\citation{Ren2020Query2boxReasoning}
\citation{Daza2020MessagePassing,Liu2022MaskReason,LMPNN}
\citation{shi2016survey}
\citation{Liu2022MaskReason}
\citation{Arakelyan2021ComplexQuery,LMPNN}
\citation{rossi2006handbook}
\citation{Daza2020MessagePassing}
\citation{LMPNN}
\citation{Liu2022MaskReason}
\citation{Kotnis2021AnsweringComplex}
\newlabel{eq:neg-sample}{{3}{11}{Logical Queries as Operator Trees}{equation.4.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Logical Queries as Query Graphs}{11}{subsubsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Logical Queries as Sequences}{11}{subsubsection.4.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Future Directions}{11}{section.5}\protected@file@percent }
\newlabel{sec:future}{{5}{11}{Future Directions}{section.5}{}}
\citation{Zhang2022FactTreeReasoning}
\citation{Galkin2020MessagePassing,Alivanistos2022QueryEmbedding}
\citation{Auer2007DBpediaNucleus,Hu2022TypeawareEmbeddings}
\citation{Jia2021ComplexTemporal,Saxena2021QuestionAnswering}
\citation{Carlson2010ArchitectureNeverEnding}
\citation{VandenBroeck2017QueryProcessing}
\citation{emerson1990temporal}
\citation{Libkin2004ElementsFinite}
\citation{DBLP:conf/iclr/BelloPL0B17}
\citation{petroni2019language,brown2020language}
\citation{Marker2002Modeltheory,Libkin2004ElementsFinite}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Towards General Relational Data}{12}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Towards First Order Queries and Beyond}{12}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Towards Versatile Learning-based Models}{12}{subsection.5.3}\protected@file@percent }
\bibcite{abiteboul1995FoundationsDatabases}{{1}{}{{}}{{}}}
\bibcite{Alivanistos2022QueryEmbedding}{{2}{}{{}}{{}}}
\bibcite{Amayuelas2022NeuralMethods}{{3}{}{{}}{{}}}
\bibcite{Arakelyan2021ComplexQuery}{{4}{}{{}}{{}}}
\bibcite{Auer2007DBpediaNucleus}{{5}{}{{}}{{}}}
\bibcite{Bai2022Query2ParticlesKnowledge}{{6}{}{{}}{{}}}
\bibcite{DBLP:conf/iclr/BelloPL0B17}{{7}{}{{}}{{}}}
\bibcite{Bollacker2008Freebasecollaboratively}{{8}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{13}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Ackonwledgement}{13}{section.7}\protected@file@percent }
\bibcite{Bordes2013TranslatingEmbeddings}{{9}{}{{}}{{}}}
\bibcite{brown2020language}{{10}{}{{}}{{}}}
\bibcite{Carlson2010ArchitectureNeverEnding}{{11}{}{{}}{{}}}
\bibcite{Chen2022FuzzyLogic}{{12}{}{{}}{{}}}
\bibcite{Choudhary2021ProbabilisticEntity}{{13}{}{{}}{{}}}
\bibcite{Choudhary2021SelfSupervisedHyperboloidc}{{14}{}{{}}{{}}}
\bibcite{Cohen2020TensorLogProbabilistic}{{15}{}{{}}{{}}}
\bibcite{Daza2020MessagePassing}{{16}{}{{}}{{}}}
\bibcite{emerson1990temporal}{{17}{}{{}}{{}}}
\bibcite{Galkin2020MessagePassing}{{18}{}{{}}{{}}}
\bibcite{Galkin2022InductiveLogical}{{19}{}{{}}{{}}}
\bibcite{Hajek1998MetamathematicsFuzzy}{{20}{}{{}}{{}}}
\bibcite{Hamilton2018EmbeddingLogical}{{21}{}{{}}{{}}}
\bibcite{Hu2020OpenGraph}{{22}{}{{}}{{}}}
\bibcite{Hu2022TypeawareEmbeddings}{{23}{}{{}}{{}}}
\bibcite{Huang2022LinELogical}{{24}{}{{}}{{}}}
\bibcite{Ji2022Surveyknowledge}{{25}{}{{}}{{}}}
\bibcite{Jia2021ComplexTemporal}{{26}{}{{}}{{}}}
\bibcite{Katsaras1977Fuzzyvector}{{27}{}{{}}{{}}}
\bibcite{Kotnis2021AnsweringComplex}{{28}{}{{}}{{}}}
\bibcite{Kroenke2018Databaseprocessing}{{29}{}{{}}{{}}}
\bibcite{Libkin2004ElementsFinite}{{30}{}{{}}{{}}}
\bibcite{Libkin2009OpenClosed}{{31}{}{{}}{{}}}
\bibcite{Lin2019KagNetKnowledgeAware}{{32}{}{{}}{{}}}
\bibcite{Liu2021NeuralAnsweringLogical}{{33}{}{{}}{{}}}
\bibcite{Liu2022MaskReason}{{34}{}{{}}{{}}}
\bibcite{Luus2021LogicEmbeddings}{{35}{}{{}}{{}}}
\bibcite{Marker2002Modeltheory}{{36}{}{{}}{{}}}
\bibcite{Miller1995WordNetlexical}{{37}{}{{}}{{}}}
\bibcite{PellissierTanon2016FreebaseWikidata}{{38}{}{{}}{{}}}
\bibcite{petroni2019language}{{39}{}{{}}{{}}}
\bibcite{Ren2021LEGOLatent}{{40}{}{{}}{{}}}
\bibcite{Ren2022SMOREKnowledgea}{{41}{}{{}}{{}}}
\bibcite{Ren2020Query2boxReasoning}{{42}{}{{}}{{}}}
\bibcite{Ren2020BetaEmbeddings}{{43}{}{{}}{{}}}
\bibcite{rossi2006handbook}{{44}{}{{}}{{}}}
\bibcite{Ruffinelli2020YouCAN}{{45}{}{{}}{{}}}
\bibcite{Saxena2021QuestionAnswering}{{46}{}{{}}{{}}}
\bibcite{Schlichtkrull2018ModelingRelational}{{47}{}{{}}{{}}}
\bibcite{shi2016survey}{{48}{}{{}}{{}}}
\bibcite{Sun2022JointLKJoint}{{49}{}{{}}{{}}}
\bibcite{Talmor2018WebKnowledgeBase}{{50}{}{{}}{{}}}
\bibcite{Teru2020InductiveRelation}{{51}{}{{}}{{}}}
\bibcite{tolstikhin2021mlp}{{52}{}{{}}{{}}}
\bibcite{Toutanova2015Observedlatent}{{53}{}{{}}{{}}}
\bibcite{Trouillon2016ComplexEmbeddings}{{54}{}{{}}{{}}}
\bibcite{VandenBroeck2017QueryProcessing}{{55}{}{{}}{{}}}
\bibcite{Vrandecic2014Wikidatafree}{{56}{}{{}}{{}}}
\bibcite{LMPNN}{{57}{}{{}}{{}}}
\bibcite{Wang2021BenchmarkingCombinatorial}{{58}{}{{}}{{}}}
\bibcite{xiong2017deeppath}{{59}{}{{}}{{}}}
\bibcite{Xu2022NeuralSymbolicEntangleda}{{60}{}{{}}{{}}}
\bibcite{Yang2022GammaEGamma}{{61}{}{{}}{{}}}
\bibcite{Yasunaga2021QAGNNReasoning}{{62}{}{{}}{{}}}
\bibcite{Zaheer2017DeepSets}{{63}{}{{}}{{}}}
\bibcite{Zhang2021Drugrepurposing}{{64}{}{{}}{{}}}
\bibcite{Zhang2022KnowledgeGraph}{{65}{}{{}}{{}}}
\bibcite{Zhang2022FactTreeReasoning}{{66}{}{{}}{{}}}
\bibcite{Zhang2021ConECone}{{67}{}{{}}{{}}}
\bibcite{Zhu2022NeuralSymbolicModelsa}{{68}{}{{}}{{}}}
\bibcite{Zhu2021NeuralBellmanForda}{{69}{}{{}}{{}}}
\citation{binet}
\citation{transE}
\citation{binet}
\citation{lihui}
\citation{kgminer,KL}
\citation{kompare,prototype_liu}
\citation{kompare}
\@writefile{toc}{\vbox {\strut  \hbox to \hsize {\hskip 1\tocindention \begingroup \advance \hsize by -1\tocindention \hbox to \hsize {\vbox {\leftskip \toclhindent \parindent -\toclhindent \rightskip \tocrhindent \parfillskip -\tocrhindent Knowledge Graph Comparative Reasoning for Fact Checking: Problem Definition and Algorithms\unskip \nobreak  \xleaders \hbox to .5em{\hss .\hss }\hfill \penalty 50\xleaders \hbox to .5em{\hss .\hss }\hskip 1em\nobreak  \hbox {}\xleaders \hbox to .5em{\hss .\hss }\hfill {\it  Lihui Liu*, Ruining Zhao*, Boxin Du, Yi Ren Fung, Heng Ji, Jiejun Xu, and Hanghang Tong\/}\nobreak  \hbox to\tocpagenumwidth {\hss 19}}}\endgroup }\strut  }}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{19}{section.1}\protected@file@percent }
\citation{multimodal}
\citation{kompare}
\citation{Cui2019SAMES}
\citation{kompare}
\citation{Cui2019SAMES}
\citation{kompare}
\@writefile{toc}{\contentsline {section}{\numberline {2}Problem Definition}{20}{section.2}\protected@file@percent }
\newlabel{problem_definition}{{2}{20}{Problem Definition}{section.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An illustrative example of using comparative reasoning for semantic inconsistency detection. Source of the image at the top-left: \cite  {Cui2019SAMES}. The example is borrowed from \nobreakspace  {}\cite  {kompare}. \relax }}{21}{figure.caption.9}\protected@file@percent }
\newlabel{inconsistency}{{1}{21}{An illustrative example of using comparative reasoning for semantic inconsistency detection. Source of the image at the top-left: \cite {Cui2019SAMES}. The example is borrowed from ~\cite {kompare}. \relax }{figure.caption.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Notations and definitions\relax }}{21}{table.caption.10}\protected@file@percent }
\newlabel{notation}{{4}{21}{Notations and definitions\relax }{table.caption.10}{}}
\citation{knowledge-path}
\citation{Shiralkar2017}
\citation{Freitas}
\citation{Faloutsos2004}
\citation{Koren2006MEP}
\citation{conan}
\citation{Tong2006CSP}
\citation{Koren2006MEP}
\citation{Freitas}
\citation{Koren2006MEP}
\@writefile{toc}{\contentsline {section}{\numberline {3}Knowledge Segment Extraction}{23}{section.3}\protected@file@percent }
\newlabel{ks_extractt}{{3}{23}{Knowledge Segment Extraction}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Predicate-Predicate Similarity}{23}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Edge-specific Knowledge Segment}{23}{subsection.3.2}\protected@file@percent }
\newlabel{basic:edge}{{3.2}{23}{Edge-specific Knowledge Segment}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Subgraph-specific Knowledge Segment}{24}{subsection.3.3}\protected@file@percent }
\newlabel{basic:subgraph}{{3.3}{24}{Subgraph-specific Knowledge Segment}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Comparative Reasoning}{24}{section.4}\protected@file@percent }
\newlabel{methods}{{4}{24}{Comparative Reasoning}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Pairwise Comparative Reasoning Condition}{24}{subsection.4.1}\protected@file@percent }
\citation{Tong2006rdwalk}
\citation{bright}
\citation{bright}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Neural Network Based Pairwise Comparative Reasoning}{25}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Structure Embedding}{25}{subsubsection.4.2.1}\protected@file@percent }
\citation{bert}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Semantic Embedding}{26}{subsubsection.4.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Neural network based pairwise comparative reasoning framework. \relax }}{26}{figure.caption.11}\protected@file@percent }
\newlabel{nn_pairwise}{{2}{26}{Neural network based pairwise comparative reasoning framework. \relax }{figure.caption.11}{}}
\citation{qinghai}
\citation{qinghai}
\citation{sysvester}
\citation{qinghai}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Neural Network Based Pairwise Comparative Reasoning\relax }}{27}{algorithm.1}\protected@file@percent }
\newlabel{pair_nn}{{1}{27}{Neural Network Based Pairwise Comparative Reasoning\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Graph Kernel Based Pairwise Comparative Reasoning}{27}{subsection.4.3}\protected@file@percent }
\newlabel{eq:rwgraphkernel}{{9}{27}{Graph Kernel Based Pairwise Comparative Reasoning}{equation.4.9}{}}
\newlabel{lm:influence}{{6}{27}{Graph Kernel Based Pairwise Comparative Reasoning}{theorem.6}{}}
\citation{Shiralkar2017}
\newlabel{eq:transinfo}{{13}{28}{Graph Kernel Based Pairwise Comparative Reasoning}{equation.4.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Graph Kernel Based Collective Comparative Reasoning}{28}{subsection.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Collective comparative reasoning workflow.\relax }}{29}{figure.caption.12}\protected@file@percent }
\newlabel{collective-compare-workflow}{{3}{29}{Collective comparative reasoning workflow.\relax }{figure.caption.12}{}}
\newlabel{lm:collectiveinfluence}{{8}{29}{Graph Kernel Based Collective Comparative Reasoning}{theorem.8}{}}
\citation{yago}
\citation{yago}
\citation{transE}
\citation{jaccard}
\citation{KL}
\citation{kgminer}
\citation{transE}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experimental Results}{30}{section.5}\protected@file@percent }
\newlabel{experiments}{{5}{30}{Experimental Results}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Predicate-Predicate Similarity Efficacy}{30}{subsection.5.1}\protected@file@percent }
\newlabel{subfig:dbqa}{{4(a)}{31}{Subfigure 4(a)}{subfigure.4.1}{}}
\newlabel{sub@subfig:dbqa}{{(a)}{31}{Subfigure 4(a)\relax }{subfigure.4.1}{}}
\newlabel{subfig:dbqa}{{4(b)}{31}{Subfigure 4(b)}{subfigure.4.2}{}}
\newlabel{sub@subfig:dbqa}{{(b)}{31}{Subfigure 4(b)\relax }{subfigure.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Top-{\em 10} most similar predicates in Yago.\relax }}{31}{figure.caption.13}\protected@file@percent }
\newlabel{word-cloud}{{4}{31}{Top-{\em 10} most similar predicates in Yago.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {exports}}}{31}{figure.caption.13}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {livesIn}}}{31}{figure.caption.13}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Predicate similarity of {\tt  isTypeOf} with others\relax }}{31}{table.caption.14}\protected@file@percent }
\newlabel{appendix-pred-sim}{{5}{31}{Predicate similarity of {\tt isTypeOf} with others\relax }{table.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Pair-wise Comparative Reasoning}{31}{subsection.5.2}\protected@file@percent }
\newlabel{exp-pair-section}{{5.2}{31}{Pair-wise Comparative Reasoning}{subsection.5.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Accuracy of pair-wise comparative reasoning. \relax }}{31}{table.caption.15}\protected@file@percent }
\newlabel{pair_dataset}{{6}{31}{Accuracy of pair-wise comparative reasoning. \relax }{table.caption.15}{}}
\citation{kgminer}
\citation{jaccard}
\citation{transE}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Neural Network Based Pair-wise Comparative Reasoning}{32}{subsection.5.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Accuracy, recall and precision of neural network based pair-wise comparative reasoning \relax }}{32}{table.caption.16}\protected@file@percent }
\newlabel{pair_dataset_bin_3}{{7}{32}{Accuracy, recall and precision of neural network based pair-wise comparative reasoning \relax }{table.caption.16}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Accuracy of neural network based pair-wise comparative reasoning \relax }}{32}{table.caption.17}\protected@file@percent }
\newlabel{pair_dataset_bin_Acc}{{8}{32}{Accuracy of neural network based pair-wise comparative reasoning \relax }{table.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Collective Comparative Reasoning}{32}{subsection.5.4}\protected@file@percent }
\newlabel{exp-coll-section}{{5.4}{32}{Collective Comparative Reasoning}{subsection.5.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Accuracy of collective comparative reasoning.\relax }}{33}{table.caption.18}\protected@file@percent }
\newlabel{coll_dataset}{{9}{33}{Accuracy of collective comparative reasoning.\relax }{table.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Accuracy of collective comparative reasoning for Covid-19.\relax }}{33}{table.caption.19}\protected@file@percent }
\newlabel{covid_coll}{{10}{33}{Accuracy of collective comparative reasoning for Covid-19.\relax }{table.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Efficiency Results}{33}{subsection.5.5}\protected@file@percent }
\citation{Wang2015QUT}
\citation{YinghuiWu}
\citation{Yang2014vldb}
\citation{GQBE}
\citation{tongtao2018Gaia}
\citation{ciampaglia2015computational}
\citation{shi2016discriminative}
\citation{shiralkar2017finding}
\citation{lin2018fact}
\citation{tchechmedjiev2019claimskg}
\citation{transE}
\citation{rotatE}
\citation{entity-predicate}
\citation{pprop}
\citation{williamCohen}
\citation{willianWang}
\citation{das-etal-2017-chains}
\citation{transE}
\citation{Lin2015TransR}
\citation{entity-predicate}
\newlabel{fig:runtime}{{\caption@xref {fig:runtime}{ on input line 323}}{34}{Efficiency Results}{figure.caption.20}{}}
\newlabel{subfig:dbqa}{{5(a)}{34}{Subfigure 5(a)}{subfigure.5.1}{}}
\newlabel{sub@subfig:dbqa}{{(a)}{34}{Subfigure 5(a)\relax }{subfigure.5.1}{}}
\newlabel{subfig:dbqa}{{5(b)}{34}{Subfigure 5(b)}{subfigure.5.2}{}}
\newlabel{sub@subfig:dbqa}{{(b)}{34}{Subfigure 5(b)\relax }{subfigure.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces A set of four subfigures.}}{34}{figure.caption.20}\protected@file@percent }
\newlabel{precision-4}{{5}{34}{A set of four subfigures}{figure.caption.20}{}}
\newlabel{fig:runtime}{{5}{34}{A set of four subfigures}{figure.caption.20}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Subgraph-specific KS extraction}}}{34}{figure.caption.20}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Comparative reasoning}}}{34}{figure.caption.20}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Related Work}{34}{section.6}\protected@file@percent }
\newlabel{related-work}{{6}{34}{Related Work}{section.6}{}}
\citation{Shiralkar2017}
\citation{Shi2016dpp}
\citation{Shiralkar2017}
\bibcite{transE}{{1}{}{{}}{{}}}
\bibcite{KL}{{2}{}{{}}{{}}}
\bibcite{ciampaglia2015computational}{{3}{}{{}}{{}}}
\bibcite{Cui2019SAMES}{{4}{}{{}}{{}}}
\bibcite{bert}{{5}{}{{}}{{}}}
\bibcite{sysvester}{{6}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions}{35}{section.7}\protected@file@percent }
\newlabel{conclusion}{{7}{35}{Conclusions}{section.7}{}}
\bibcite{Faloutsos2004}{{7}{}{{}}{{}}}
\bibcite{Freitas}{{8}{}{{}}{{}}}
\bibcite{knowledge-path}{{9}{}{{}}{{}}}
\bibcite{GQBE}{{10}{}{{}}{{}}}
\bibcite{Koren2006MEP}{{11}{}{{}}{{}}}
\bibcite{entity-predicate}{{12}{}{{}}{{}}}
\bibcite{williamCohen}{{13}{}{{}}{{}}}
\bibcite{jaccard}{{14}{}{{}}{{}}}
\bibcite{lin2018fact}{{15}{}{{}}{{}}}
\bibcite{Lin2015TransR}{{16}{}{{}}{{}}}
\bibcite{lihui}{{17}{}{{}}{{}}}
\bibcite{kompare}{{18}{}{{}}{{}}}
\bibcite{prototype_liu}{{19}{}{{}}{{}}}
\bibcite{binet}{{20}{}{{}}{{}}}
\bibcite{multimodal}{{21}{}{{}}{{}}}
\bibcite{das-etal-2017-chains}{{22}{}{{}}{{}}}
\bibcite{conan}{{23}{}{{}}{{}}}
\bibcite{Shiralkar2017}{{24}{}{{}}{{}}}
\bibcite{Shi2016dpp}{{25}{}{{}}{{}}}
\bibcite{kgminer}{{26}{}{{}}{{}}}
\bibcite{shi2016discriminative}{{27}{}{{}}{{}}}
\bibcite{shiralkar2017finding}{{28}{}{{}}{{}}}
\bibcite{YinghuiWu}{{29}{}{{}}{{}}}
\bibcite{yago}{{30}{}{{}}{{}}}
\bibcite{rotatE}{{31}{}{{}}{{}}}
\bibcite{tchechmedjiev2019claimskg}{{32}{}{{}}{{}}}
\bibcite{Tong2006CSP}{{33}{}{{}}{{}}}
\bibcite{Tong2006rdwalk}{{34}{}{{}}{{}}}
\bibcite{pprop}{{35}{}{{}}{{}}}
\bibcite{Wang2015QUT}{{36}{}{{}}{{}}}
\bibcite{willianWang}{{37}{}{{}}{{}}}
\bibcite{bright}{{38}{}{{}}{{}}}
\bibcite{Yang2014vldb}{{39}{}{{}}{{}}}
\bibcite{tongtao2018Gaia}{{40}{}{{}}{{}}}
\bibcite{qinghai}{{41}{}{{}}{{}}}
\citation{wittgenstein1958blue}
\citation{weizenbaum1966eliza}
\citation{wu2016google}
\citation{xu-etal-2020-xiaomingbot}
\citation{thoppilan2022lamda}
\citation{gkatzia-et-al-2017}
\citation{paolini2021structured}
\citation{kukich-1983-design,mckeown1992text}
\citation{vaswani2017attention}
\citation{radford2019language,devlin-etal-2019-bert,raffel2020exploring,lewis-etal-2020-bart,NEURIPS2020_1457c0d6}
\citation{liu-etal-2021-explainaboard}
\citation{raunak-etal-2021-curious,xiao-wang-2021-hallucination}
\citation{vanderlyn-etal-2021-seemed,ziems-etal-2022-moral}
\citation{kim-etal-2020-will,elazar-etal-2021-measuring}
\citation{Hwang2021COMETATOMIC2O}
\citation{Speer_Chin_Havasi_2017}
\citation{10.5555/1785162.1785216,vrandevcic2014wikidata}
\@writefile{toc}{\vbox {\strut  \hbox to \hsize {\hskip 1\tocindention \begingroup \advance \hsize by -1\tocindention \hbox to \hsize {\vbox {\leftskip \toclhindent \parindent -\toclhindent \rightskip \tocrhindent \parfillskip -\tocrhindent Harnessing Knowledge and Reasoning for Human-Like Natural Language Generation: A Brief Review\unskip \nobreak  \xleaders \hbox to .5em{\hss .\hss }\hfill \penalty 50\xleaders \hbox to .5em{\hss .\hss }\hskip 1em\nobreak  \hbox {}\xleaders \hbox to .5em{\hss .\hss }\hfill {\it  Jiangjie Chen and Yanghua Xiao\/}\nobreak  \hbox to\tocpagenumwidth {\hss 39}}}\endgroup }\strut  }}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{39}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{39}{Introduction}{section.1}{}}
\citation{wu-etal-2020-diverse}
\citation{shen2019mixture}
\citation{10.1145/3488560.3498431}
\citation{10.1007/978-3-030-88480-2_28}
\citation{he-etal-2022-pre,liu-etal-2022-testing,chen-etal-2022-e}
\citation{chakrabarty-etal-2022-rocket}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The taxonomy of the goals in NLG.\relax }}{40}{figure.caption.22}\protected@file@percent }
\newlabel{fig:taxonomy}{{1}{40}{The taxonomy of the goals in NLG.\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Holy Grails in NLG}{40}{section.2}\protected@file@percent }
\newlabel{sec:goal}{{2}{40}{Holy Grails in NLG}{section.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Diverse}{40}{section*.23}\protected@file@percent }
\citation{yin-ordonez-2017-obj2text,DBLP:conf/ai/Shi0Z21,shi-etal-2021-enhancing}
\citation{cao2018faithful,maynez-etal-2020-faithfulness,ladhak-etal-2022-faithful}
\citation{honovich-etal-2021-q2}
\citation{devaraj-etal-2022-evaluating}
\citation{cao-etal-2022-hallucinated}
\citation{thorne-etal-2018-fever,Chen_Bao_Sun_Zhang_Chen_Zhou_Xiao_Li_2022}
\citation{betz-etal-2021-critical,chen-etal-2020-logical,shi-etal-2021-refine-imitate,shu-etal-2021-logic,pi2022logigan}
\citation{yu2022survey}
\citation{NEURIPS2020_6b493230}
\citation{liu-etal-2022-multi}
\citation{cao-etal-2021-knowledgeable}
\citation{reiter2019natural}
\citation{wiegreffe-marasovic-2021-review}
\citation{ye2022unreliability}
\citation{lime,Schulz2020Restricting,10.5555/3305890.3306024}
\citation{NEURIPS2021_d0f5edad,zhang2022survey,garbacea2022constrained}
\citation{NEURIPS2020_1457c0d6}
\@writefile{toc}{\contentsline {paragraph}{Figurative}{41}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Descriptive}{41}{section*.25}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Faithful}{41}{section*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Logical}{41}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Knowledgeable}{41}{section*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Explainable}{41}{section*.29}\protected@file@percent }
\citation{liu-etal-2020-gender,xia-etal-2020-demoting,gupta-etal-2022-mitigating}
\citation{radford2019language,raffel2020exploring,lewis-etal-2020-bart,NEURIPS2020_1457c0d6}
\citation{gu2018nonautoregressive,xiao2022survey}
\citation{vaswani2017attention}
\citation{Zhou2020Understanding}
\citation{qian-etal-2021-glancing}
\citation{zeng-etal-2022-neighbors}
\citation{yu2022survey}
\citation{chen-etal-2019-ensuring}
\citation{sun-etal-2018-logician,cao-etal-2020-unsupervised-dual}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Relations between knowledge and NLG, where knowledge can enhance, guide and be injected into NLG systems, and NLG systems can be utilized as tools to generate new knowledge.\relax }}{42}{figure.caption.33}\protected@file@percent }
\newlabel{fig:knowledge-nlg}{{2}{42}{Relations between knowledge and NLG, where knowledge can enhance, guide and be injected into NLG systems, and NLG systems can be utilized as tools to generate new knowledge.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {paragraph}{Controllable}{42}{section*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Fair}{42}{section*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Efficient}{42}{section*.32}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Knowledge in Language Generation}{42}{section.3}\protected@file@percent }
\newlabel{sec:knowledge}{{3}{42}{Knowledge in Language Generation}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Knowledge-guided NLG: Tricks of the Trade}{42}{subsection.3.1}\protected@file@percent }
\newlabel{subsec:knowledge-guided-nlg}{{3.1}{42}{Knowledge-guided NLG: Tricks of the Trade}{subsection.3.1}{}}
\citation{yang2021survey,yu2022survey}
\citation{DBLP:journals/corr/BahdanauCB14}
\citation{gu-etal-2016-incorporating}
\citation{kipf2016semi}
\citation{guo2020incorporating}
\citation{NEURIPS2020_1457c0d6}
\citation{yu2022survey}
\citation{pmlr-v119-guu20a,NEURIPS2020_6b493230}
\citation{cao-etal-2020-unsupervised-dual}
\citation{guan-etal-2020-knowledge}
\citation{hu2018deep}
\citation{li2018ensure}
\citation{huang-etal-2020-knowledge}
\citation{zhang2022survey,garbacea2022constrained}
\citation{hokamp-liu-2017-lexically,post-vilar-2018-fast,lu-etal-2021-neurologic}
\citation{susanto-etal-2020-lexically,10.1162/tacl_a_00368}
\citation{Dathathri2020Plug}
\citation{radford2019language}
\citation{Miao_Zhou_Mou_Yan_Li_2019,zhang-etal-2020-language-generation,qin2022cold}
\@writefile{toc}{\contentsline {paragraph}{Knowledge Sources}{43}{section*.34}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Knowledge Incorporation in Model Architectures}{43}{section*.35}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Learning with Knowledge}{43}{section*.36}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Knowledge-Constrained Decoding}{43}{section*.37}\protected@file@percent }
\citation{liu2022knowledge}
\citation{10.1145/219717.219748}
\citation{zhou2022survey}
\citation{Davis1977MetaLevelKO}
\citation{chen2019deep}
\citation{garderes-etal-2020-conceptbert}
\citation{chen2021commonsense}
\citation{chen-etal-2019-ensuring,9409694}
\citation{10.1016/j.knosys.2022.108371}
\citation{cao2021autoregressive,10.1162/tacl_a_00460,rossiello2021generative}
\citation{lu-etal-2022-unified}
\citation{huguet-cabot-navigli-2021-rebel-relation}
\citation{lu-etal-2021-text2event}
\citation{huang-etal-2021-document}
\citation{bosselut-etal-2019-comet,Hwang2021COMETATOMIC2O}
\citation{47786}
\citation{petroni-etal-2019-language,alkhamissi2022review}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Knowledge Acquisition with NLG}{44}{subsection.3.2}\protected@file@percent }
\newlabel{subsec:generative_acquisition}{{3.2}{44}{Knowledge Acquisition with NLG}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Paradigms of Knowledge Acquisition}{44}{section*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Meta Knowledge Generation}{44}{section*.39}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Generative Knowledge Retrieval}{44}{section*.40}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Generative Knowledge Extraction}{44}{section*.41}\protected@file@percent }
\citation{Liu_Wan_He_Peng_Yu_2021}
\citation{wang-etal-2020-heterogeneous}
\citation{NIPS2013_1cecc7a7}
\citation{kipf2016semi,velickovic2018graph}
\citation{ji-etal-2020-language}
\citation{wang-etal-2019-paperrobot,zhang-etal-2020-grounded}
\citation{gardner2017allennlp}
\citation{10.1145/3488560.3498431}
\citation{dalvi-etal-2021-explaining}
\citation{bhagavatula2020abductive}
\citation{qin-etal-2019-counterfactual}
\citation{lin-etal-2020-commongen}
\citation{sap-etal-2019-social}
\citation{Bisk_Zellers_Le_bras_Gao_Choi_2020}
\citation{zhou-etal-2019-going}
\citation{sap-etal-2019-social,Bisk_Zellers_Le_bras_Gao_Choi_2020,zhou-etal-2019-going}
\citation{2020unifiedqa}
\citation{wiegreffe-marasovic-2021-review}
\citation{NEURIPS2018_4c7a167b}
\citation{rajani-etal-2019-explain}
\citation{chen-etal-2022-e}
\citation{du-etal-2022-e}
\citation{li2018vqae}
\@writefile{toc}{\contentsline {paragraph}{Knowledge Generation}{45}{section*.42}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Reasoning in Language Generation}{45}{section.4}\protected@file@percent }
\newlabel{sec:reasoning}{{4}{45}{Reasoning in Language Generation}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Reasoning-guided NLG}{45}{subsection.4.1}\protected@file@percent }
\newlabel{subsec:reasoning-guided-nlg}{{4.1}{45}{Reasoning-guided NLG}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Graph Reasoning}{45}{section*.43}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Reasoning Tasks}{45}{section*.44}\protected@file@percent }
\citation{tafjord-etal-2021-proofwriter}
\citation{jhamtani-clark-2020-learning}
\citation{khot-etal-2021-text}
\citation{shwartz-etal-2020-unsupervised,betz2021thinking}
\citation{ijcai2020-0537}
\citation{bostrom-etal-2021-flexible,betz-etal-2021-critical}
\citation{NEURIPS2020_1457c0d6,ouyang2022training}
\citation{chowdhery2022palm}
\citation{NEURIPS2020_1457c0d6,lu-etal-2022-fantastically}
\citation{wei2022chain}
\citation{wang2022self,zhou2022least,creswell2022selection}
\citation{wei2022chain}
\citation{wei2022chain,wei2022emergent}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Reasoning by NLG}{46}{subsection.4.2}\protected@file@percent }
\newlabel{subsec:reasoning-by-nlg}{{4.2}{46}{Reasoning by NLG}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Generative Reasoning}{46}{section*.45}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Reasoning with Large Language Models}{46}{section*.46}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{46}{section.5}\protected@file@percent }
\newlabel{sec:conclusion}{{5}{46}{Conclusion}{section.5}{}}
\bibcite{alkhamissi2022review}{{1}{}{{}}{{}}}
\bibcite{10.5555/1785162.1785216}{{2}{}{{}}{{}}}
\bibcite{DBLP:journals/corr/BahdanauCB14}{{3}{}{{}}{{}}}
\bibcite{betz2021thinking}{{4}{}{{}}{{}}}
\bibcite{betz-etal-2021-critical}{{5}{}{{}}{{}}}
\bibcite{bhagavatula2020abductive}{{6}{}{{}}{{}}}
\bibcite{Bisk_Zellers_Le_bras_Gao_Choi_2020}{{7}{}{{}}{{}}}
\bibcite{NIPS2013_1cecc7a7}{{8}{}{{}}{{}}}
\bibcite{bosselut-etal-2019-comet}{{9}{}{{}}{{}}}
\bibcite{bostrom-etal-2021-flexible}{{10}{}{{}}{{}}}
\bibcite{NEURIPS2020_1457c0d6}{{11}{}{{}}{{}}}
\bibcite{NEURIPS2018_4c7a167b}{{12}{}{{}}{{}}}
\bibcite{cao-etal-2021-knowledgeable}{{13}{}{{}}{{}}}
\bibcite{cao-etal-2022-hallucinated}{{14}{}{{}}{{}}}
\bibcite{cao2021autoregressive}{{15}{}{{}}{{}}}
\bibcite{cao-etal-2020-unsupervised-dual}{{16}{}{{}}{{}}}
\bibcite{cao2018faithful}{{17}{}{{}}{{}}}
\bibcite{chakrabarty-etal-2022-rocket}{{18}{}{{}}{{}}}
\bibcite{chen2021commonsense}{{19}{}{{}}{{}}}
\bibcite{Chen_Bao_Sun_Zhang_Chen_Zhou_Xiao_Li_2022}{{20}{}{{}}{{}}}
\bibcite{chen-etal-2019-ensuring}{{21}{}{{}}{{}}}
\bibcite{chen-etal-2022-e}{{22}{}{{}}{{}}}
\bibcite{chen2019deep}{{23}{}{{}}{{}}}
\bibcite{10.1016/j.knosys.2022.108371}{{24}{}{{}}{{}}}
\bibcite{chen-etal-2020-logical}{{25}{}{{}}{{}}}
\bibcite{chowdhery2022palm}{{26}{}{{}}{{}}}
\bibcite{ijcai2020-0537}{{27}{}{{}}{{}}}
\bibcite{creswell2022selection}{{28}{}{{}}{{}}}
\bibcite{dalvi-etal-2021-explaining}{{29}{}{{}}{{}}}
\bibcite{Dathathri2020Plug}{{30}{}{{}}{{}}}
\bibcite{Davis1977MetaLevelKO}{{31}{}{{}}{{}}}
\bibcite{10.1162/tacl_a_00460}{{32}{}{{}}{{}}}
\bibcite{devaraj-etal-2022-evaluating}{{33}{}{{}}{{}}}
\bibcite{devlin-etal-2019-bert}{{34}{}{{}}{{}}}
\bibcite{du-etal-2022-e}{{35}{}{{}}{{}}}
\bibcite{elazar-etal-2021-measuring}{{36}{}{{}}{{}}}
\bibcite{garbacea2022constrained}{{37}{}{{}}{{}}}
\bibcite{garderes-etal-2020-conceptbert}{{38}{}{{}}{{}}}
\bibcite{gardner2017allennlp}{{39}{}{{}}{{}}}
\bibcite{gkatzia-et-al-2017}{{40}{}{{}}{{}}}
\bibcite{gu2018nonautoregressive}{{41}{}{{}}{{}}}
\bibcite{gu-etal-2016-incorporating}{{42}{}{{}}{{}}}
\bibcite{guan-etal-2020-knowledge}{{43}{}{{}}{{}}}
\bibcite{guo2020incorporating}{{44}{}{{}}{{}}}
\bibcite{gupta-etal-2022-mitigating}{{45}{}{{}}{{}}}
\bibcite{pmlr-v119-guu20a}{{46}{}{{}}{{}}}
\bibcite{he-etal-2022-pre}{{47}{}{{}}{{}}}
\bibcite{hokamp-liu-2017-lexically}{{48}{}{{}}{{}}}
\bibcite{honovich-etal-2021-q2}{{49}{}{{}}{{}}}
\bibcite{NEURIPS2021_d0f5edad}{{50}{}{{}}{{}}}
\bibcite{hu2018deep}{{51}{}{{}}{{}}}
\bibcite{huang-etal-2021-document}{{52}{}{{}}{{}}}
\bibcite{huang-etal-2020-knowledge}{{53}{}{{}}{{}}}
\bibcite{huguet-cabot-navigli-2021-rebel-relation}{{54}{}{{}}{{}}}
\bibcite{Hwang2021COMETATOMIC2O}{{55}{}{{}}{{}}}
\bibcite{jhamtani-clark-2020-learning}{{56}{}{{}}{{}}}
\bibcite{ji-etal-2020-language}{{57}{}{{}}{{}}}
\bibcite{2020unifiedqa}{{58}{}{{}}{{}}}
\bibcite{khot-etal-2021-text}{{59}{}{{}}{{}}}
\bibcite{kim-etal-2020-will}{{60}{}{{}}{{}}}
\bibcite{kipf2016semi}{{61}{}{{}}{{}}}
\bibcite{kukich-1983-design}{{62}{}{{}}{{}}}
\bibcite{ladhak-etal-2022-faithful}{{63}{}{{}}{{}}}
\bibcite{lewis-etal-2020-bart}{{64}{}{{}}{{}}}
\bibcite{NEURIPS2020_6b493230}{{65}{}{{}}{{}}}
\bibcite{9409694}{{66}{}{{}}{{}}}
\bibcite{li2018ensure}{{67}{}{{}}{{}}}
\bibcite{li2018vqae}{{68}{}{{}}{{}}}
\bibcite{lin-etal-2020-commongen}{{69}{}{{}}{{}}}
\bibcite{liu-etal-2022-testing}{{70}{}{{}}{{}}}
\bibcite{liu-etal-2020-gender}{{71}{}{{}}{{}}}
\bibcite{liu-etal-2021-explainaboard}{{72}{}{{}}{{}}}
\bibcite{liu2022knowledge}{{73}{}{{}}{{}}}
\bibcite{Liu_Wan_He_Peng_Yu_2021}{{74}{}{{}}{{}}}
\bibcite{liu-etal-2022-multi}{{75}{}{{}}{{}}}
\bibcite{lu-etal-2021-neurologic}{{76}{}{{}}{{}}}
\bibcite{lu-etal-2022-fantastically}{{77}{}{{}}{{}}}
\bibcite{lu-etal-2021-text2event}{{78}{}{{}}{{}}}
\bibcite{lu-etal-2022-unified}{{79}{}{{}}{{}}}
\bibcite{maynez-etal-2020-faithfulness}{{80}{}{{}}{{}}}
\bibcite{mckeown1992text}{{81}{}{{}}{{}}}
\bibcite{Miao_Zhou_Mou_Yan_Li_2019}{{82}{}{{}}{{}}}
\bibcite{10.1145/219717.219748}{{83}{}{{}}{{}}}
\bibcite{ouyang2022training}{{84}{}{{}}{{}}}
\bibcite{paolini2021structured}{{85}{}{{}}{{}}}
\bibcite{petroni-etal-2019-language}{{86}{}{{}}{{}}}
\bibcite{pi2022logigan}{{87}{}{{}}{{}}}
\bibcite{post-vilar-2018-fast}{{88}{}{{}}{{}}}
\bibcite{qian-etal-2021-glancing}{{89}{}{{}}{{}}}
\bibcite{qin-etal-2019-counterfactual}{{90}{}{{}}{{}}}
\bibcite{qin2022cold}{{91}{}{{}}{{}}}
\bibcite{radford2019language}{{92}{}{{}}{{}}}
\bibcite{raffel2020exploring}{{93}{}{{}}{{}}}
\bibcite{rajani-etal-2019-explain}{{94}{}{{}}{{}}}
\bibcite{raunak-etal-2021-curious}{{95}{}{{}}{{}}}
\bibcite{reiter2019natural}{{96}{}{{}}{{}}}
\bibcite{lime}{{97}{}{{}}{{}}}
\bibcite{rossiello2021generative}{{98}{}{{}}{{}}}
\bibcite{sap-etal-2019-social}{{99}{}{{}}{{}}}
\bibcite{Schulz2020Restricting}{{100}{}{{}}{{}}}
\bibcite{shen2019mixture}{{101}{}{{}}{{}}}
\bibcite{10.1145/3488560.3498431}{{102}{}{{}}{{}}}
\bibcite{10.1007/978-3-030-88480-2_28}{{103}{}{{}}{{}}}
\bibcite{shi-etal-2021-refine-imitate}{{104}{}{{}}{{}}}
\bibcite{DBLP:conf/ai/Shi0Z21}{{105}{}{{}}{{}}}
\bibcite{shi-etal-2021-enhancing}{{106}{}{{}}{{}}}
\bibcite{shu-etal-2021-logic}{{107}{}{{}}{{}}}
\bibcite{shwartz-etal-2020-unsupervised}{{108}{}{{}}{{}}}
\bibcite{Speer_Chin_Havasi_2017}{{109}{}{{}}{{}}}
\bibcite{sun-etal-2018-logician}{{110}{}{{}}{{}}}
\bibcite{10.5555/3305890.3306024}{{111}{}{{}}{{}}}
\bibcite{susanto-etal-2020-lexically}{{112}{}{{}}{{}}}
\bibcite{tafjord-etal-2021-proofwriter}{{113}{}{{}}{{}}}
\bibcite{47786}{{114}{}{{}}{{}}}
\bibcite{thoppilan2022lamda}{{115}{}{{}}{{}}}
\bibcite{thorne-etal-2018-fever}{{116}{}{{}}{{}}}
\bibcite{vanderlyn-etal-2021-seemed}{{117}{}{{}}{{}}}
\bibcite{vaswani2017attention}{{118}{}{{}}{{}}}
\bibcite{velickovic2018graph}{{119}{}{{}}{{}}}
\bibcite{vrandevcic2014wikidata}{{120}{}{{}}{{}}}
\bibcite{wang-etal-2020-heterogeneous}{{121}{}{{}}{{}}}
\bibcite{wang-etal-2019-paperrobot}{{122}{}{{}}{{}}}
\bibcite{wang2022self}{{123}{}{{}}{{}}}
\bibcite{wei2022emergent}{{124}{}{{}}{{}}}
\bibcite{wei2022chain}{{125}{}{{}}{{}}}
\bibcite{weizenbaum1966eliza}{{126}{}{{}}{{}}}
\bibcite{wiegreffe-marasovic-2021-review}{{127}{}{{}}{{}}}
\bibcite{wittgenstein1958blue}{{128}{}{{}}{{}}}
\bibcite{wu-etal-2020-diverse}{{129}{}{{}}{{}}}
\bibcite{wu2016google}{{130}{}{{}}{{}}}
\bibcite{xia-etal-2020-demoting}{{131}{}{{}}{{}}}
\bibcite{xiao-wang-2021-hallucination}{{132}{}{{}}{{}}}
\bibcite{xiao2022survey}{{133}{}{{}}{{}}}
\bibcite{xu-etal-2020-xiaomingbot}{{134}{}{{}}{{}}}
\bibcite{10.1162/tacl_a_00368}{{135}{}{{}}{{}}}
\bibcite{yang2021survey}{{136}{}{{}}{{}}}
\bibcite{ye2022unreliability}{{137}{}{{}}{{}}}
\bibcite{yin-ordonez-2017-obj2text}{{138}{}{{}}{{}}}
\bibcite{yu2022survey}{{139}{}{{}}{{}}}
\bibcite{zeng-etal-2022-neighbors}{{140}{}{{}}{{}}}
\bibcite{zhang2022survey}{{141}{}{{}}{{}}}
\bibcite{zhang-etal-2020-grounded}{{142}{}{{}}{{}}}
\bibcite{zhang-etal-2020-language-generation}{{143}{}{{}}{{}}}
\bibcite{zhou-etal-2019-going}{{144}{}{{}}{{}}}
\bibcite{Zhou2020Understanding}{{145}{}{{}}{{}}}
\bibcite{zhou2022least}{{146}{}{{}}{{}}}
\bibcite{zhou2022survey}{{147}{}{{}}{{}}}
\bibcite{ziems-etal-2022-moral}{{148}{}{{}}{{}}}
\citation{c1,c2}
\citation{c3,c4}
\citation{Bollacker-etal08Freebase}
\citation{c13}
\citation{c14}
\citation{c8,c9}
\citation{c9,c11}
\@writefile{toc}{\vbox {\strut  \hbox to \hsize {\hskip 1\tocindention \begingroup \advance \hsize by -1\tocindention \hbox to \hsize {\vbox {\leftskip \toclhindent \parindent -\toclhindent \rightskip \tocrhindent \parfillskip -\tocrhindent College-Related Question Answering based on Knowledge Graph\unskip \nobreak  \xleaders \hbox to .5em{\hss .\hss }\hfill \penalty 50\xleaders \hbox to .5em{\hss .\hss }\hskip 1em\nobreak  \hbox {}\xleaders \hbox to .5em{\hss .\hss }\hfill {\it  Cheng Peng, Hao Jiang, Junnan Dong, and Xiao Huang\/}\nobreak  \hbox to\tocpagenumwidth {\hss 60}}}\endgroup }\strut  }}
\@writefile{toc}{\contentsline {section}{\numberline {1}INTRODUCTION}{60}{section.1}\protected@file@percent }
\citation{c15}
\citation{c16}
\citation{c9,c11}
\@writefile{toc}{\contentsline {section}{\numberline {2}METHODOLOGY}{61}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Overall Architecture of the Proposed Framework}{61}{subsection.2.1}\protected@file@percent }
\citation{c1,c2}
\citation{c19}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The architecture of the proposed question answering framework.\relax }}{62}{figure.caption.48}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Construction of College-related Knowledge Graph }{62}{subsection.2.2}\protected@file@percent }
\newlabel{sec:Knowledge Graph Construction}{{2.2}{62}{Construction of College-related Knowledge Graph}{subsection.2.2}{}}
\citation{c30}
\citation{c31}
\citation{c8,c9}
\citation{c9,c11}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Rule-based Question Answering}{63}{subsection.2.3}\protected@file@percent }
\newlabel{sec:RULE-BASED QA}{{2.3}{63}{Rule-based Question Answering}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Question Answering based on Knowledge Graph Embedding}{63}{subsection.2.4}\protected@file@percent }
\newlabel{sec:Knowledge Embedding Based KGQA}{{2.4}{63}{Question Answering based on Knowledge Graph Embedding}{subsection.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The workflow of the KGQA component.\relax }}{64}{figure.caption.49}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces The notations in KGQA component and corresponding definitions.\relax }}{64}{table.caption.50}\protected@file@percent }
\newlabel{table:KGQA}{{11}{64}{The notations in KGQA component and corresponding definitions.\relax }{table.caption.50}{}}
\citation{c20}
\citation{c21}
\citation{c20}
\citation{c9,c11}
\citation{c9,c11}
\citation{c15,c22,c23}
\citation{c15,c22}
\citation{c24,c25}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Head Entity Detection Model}{65}{subsubsection.2.4.1}\protected@file@percent }
\newlabel{sec:Head Entity Detection Model}{{2.4.1}{65}{Head Entity Detection Model}{subsubsection.2.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Architectures of head entity detection model and predicate/head entity representation model.\relax }}{65}{figure.caption.51}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Knowledge Graph Embedding}{65}{subsubsection.2.4.2}\protected@file@percent }
\newlabel{sec:Knowledge Graph Embedding}{{2.4.2}{65}{Knowledge Graph Embedding}{subsubsection.2.4.2}{}}
\citation{c22}
\citation{c20}
\citation{c22}
\citation{c26}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}Predicate and Head Entity Representation Models}{66}{subsubsection.2.4.3}\protected@file@percent }
\newlabel{sec:Predicate and Head Entity Representation Models}{{2.4.3}{66}{Predicate and Head Entity Representation Models}{subsubsection.2.4.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.4}Joint Search on Embedding Spaces}{66}{subsubsection.2.4.4}\protected@file@percent }
\newlabel{sec:Joint Search on Embedding Spaces}{{2.4.4}{66}{Joint Search on Embedding Spaces}{subsubsection.2.4.4}{}}
\citation{c26}
\citation{c27}
\citation{c28}
\citation{c29}
\newlabel{eq:prediction}{{15}{67}{Joint Search on Embedding Spaces}{equation.2.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.5}Entity Detection Improvement}{67}{subsubsection.2.4.5}\protected@file@percent }
\newlabel{sec:Entity Detection Improvement}{{2.4.5}{67}{Entity Detection Improvement}{subsubsection.2.4.5}{}}
\newlabel{equ:match}{{16}{67}{Entity Detection Improvement}{equation.2.16}{}}
\citation{c36}
\citation{c33}
\citation{c33}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Content-based Question Answering}{68}{subsection.2.5}\protected@file@percent }
\newlabel{sec:CONTENT-BASED QA}{{2.5}{68}{Content-based Question Answering}{subsection.2.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The workflow of content-based question answering component.\relax }}{68}{figure.caption.52}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}Document Retrieval}{68}{subsubsection.2.5.1}\protected@file@percent }
\newlabel{sec:CONTENT-BASED QA 1}{{2.5.1}{68}{Document Retrieval}{subsubsection.2.5.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.2}Content Reader}{68}{subsubsection.2.5.2}\protected@file@percent }
\newlabel{sec:CONTENT-BASED QA 1}{{2.5.2}{68}{Content Reader}{subsubsection.2.5.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}EXPERIMENTS}{69}{section.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces The accuracy of our question answering framework.\relax }}{69}{table.caption.53}\protected@file@percent }
\newlabel{equ:overall}{{17}{69}{EXPERIMENTS}{equation.3.17}{}}
\bibcite{c1}{{1}{}{{}}{{}}}
\bibcite{c2}{{2}{}{{}}{{}}}
\bibcite{c3}{{3}{}{{}}{{}}}
\bibcite{c4}{{4}{}{{}}{{}}}
\bibcite{Bollacker-etal08Freebase}{{5}{}{{}}{{}}}
\bibcite{c8}{{6}{}{{}}{{}}}
\bibcite{c9}{{7}{}{{}}{{}}}
\bibcite{c11}{{8}{}{{}}{{}}}
\bibcite{c13}{{9}{}{{}}{{}}}
\bibcite{c14}{{10}{}{{}}{{}}}
\bibcite{c15}{{11}{}{{}}{{}}}
\bibcite{c16}{{12}{}{{}}{{}}}
\bibcite{c19}{{13}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {4}CONCLUSIONS AND FUTURE WORK}{70}{section.4}\protected@file@percent }
\bibcite{c20}{{14}{}{{}}{{}}}
\bibcite{c21}{{15}{}{{}}{{}}}
\bibcite{c22}{{16}{}{{}}{{}}}
\bibcite{c23}{{17}{}{{}}{{}}}
\bibcite{c24}{{18}{}{{}}{{}}}
\bibcite{c25}{{19}{}{{}}{{}}}
\bibcite{c26}{{20}{}{{}}{{}}}
\bibcite{c27}{{21}{}{{}}{{}}}
\bibcite{c28}{{22}{}{{}}{{}}}
\bibcite{c29}{{23}{}{{}}{{}}}
\bibcite{c30}{{24}{}{{}}{{}}}
\bibcite{c31}{{25}{}{{}}{{}}}
\bibcite{c33}{{26}{}{{}}{{}}}
\bibcite{c36}{{27}{}{{}}{{}}}
\citation{PanDongXing2020}
\citation{liu2020sentiment}
\citation{jian2016constitution,chen2016implicit,liao2019identification}
\@writefile{toc}{\vbox {\strut  \hbox to \hsize {\hskip 1\tocindention \begingroup \advance \hsize by -1\tocindention \hbox to \hsize {\vbox {\leftskip \toclhindent \parindent -\toclhindent \rightskip \tocrhindent \parfillskip -\tocrhindent Implicit Sentiment Analysis of Chinese Texts based on Contextual Information and Knowledge Enhancement\unskip \nobreak  \xleaders \hbox to .5em{\hss .\hss }\hfill \penalty 50\xleaders \hbox to .5em{\hss .\hss }\hskip 1em\nobreak  \hbox {}\xleaders \hbox to .5em{\hss .\hss }\hfill {\it  Zhenghui Cao, Siqi Wang, Haofen Wang, and Wenqiang Zhang \/}\nobreak  \hbox to\tocpagenumwidth {\hss 72}}}\endgroup }\strut  }}
\@writefile{toc}{\contentsline {section}{\numberline {1}Abstract}{72}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Introduction}{72}{section.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Sentences with different contexts or based on external common sense knowledge can express different sentiments. Expressions carrying positive (smiling face) or negative (crying face) sentiments are highlighted in color. \relax }}{73}{figure.caption.55}\protected@file@percent }
\newlabel{fig:Example}{{1}{73}{Sentences with different contexts or based on external common sense knowledge can express different sentiments. Expressions carrying positive (smiling face) or negative (crying face) sentiments are highlighted in color. \relax }{figure.caption.55}{}}
\citation{erik2017sentiment,liu2020sentiment}
\citation{liao2019identification}
\citation{LiaoJian2018}
\citation{mason2004cormet}
\citation{J2008LakoffGeorge}
\citation{shutova2013statistical}
\citation{shutova2017multilingual}
\citation{zhang2011identifying}
\citation{balahur2011detecting}
\citation{balahur2012detecting}
\citation{zhao2012collocation}
\citation{tong2013can}
\citation{mehndiratta2017detection}
\citation{qian2018hierarchical}
\@writefile{toc}{\contentsline {section}{\numberline {3}Related Work}{74}{section.3}\protected@file@percent }
\citation{liao2017freerl}
\citation{LiaoJian2018,liao2019identification}
\citation{wei2020BiLSTM}
\citation{ZhaoRongMei2020}
\citation{zuo2020context}
\citation{YangShanLiang2021}
\citation{ChenQiuChang2022}
\citation{wang2020chinese}
\citation{PanDongXing2020,samuel2022direct,wang2020chinese}
\@writefile{toc}{\contentsline {section}{\numberline {4}Methodology}{75}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Problem Setup}{75}{subsection.4.1}\protected@file@percent }
\citation{sap2019atomic}
\citation{li2022c3kg}
\newlabel{formula:classification-definition}{{18}{76}{Problem Setup}{equation.4.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Knowledge Graph And Knowledge Retrieval}{76}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Knowledge triples extraction based on rules}{76}{section*.56}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Knowledge triples extraction based on sentiment dictionary matching}{77}{section*.57}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Knowledge triples extraction based on event matching}{77}{section*.58}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Sentiment Analysis Incorporating Contextual Information And External Common Sense Knowledge}{77}{subsection.4.3}\protected@file@percent }
\citation{lin2015learning}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Framework of the model\relax }}{78}{figure.caption.59}\protected@file@percent }
\newlabel{fig:framework-of-the-model}{{2}{78}{Framework of the model\relax }{figure.caption.59}{}}
\@writefile{toc}{\contentsline {paragraph}{Input layer}{78}{section*.60}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Adaptive knowledge fusion layer}{78}{section*.61}\protected@file@percent }
\citation{wei2020BiLSTM}
\newlabel{formula_4_1}{{19}{79}{Adaptive knowledge fusion layer}{equation.4.19}{}}
\@writefile{toc}{\contentsline {paragraph}{Multipolar attention layer fusing contextual contexts}{79}{section*.62}\protected@file@percent }
\newlabel{formula_4_2}{{20}{79}{Multipolar attention layer fusing contextual contexts}{equation.4.20}{}}
\newlabel{formula_4_3}{{21}{79}{Multipolar attention layer fusing contextual contexts}{equation.4.21}{}}
\newlabel{formula_4_4}{{22}{79}{Multipolar attention layer fusing contextual contexts}{equation.4.22}{}}
\newlabel{formula_4_5}{{23}{79}{Multipolar attention layer fusing contextual contexts}{equation.4.23}{}}
\newlabel{formula_4_6}{{24}{80}{Multipolar attention layer fusing contextual contexts}{equation.4.24}{}}
\newlabel{formula_4_7}{{25}{80}{Multipolar attention layer fusing contextual contexts}{equation.4.25}{}}
\newlabel{formula_4_8}{{26}{80}{Multipolar attention layer fusing contextual contexts}{equation.4.26}{}}
\newlabel{formula_4_9}{{27}{80}{Multipolar attention layer fusing contextual contexts}{equation.4.27}{}}
\newlabel{formula_4_10}{{28}{80}{Multipolar attention layer fusing contextual contexts}{equation.4.28}{}}
\@writefile{toc}{\contentsline {paragraph}{Output layer}{80}{section*.63}\protected@file@percent }
\newlabel{formula_4_11}{{29}{80}{Output layer}{equation.4.29}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experimental Setup}{80}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Dataset}{80}{subsection.5.1}\protected@file@percent }
\citation{liao2022dynamic}
\citation{zhang2022incorporating}
\@writefile{lot}{\contentsline {table}{\numberline {13}{\ignorespaces SMP-ECISA 2019 Dataset\relax }}{81}{table.caption.64}\protected@file@percent }
\newlabel{table:smp-ecisa-2019-dataset}{{13}{81}{SMP-ECISA 2019 Dataset\relax }{table.caption.64}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Evaluation Metrics}{81}{subsection.5.2}\protected@file@percent }
\newlabel{formula_4_12}{{30}{81}{Evaluation Metrics}{equation.5.30}{}}
\newlabel{formula_4_13}{{31}{81}{Evaluation Metrics}{equation.5.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Implementation Details}{81}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Baseline Methods}{81}{subsection.5.4}\protected@file@percent }
\citation{wei2020BiLSTM}
\citation{WangSuGe2022}
\citation{zuo2020context}
\citation{che2010ltp}
\citation{tai2015improved}
\@writefile{toc}{\contentsline {paragraph}{Bi-LSTM+multi-attention}{82}{section*.65}\protected@file@percent }
\newlabel{par:Bi-LSTM+MPOA}{{5.4}{82}{Bi-LSTM+MPOA}{section*.66}{}}
\@writefile{toc}{\contentsline {paragraph}{Bi-LSTM+MPOA}{82}{section*.66}\protected@file@percent }
\newlabel{par:CMPOA}{{5.4}{82}{CMPOA}{section*.67}{}}
\@writefile{toc}{\contentsline {paragraph}{CMPOA}{82}{section*.67}\protected@file@percent }
\newlabel{par:CsHGCN}{{5.4}{82}{CsHGCN}{section*.68}{}}
\@writefile{toc}{\contentsline {paragraph}{CsHGCN}{82}{section*.68}\protected@file@percent }
\newlabel{par:Tree-LSTM+KG}{{5.4}{82}{Tree-LSTM+KG}{section*.69}{}}
\@writefile{toc}{\contentsline {paragraph}{Tree-LSTM+KG}{82}{section*.69}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Results And Analysis}{82}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Comparison with Baselines}{82}{subsection.6.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {14}{\ignorespaces Performance of Chinese implicit sentiment analysis\relax }}{83}{table.caption.70}\protected@file@percent }
\newlabel{table:6_1}{{14}{83}{Performance of Chinese implicit sentiment analysis\relax }{table.caption.70}{}}
\@writefile{lot}{\contentsline {table}{\numberline {15}{\ignorespaces Performance of Chinese implicit sentiment analysis The ablations of different components are reported separately in this table, where the model without additional explicit introduction of external common sense knowledge is denoted as ‘-KG’, ‘-MPA’ indicates that no multipolar orthogonal attention mechanism is used in the process of sentiment representation and knowledge incorporation, and ‘-Context’ indicates that no additional contextual information of additional sentiment representation is introduced.\relax }}{83}{table.caption.71}\protected@file@percent }
\newlabel{table:6_2}{{15}{83}{Performance of Chinese implicit sentiment analysis The ablations of different components are reported separately in this table, where the model without additional explicit introduction of external common sense knowledge is denoted as ‘-KG’, ‘-MPA’ indicates that no multipolar orthogonal attention mechanism is used in the process of sentiment representation and knowledge incorporation, and ‘-Context’ indicates that no additional contextual information of additional sentiment representation is introduced.\relax }{table.caption.71}{}}
\bibcite{balahur2011detecting}{{1}{}{{}}{{}}}
\bibcite{balahur2012detecting}{{2}{}{{}}{{}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Ablation Study}{84}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{84}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Acknowledgments}{84}{section.8}\protected@file@percent }
\bibcite{bordes2013translating}{{3}{}{{}}{{}}}
\bibcite{che2010ltp}{{4}{}{{}}{{}}}
\bibcite{chen2016implicit}{{5}{}{{}}{{}}}
\bibcite{ChenQiuChang2022}{{6}{}{{}}{{}}}
\bibcite{erik2017sentiment}{{7}{}{{}}{{}}}
\bibcite{jian2016constitution}{{8}{}{{}}{{}}}
\bibcite{li2022c3kg}{{9}{}{{}}{{}}}
\bibcite{LiaoJian2018}{{10}{}{{}}{{}}}
\bibcite{liao2022dynamic}{{11}{}{{}}{{}}}
\bibcite{liao2019identification}{{12}{}{{}}{{}}}
\bibcite{liao2017freerl}{{13}{}{{}}{{}}}
\bibcite{lin2015learning}{{14}{}{{}}{{}}}
\bibcite{liu2020sentiment}{{15}{}{{}}{{}}}
\bibcite{mason2004cormet}{{16}{}{{}}{{}}}
\bibcite{mehndiratta2017detection}{{17}{}{{}}{{}}}
\bibcite{PanDongXing2020}{{18}{}{{}}{{}}}
\bibcite{qian2018hierarchical}{{19}{}{{}}{{}}}
\bibcite{samuel2022direct}{{20}{}{{}}{{}}}
\bibcite{sap2019atomic}{{21}{}{{}}{{}}}
\bibcite{shutova2017multilingual}{{22}{}{{}}{{}}}
\bibcite{shutova2013statistical}{{23}{}{{}}{{}}}
\bibcite{tai2015improved}{{24}{}{{}}{{}}}
\bibcite{J2008LakoffGeorge}{{25}{}{{}}{{}}}
\bibcite{tong2013can}{{26}{}{{}}{{}}}
\bibcite{vaswani2017attention}{{27}{}{{}}{{}}}
\bibcite{wang2020chinese}{{28}{}{{}}{{}}}
\bibcite{WangSuGe2022}{{29}{}{{}}{{}}}
\bibcite{wei2020BiLSTM}{{30}{}{{}}{{}}}
\bibcite{YangShanLiang2021}{{31}{}{{}}{{}}}
\bibcite{zhang2022incorporating}{{32}{}{{}}{{}}}
\bibcite{zhang2011identifying}{{33}{}{{}}{{}}}
\bibcite{ZhaoRongMei2020}{{34}{}{{}}{{}}}
\bibcite{zhao2012collocation}{{35}{}{{}}{{}}}
\bibcite{zuo2020context}{{36}{}{{}}{{}}}
\citation{kou_social_2016,yang_co-clustering_2022}
\citation{yang_co-clustering_2022}
\@writefile{toc}{\vbox {\strut  \hbox to \hsize {\hskip 1\tocindention \begingroup \advance \hsize by -1\tocindention \hbox to \hsize {\vbox {\leftskip \toclhindent \parindent -\toclhindent \rightskip \tocrhindent \parfillskip -\tocrhindent Hypergraph Clustering Network for Interaction Data\unskip \nobreak  \xleaders \hbox to .5em{\hss .\hss }\hfill \penalty 50\xleaders \hbox to .5em{\hss .\hss }\hskip 1em\nobreak  \hbox {}\xleaders \hbox to .5em{\hss .\hss }\hfill {\it  Tianchi Yang, Luhao Zhang, Cheng Yang, Chuan Shi, Maodi Hu, Tao Li, and Dong Wang\/}\nobreak  \hbox to\tocpagenumwidth {\hss 88}}}\endgroup }\strut  }}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{88}{section.1}\protected@file@percent }
\newlabel{sec:introduction}{{1}{88}{Introduction}{section.1}{}}
\citation{hartigan_algorithm_1979,zhang_maximum_2021}
\citation{ng2001spectral}
\citation{yang_effective_2021}
\citation{min_survey_2018}
\citation{bo_structural_2020,wang_attributed_2019,song_deep_2021,yang_variational_2021}
\citation{song_autoint_2019,xu_disentangled_2021}
\citation{yan_deep_2015}
\citation{xie_unsupervised_2016,wang_attributed_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Examples of interactions from Meituan Waimai\footnotemark [2] and academic networks. \relax }}{89}{figure.caption.73}\protected@file@percent }
\newlabel{fig:example}{{1}{89}{Examples of interactions from Meituan Waimai\protect \footnotemark [2] and academic networks. \relax }{figure.caption.73}{}}
\citation{hinton_reducing_2006}
\citation{hartigan_algorithm_1979}
\citation{ng2001spectral}
\citation{yang_effective_2021}
\citation{min_survey_2018}
\citation{kipf_semi_supervised_2017,kipf_variational_2016}
\citation{bo_structural_2020,wang_attributed_2019,fan_one2multi_2020,song_deep_2021,yang_variational_2021}
\citation{yang2020hypergraph}
\citation{zhang_hyper_sagnn_2020,yadati_hypergcn_2019,tran_directed_2020,hu_adaptive_2021}
\citation{zhou_learning_2006}
\citation{feng_hypergraph_2019}
\citation{kipf_semi_supervised_2017}
\citation{zhu_adaptive_2017}
\citation{hu_adaptive_2021}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{90}{section.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Illustration of HyCLID\nobreakspace  {}(object attributes and interaction conditions are omitted for easy to understand). \relax }}{91}{figure.caption.74}\protected@file@percent }
\newlabel{fig:model}{{2}{91}{Illustration of \modelname ~(object attributes and interaction conditions are omitted for easy to understand). \relax }{figure.caption.74}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{91}{section.3}\protected@file@percent }
\newlabel{sec:model}{{3}{91}{Methodology}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Interaction Modeling via Hypergraph}{91}{subsection.3.1}\protected@file@percent }
\newlabel{mod:construction}{{3.1}{91}{Interaction Modeling via Hypergraph}{subsection.3.1}{}}
\newlabel{def:interaction}{{1}{91}{Interaction Modeling via Hypergraph}{theorem.1}{}}
\citation{hu_adaptive_2021}
\citation{song_autoint_2019}
\citation{feng_hypergraph_2019,hu_adaptive_2021}
\newlabel{def:hypergraph}{{2}{92}{Interaction Modeling via Hypergraph}{theorem.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Rethinking-based Hypergraph Neural Network}{92}{subsection.3.2}\protected@file@percent }
\newlabel{mod:hgnn}{{3.2}{92}{Rethinking-based Hypergraph Neural Network}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Input Layer. }{92}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Layer-wise Aggregation. }{92}{subsubsection.3.2.2}\protected@file@percent }
\citation{song_autoint_2019,xu_disentangled_2021}
\citation{song_autoint_2019,xu_disentangled_2021}
\newlabel{eq:e_aggr}{{33}{93}{Layer-wise Aggregation}{equation.3.33}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Attentive Routing-based Rethinking Mechanism }{93}{subsubsection.3.2.3}\protected@file@percent }
\newlabel{mod:routing}{{3.2.3}{93}{Attentive Routing-based Rethinking Mechanism}{subsubsection.3.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Illustration of the attentive routing-based rethinking mechanism. \relax }}{93}{figure.caption.75}\protected@file@percent }
\newlabel{fig:routing}{{3}{93}{Illustration of the attentive routing-based rethinking mechanism. \relax }{figure.caption.75}{}}
\newlabel{eq:phi}{{35}{93}{Attentive Routing-based Rethinking Mechanism}{equation.3.35}{}}
\newlabel{eq:alpha}{{36}{93}{Attentive Routing-based Rethinking Mechanism}{equation.3.36}{}}
\newlabel{eq:highorder}{{37}{93}{Attentive Routing-based Rethinking Mechanism}{equation.3.37}{}}
\citation{yan_deep_2015}
\citation{xie_unsupervised_2016}
\citation{xie_unsupervised_2016}
\newlabel{eq:update}{{38}{94}{Attentive Routing-based Rethinking Mechanism}{equation.3.38}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}Interaction \& Object Embedding. }{94}{subsubsection.3.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Adaptive Mini-batch Clustering}{94}{subsection.3.3}\protected@file@percent }
\newlabel{mod:batch}{{3.3}{94}{Adaptive Mini-batch Clustering}{subsection.3.3}{}}
\citation{yun_graph_2019}
\@writefile{lot}{\contentsline {table}{\numberline {16}{\ignorespaces Statistics of datasets. \relax }}{95}{table.caption.76}\protected@file@percent }
\newlabel{tab:statistics}{{16}{95}{Statistics of datasets. \relax }{table.caption.76}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Model Training}{95}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{95}{section.4}\protected@file@percent }
\newlabel{sec:experiment}{{4}{95}{Experiments}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Experimental Setup}{95}{subsection.4.1}\protected@file@percent }
\newlabel{exp:setup}{{4.1}{95}{Experimental Setup}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Datasets}{95}{subsubsection.4.1.1}\protected@file@percent }
\citation{hu_adaptive_2021}
\citation{hartigan_algorithm_1979}
\citation{grover_node2vec_2016}
\citation{shi2018heterogeneous}
\citation{bo_structural_2020}
\citation{wang_heterogeneous_2019}
\citation{hu_heterogeneous_2020}
\citation{li_adaptive_2021}
\citation{feng_hypergraph_2019}
\citation{hu_adaptive_2021}
\citation{hu_heterogeneous_2020}
\citation{kingma_adam_2015}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Evaluation Metrics}{96}{subsubsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Baselines}{96}{subsubsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}Implementation Detail}{96}{subsubsection.4.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Analysis of Clustering Results}{96}{subsection.4.2}\protected@file@percent }
\citation{xie_unsupervised_2016}
\citation{xie_unsupervised_2016}
\@writefile{lot}{\contentsline {table}{\numberline {17}{\ignorespaces Clustering results on datasets ACM, IMDB and MT-S (mean$\pm $std in percent). The best and second best results are bold and underlined, respectively. Symbol ``-'' represents unavailable results due to out-of-memory. \relax }}{97}{table.caption.77}\protected@file@percent }
\newlabel{tab:performance}{{17}{97}{Clustering results on datasets ACM, IMDB and MT-S (mean$\pm $std in percent). The best and second best results are bold and underlined, respectively. Symbol ``-'' represents unavailable results due to out-of-memory. \relax }{table.caption.77}{}}
\@writefile{lot}{\contentsline {table}{\numberline {18}{\ignorespaces Clustering results on dataset MT-L. \relax }}{97}{table.caption.78}\protected@file@percent }
\newlabel{tab:app:cluster}{{18}{97}{Clustering results on dataset MT-L. \relax }{table.caption.78}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Ablation Study}{97}{subsection.4.3}\protected@file@percent }
\citation{guo_deepfm_2017}
\citation{song_autoint_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Clustering results of different variants. \relax }}{98}{figure.caption.79}\protected@file@percent }
\newlabel{fig:variant}{{4}{98}{Clustering results of different variants. \relax }{figure.caption.79}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Case Study for Rethinking Mechanism}{98}{subsection.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Heat map visualization for attentive routing-based rethinking mechanism. The rows/columns represent four selected attributes from an interaction case belonging to category ``afternoon tea'' of dataset MT-S, i.e., \textit  {lower consumption level}, \textit  {student}, \textit  {coffee}, \textit  {afternoon}, respectively. \relax }}{98}{figure.caption.80}\protected@file@percent }
\newlabel{fig:case}{{5}{98}{Heat map visualization for attentive routing-based rethinking mechanism. The rows/columns represent four selected attributes from an interaction case belonging to category ``afternoon tea'' of dataset MT-S, i.e., \textit {lower consumption level}, \textit {student}, \textit {coffee}, \textit {afternoon}, respectively. \relax }{figure.caption.80}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Offline Experiment on Recommendation}{98}{subsection.4.5}\protected@file@percent }
\bibcite{bo_structural_2020}{{1}{}{{}}{{}}}
\bibcite{fan_one2multi_2020}{{2}{}{{}}{{}}}
\bibcite{feng_hypergraph_2019}{{3}{}{{}}{{}}}
\bibcite{grover_node2vec_2016}{{4}{}{{}}{{}}}
\bibcite{guo_deepfm_2017}{{5}{}{{}}{{}}}
\bibcite{hartigan_algorithm_1979}{{6}{}{{}}{{}}}
\bibcite{hinton_reducing_2006}{{7}{}{{}}{{}}}
\bibcite{hu_adaptive_2021}{{8}{}{{}}{{}}}
\@writefile{lot}{\contentsline {table}{\numberline {19}{\ignorespaces Top-3 recommendation performance. \relax }}{99}{table.caption.81}\protected@file@percent }
\newlabel{tab:app:rec}{{19}{99}{Top-3 recommendation performance. \relax }{table.caption.81}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{99}{section.5}\protected@file@percent }
\bibcite{hu_heterogeneous_2020}{{9}{}{{}}{{}}}
\bibcite{kingma_adam_2015}{{10}{}{{}}{{}}}
\bibcite{kipf_variational_2016}{{11}{}{{}}{{}}}
\bibcite{kipf_semi_supervised_2017}{{12}{}{{}}{{}}}
\bibcite{kou_social_2016}{{13}{}{{}}{{}}}
\bibcite{li_adaptive_2021}{{14}{}{{}}{{}}}
\bibcite{min_survey_2018}{{15}{}{{}}{{}}}
\bibcite{ng2001spectral}{{16}{}{{}}{{}}}
\bibcite{shi2018heterogeneous}{{17}{}{{}}{{}}}
\bibcite{song_deep_2021}{{18}{}{{}}{{}}}
\bibcite{song_autoint_2019}{{19}{}{{}}{{}}}
\bibcite{tran_directed_2020}{{20}{}{{}}{{}}}
\bibcite{wang_attributed_2019}{{21}{}{{}}{{}}}
\bibcite{wang_heterogeneous_2019}{{22}{}{{}}{{}}}
\bibcite{xie_unsupervised_2016}{{23}{}{{}}{{}}}
\bibcite{xu_disentangled_2021}{{24}{}{{}}{{}}}
\bibcite{yadati_hypergcn_2019}{{25}{}{{}}{{}}}
\bibcite{yan_deep_2015}{{26}{}{{}}{{}}}
\bibcite{yang2020hypergraph}{{27}{}{{}}{{}}}
\bibcite{yang_effective_2021}{{28}{}{{}}{{}}}
\bibcite{yang_variational_2021}{{29}{}{{}}{{}}}
\bibcite{yang_co-clustering_2022}{{30}{}{{}}{{}}}
\bibcite{yun_graph_2019}{{31}{}{{}}{{}}}
\bibcite{zhang_maximum_2021}{{32}{}{{}}{{}}}
\bibcite{zhang_hyper_sagnn_2020}{{33}{}{{}}{{}}}
\bibcite{zhou_learning_2006}{{34}{}{{}}{{}}}
\bibcite{zhu_adaptive_2017}{{35}{}{{}}{{}}}
\citation{ji2021survey,zhang2020aser}
\citation{wang2021benchmarking,lin2021multi,chen2022fuzzy}
\citation{wang2019kgat,wang2019multi,li2021kg4vis}
\citation{evans2011metaknowledge}
\citation{galarraga2013amie,galarraga2015fast,meilicke2019anytime}
\citation{10.1214/ss/1177009870}
\citation{fortunato2018science}
\citation{himmelstein2017systematic}
\@writefile{toc}{\vbox {\strut  \hbox to \hsize {\hskip 1\tocindention \begingroup \advance \hsize by -1\tocindention \hbox to \hsize {\vbox {\leftskip \toclhindent \parindent -\toclhindent \rightskip \tocrhindent \parfillskip -\tocrhindent Distilling Causal Metaknowledge from Knowledge Graphs\unskip \nobreak  \xleaders \hbox to .5em{\hss .\hss }\hfill \penalty 50\xleaders \hbox to .5em{\hss .\hss }\hskip 1em\nobreak  \hbox {}\xleaders \hbox to .5em{\hss .\hss }\hfill {\it  Yuan Meng, Yancheng Dong, Shixuan Liu, Chaohao Yuan, Yue He, Jian Pei, and Peng Cui\/}\nobreak  \hbox to\tocpagenumwidth {\hss 102}}}\endgroup }\strut  }}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{102}{section.1}\protected@file@percent }
\newlabel{section:introduction}{{1}{102}{Introduction}{section.1}{}}
\citation{le2016fast}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Motivation illustration. Consider a scenario to learn rules for inferring the \texttt  {Treat} relation between compounds and diseases on a heart disease KG (\emph {top}), and thereby discover novel drugs for treating nicotine addiction on an addiction disease KG (\emph {bottom}). On the heart disease KG, drugs that treat the same disease often share the same side effects. The correlation-based approach establishes a strong spurious correlation between the shared side-effect information and the \texttt  {treat} relation. In contrast, the underlying cause of the \texttt  {treat} shows a weak association (Rule {\fontfamily  {pzd}\fontencoding  {U}\fontseries  {m}\fontshape  {n}\selectfont  \char 172}). Therefore, when the above rule is migrated to addiction disease KG (drugs that treat the same basic kind of disease often do not have shared side effects), false prediction could be resulted (e.g., Brodalumab is more likely to be prescribed for nicotine addiction, instead of Bupropion).\relax }}{103}{figure.caption.83}\protected@file@percent }
\newlabel{fig:rule_example}{{1}{103}{Motivation illustration. Consider a scenario to learn rules for inferring the \texttt {Treat} relation between compounds and diseases on a heart disease KG (\emph {top}), and thereby discover novel drugs for treating nicotine addiction on an addiction disease KG (\emph {bottom}). On the heart disease KG, drugs that treat the same disease often share the same side effects. The correlation-based approach establishes a strong spurious correlation between the shared side-effect information and the \texttt {treat} relation. In contrast, the underlying cause of the \texttt {treat} shows a weak association (Rule \ding {172}). Therefore, when the above rule is migrated to addiction disease KG (drugs that treat the same basic kind of disease often do not have shared side effects), false prediction could be resulted (e.g., Brodalumab is more likely to be prescribed for nicotine addiction, instead of Bupropion).\relax }{figure.caption.83}{}}
\citation{ji2021survey}
\citation{galarraga_amie_2013}
\@writefile{toc}{\contentsline {section}{\numberline {2}Preliminaries and Problem Statement}{104}{section.2}\protected@file@percent }
\newlabel{section:model}{{2}{104}{Preliminaries and Problem Statement}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Definitions and Notations}{104}{subsection.2.1}\protected@file@percent }
\newlabel{def:horn_rule}{{2.2}{104}{Definitions and Notations}{definitionnew.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Problem Statement}{104}{subsection.2.2}\protected@file@percent }
\citation{rossi2021knowledge,tiwari2021revisiting}
\citation{evans2011metaknowledge}
\citation{evans2011metaknowledge}
\@writefile{toc}{\contentsline {section}{\numberline {3}Proposed Method: \nobreakspace  {}CMLP}{105}{section.3}\protected@file@percent }
\newlabel{section:model}{{3}{105}{Proposed Method: ~\dname }{section.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The framework of\nobreakspace  {}CMLP. Particularly, CFLP first transforms the relational data into propositional data for better statistical analysis. Then it mines interpretable causal rules, which can be interpreted as a kind of metaknowlege\cite  {evans2011metaknowledge}. Finally, a plausibiliy score derived from the causality test is applied in predictor to rank the answers of the given query.\relax }}{105}{figure.caption.84}\protected@file@percent }
\newlabel{fig:framwork}{{2}{105}{The framework of~\dname . Particularly, CFLP first transforms the relational data into propositional data for better statistical analysis. Then it mines interpretable causal rules, which can be interpreted as a kind of metaknowlege\cite {evans2011metaknowledge}. Finally, a plausibiliy score derived from the causality test is applied in predictor to rank the answers of the given query.\relax }{figure.caption.84}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The process of knowledge graph transformer\relax }}{105}{figure.caption.85}\protected@file@percent }
\newlabel{fig:tabular}{{3}{105}{The process of knowledge graph transformer\relax }{figure.caption.85}{}}
\citation{lanning2014dijkstra}
\citation{cui2011based}
\citation{heusner2018best}
\citation{maier2010learning,lee2016learning,lee2020towards,salimi2020causal}
\citation{glymour2016causal}
\citation{giudice2022dual,sondhi2019reduced,gerhardus2020high}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Knowledge Graph Transformer}{106}{subsection.3.1}\protected@file@percent }
\newlabel{sec:tabularnizar}{{3.1}{106}{Knowledge Graph Transformer}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Causal variables in KG}{106}{subsubsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Transforming knowledge graph into propositional data}{106}{subsubsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Causal MetaKnowlege Discovery via $d$-seperation Criterion}{107}{subsection.3.2}\protected@file@percent }
\newlabel{sec:discovery}{{3.2}{107}{Causal MetaKnowlege Discovery via $d$-seperation Criterion}{subsection.3.2}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Local causal metaknowledge discovery\relax }}{107}{algocf.1}\protected@file@percent }
\newlabel{alg:pc-like}{{1}{107}{Causal MetaKnowlege Discovery via $d$-seperation Criterion}{algocf.1}{}}
\citation{marx2019testing}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces An example of bidirectional causal relationship, which may lead wrong results.\relax }}{108}{figure.caption.87}\protected@file@percent }
\newlabel{fig:bidirection}{{4}{108}{An example of bidirectional causal relationship, which may lead wrong results.\relax }{figure.caption.87}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces An example of non-independent rule-induced variables, which are both the causes of queried relation.\relax }}{108}{figure.caption.88}\protected@file@percent }
\newlabel{fig:direct_cause_example}{{5}{108}{An example of non-independent rule-induced variables, which are both the causes of queried relation.\relax }{figure.caption.88}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Link Prediction based on Explainable Causal Metaknowledge}{108}{subsection.3.3}\protected@file@percent }
\newlabel{sec:link_pred}{{3.3}{108}{Link Prediction based on Explainable Causal Metaknowledge}{subsection.3.3}{}}
\citation{marx2019testing}
\citation{ji2021survey}
\citation{ji2021survey}
\citation{balazevic2019tucker}
\citation{rossi2021knowledge}
\newlabel{eq:weight}{{44}{109}{Link Prediction based on Explainable Causal Metaknowledge}{equation.3.44}{}}
\newlabel{eq:link-prediction-sum}{{45}{109}{Link Prediction based on Explainable Causal Metaknowledge}{equation.3.45}{}}
\newlabel{eq:link-prediction-avg}{{46}{109}{Link Prediction based on Explainable Causal Metaknowledge}{equation.3.46}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental Study}{109}{section.4}\protected@file@percent }
\newlabel{section:experiment}{{4}{109}{Experimental Study}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Experimental Setup}{109}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}\textbf  {Baselines}}{109}{subsubsection.4.1.1}\protected@file@percent }
\citation{galarraga2015fast}
\citation{meilicke2019anytime}
\citation{yang2017differentiable}
\citation{qu2020rnnlogic}
\citation{balazevic2019tucker}
\citation{himmelstein2017systematic}
\@writefile{lot}{\contentsline {table}{\numberline {20}{\ignorespaces Dataset statistics of all the experiments.\relax }}{110}{table.caption.89}\protected@file@percent }
\newlabel{tab:dataset_statistics}{{20}{110}{Dataset statistics of all the experiments.\relax }{table.caption.89}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}\textbf  {Datasets}}{110}{subsubsection.4.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The causal graph of relation paths, based on which the simulated KGs are generated .\relax }}{110}{figure.caption.90}\protected@file@percent }
\newlabel{fig:simulation}{{6}{110}{The causal graph of relation paths, based on which the simulated KGs are generated .\relax }{figure.caption.90}{}}
\citation{himmelstein2017systematic}
\citation{himmelstein2017systematic,ratajczak2022task}
\citation{rossi2021knowledge,balazevic2019tucker,bordes2013translating}
\citation{rossi2021knowledge,ruffinelli2020you}
\citation{zheng2018dags,zheng2020learning}
\@writefile{lot}{\contentsline {table}{\numberline {21}{\ignorespaces The parameters of conditional distributions.\relax }}{111}{table.caption.91}\protected@file@percent }
\newlabel{tab:simulation_set}{{21}{111}{The parameters of conditional distributions.\relax }{table.caption.91}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}\textbf  {Metrics.}}{111}{subsubsection.4.1.3}\protected@file@percent }
\newlabel{eq:mrr}{{47}{111}{\textbf {Metrics.}}{equation.4.47}{}}
\newlabel{eq:hitk}{{48}{111}{\textbf {Metrics.}}{equation.4.48}{}}
\newlabel{eq:precision}{{49}{111}{\textbf {Metrics.}}{equation.4.49}{}}
\citation{tang2020investigating,wu2021self}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}\textbf  {Out-of-Distribution Link Prediction}}{112}{subsubsection.4.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Performance of Link prediction task in Out-of-Distrition Settings}{112}{subsection.4.2}\protected@file@percent }
\citation{sadeghian2019drum}
\@writefile{lot}{\contentsline {table}{\numberline {22}{\ignorespaces The results of link prediction on simulation datasets.\relax }}{113}{table.caption.92}\protected@file@percent }
\newlabel{tab:simulation_result}{{22}{113}{The results of link prediction on simulation datasets.\relax }{table.caption.92}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Quality and Interpretability of Causal Rules.}{113}{subsection.4.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {23}{\ignorespaces MRR (left) and Hits@5 (right) for Douban movie rating. The * marks columns that contain the I.I.D results. Other columns contain OoD results.\relax }}{114}{table.caption.93}\protected@file@percent }
\newlabel{tab:douban-mrr}{{23}{114}{MRR (left) and Hits@5 (right) for Douban movie rating. The * marks columns that contain the I.I.D results. Other columns contain OoD results.\relax }{table.caption.93}{}}
\@writefile{lot}{\contentsline {table}{\numberline {24}{\ignorespaces MRR(left) and Hits@5(right) for drug repurposing on Hetionet. The * marks columns that contain the I.I.D results. Other columns contain OoD results.\relax }}{114}{table.caption.94}\protected@file@percent }
\newlabel{tab:hetionet-mrr}{{24}{114}{MRR(left) and Hits@5(right) for drug repurposing on Hetionet. The * marks columns that contain the I.I.D results. Other columns contain OoD results.\relax }{table.caption.94}{}}
\@writefile{lot}{\contentsline {table}{\numberline {25}{\ignorespaces Experimental results on simulation data with $p_{X_1}=0.5$, based on the metrics (precision, recall and SHD), which are commonly used to evaluate the estimated causal graph.\relax }}{115}{table.caption.95}\protected@file@percent }
\newlabel{tab:simulation_rule_quality}{{25}{115}{Experimental results on simulation data with $p_{X_1}=0.5$, based on the metrics (precision, recall and SHD), which are commonly used to evaluate the estimated causal graph.\relax }{table.caption.95}{}}
\@writefile{lot}{\contentsline {table}{\numberline {26}{\ignorespaces All rules whose head are $R_3$ and $R_5$, obtained by each algorithm learned on simulated dataset. The strikethroughs indicate the wrong results (there is no entities satisfying the rule). The rules consistent with the generation process are in bold. The orange text denotes the weight of each rule with the form max-normalization(original weight)\relax }}{115}{table.caption.96}\protected@file@percent }
\newlabel{tab:simulation_rule}{{26}{115}{All rules whose head are $R_3$ and $R_5$, obtained by each algorithm learned on simulated dataset. The strikethroughs indicate the wrong results (there is no entities satisfying the rule). The rules consistent with the generation process are in bold. The orange text denotes the weight of each rule with the form max-normalization(original weight)\relax }{table.caption.96}{}}
\citation{imbens2010rubin}
\citation{pearl2010causal}
\citation{spirtes2000causation}
\@writefile{lot}{\contentsline {table}{\numberline {27}{\ignorespaces Top 5 Rules to infer HighRate(User, Movie) given by the methods. The strikethroughs indicate the wrong results (there is no entities satisfying the rule). \relax }}{116}{table.caption.97}\protected@file@percent }
\newlabel{tab:rules_recom_result}{{27}{116}{Top 5 Rules to infer HighRate(User, Movie) given by the methods. The strikethroughs indicate the wrong results (there is no entities satisfying the rule). \relax }{table.caption.97}{}}
\@writefile{lot}{\contentsline {table}{\numberline {28}{\ignorespaces Top 5 Rules to infer Treats(Compound, Disease) given by the methods. For brevity, we use `C' and `D' for compound and disease, respectively.\relax }}{116}{table.caption.98}\protected@file@percent }
\newlabel{tab:rule_hetionet}{{28}{116}{Top 5 Rules to infer Treats(Compound, Disease) given by the methods. For brevity, we use `C' and `D' for compound and disease, respectively.\relax }{table.caption.98}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Related Work}{116}{section.5}\protected@file@percent }
\newlabel{section:related}{{5}{116}{Related Work}{section.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {29}{\ignorespaces Comparison of our work and related work.\relax }}{116}{table.caption.99}\protected@file@percent }
\newlabel{tab:related}{{29}{116}{Comparison of our work and related work.\relax }{table.caption.99}{}}
\citation{maier2010learning,lee2016learning,lee2020towards,salimi2020causal}
\citation{maier2013sound}
\citation{galarraga2013amie,galarraga2015fast,omran2019embedding}
\citation{meilicke2019anytime}
\citation{yang2017differentiable}
\citation{sadeghian2019drum}
\citation{qu2020rnnlogic}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion and Future work}{117}{section.6}\protected@file@percent }
\newlabel{section:conclusion}{{6}{117}{Conclusion and Future work}{section.6}{}}
\bibcite{10.1214/ss/1177009870}{{1}{}{{}}{{}}}
\bibcite{balazevic2019tucker}{{2}{}{{}}{{}}}
\bibcite{bordes2013translating}{{3}{}{{}}{{}}}
\bibcite{chen2022fuzzy}{{4}{}{{}}{{}}}
\bibcite{cui2011based}{{5}{}{{}}{{}}}
\bibcite{evans2011metaknowledge}{{6}{}{{}}{{}}}
\bibcite{fortunato2018science}{{7}{}{{}}{{}}}
\bibcite{galarraga2015fast}{{8}{}{{}}{{}}}
\bibcite{galarraga2013amie}{{9}{}{{}}{{}}}
\bibcite{galarraga_amie_2013}{{10}{}{{}}{{}}}
\bibcite{gerhardus2020high}{{11}{}{{}}{{}}}
\bibcite{giudice2022dual}{{12}{}{{}}{{}}}
\bibcite{glymour2016causal}{{13}{}{{}}{{}}}
\bibcite{heusner2018best}{{14}{}{{}}{{}}}
\bibcite{himmelstein2017systematic}{{15}{}{{}}{{}}}
\bibcite{imbens2010rubin}{{16}{}{{}}{{}}}
\bibcite{ji2021survey}{{17}{}{{}}{{}}}
\bibcite{lanning2014dijkstra}{{18}{}{{}}{{}}}
\bibcite{le2016fast}{{19}{}{{}}{{}}}
\bibcite{lee2016learning}{{20}{}{{}}{{}}}
\bibcite{lee2020towards}{{21}{}{{}}{{}}}
\bibcite{li2021kg4vis}{{22}{}{{}}{{}}}
\bibcite{lin2021multi}{{23}{}{{}}{{}}}
\bibcite{maier2013sound}{{24}{}{{}}{{}}}
\bibcite{maier2010learning}{{25}{}{{}}{{}}}
\bibcite{marx2019testing}{{26}{}{{}}{{}}}
\bibcite{meilicke2019anytime}{{27}{}{{}}{{}}}
\bibcite{omran2019embedding}{{28}{}{{}}{{}}}
\bibcite{pearl2010causal}{{29}{}{{}}{{}}}
\bibcite{qu2020rnnlogic}{{30}{}{{}}{{}}}
\bibcite{ratajczak2022task}{{31}{}{{}}{{}}}
\bibcite{rossi2021knowledge}{{32}{}{{}}{{}}}
\bibcite{ruffinelli2020you}{{33}{}{{}}{{}}}
\bibcite{sadeghian2019drum}{{34}{}{{}}{{}}}
\bibcite{salimi2020causal}{{35}{}{{}}{{}}}
\bibcite{sondhi2019reduced}{{36}{}{{}}{{}}}
\bibcite{spirtes2000causation}{{37}{}{{}}{{}}}
\bibcite{tang2020investigating}{{38}{}{{}}{{}}}
\bibcite{tiwari2021revisiting}{{39}{}{{}}{{}}}
\bibcite{wang2019multi}{{40}{}{{}}{{}}}
\bibcite{wang2019kgat}{{41}{}{{}}{{}}}
\bibcite{wang2021benchmarking}{{42}{}{{}}{{}}}
\bibcite{wu2021self}{{43}{}{{}}{{}}}
\bibcite{yang2017differentiable}{{44}{}{{}}{{}}}
\bibcite{zhang2020aser}{{45}{}{{}}{{}}}
\bibcite{zheng2018dags}{{46}{}{{}}{{}}}
\bibcite{zheng2020learning}{{47}{}{{}}{{}}}
\@writefile{toc}{\vskip \bigskipamount }
\@writefile{toc}{\smallskip \hrule \smallskip }
\@writefile{toc}{\vbox {\strut  \hbox to \hsize {\hskip 0\tocindention \begingroup \advance \hsize by -0\tocindention \hbox to \hsize {\vbox {\leftskip \toclhindent \parindent -\toclhindent \rightskip \tocrhindent \parfillskip -\tocrhindent \textbf {\Large  \strut  Conference and Journal Notices}\hfil \hbox {}}}\endgroup }\strut  }}
\@writefile{toc}{\vskip \smallskipamount }
\@writefile{toc}{\vbox {\strut  \hbox to \hsize {\hskip 1\tocindention \begingroup \advance \hsize by -1\tocindention \hbox to \hsize {\vbox {\leftskip \toclhindent \parindent -\toclhindent \rightskip \tocrhindent \parfillskip -\tocrhindent TCDE Membership Form\unskip \nobreak  \xleaders \hbox to .5em{\hss .\hss }\hfill \penalty 50\xleaders \hbox to .5em{\hss .\hss }\hskip 1em\nobreak  \hbox {}\xleaders \hbox to .5em{\hss .\hss }\hfill {\it  \/}\nobreak  \hbox to\tocpagenumwidth {\hss 122}}}\endgroup }\strut  }}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\gdef \@abspage@last{126}
