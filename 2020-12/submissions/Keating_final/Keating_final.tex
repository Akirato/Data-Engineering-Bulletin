\documentclass[11pt,dvipdfm]{article}
%\documentclass[11pt]{article} %The above line must be used for your camera-ready submission, which requires a latex -> DVI -> PDF compilation pipeline.  As a workaround while you are writing your paper, you could comment it out and use this line instead, which is compatible with pdflatex.
\usepackage{deauthor,times,graphicx,hyperref} 

\renewcommand{\thesection}{\Roman{section}} 

\begin{document}
\title{Responsible Design Through Interdisciplinary Collaboration:  Contact Tracing Apps, Surveillance \\and the Prospect of Building User Trust }
\author{Jennifer Keating\\University of Pittsburgh\\jennifer.keating@pitt.edu}


\maketitle
\begin{abstract}
The recently released Apple/ Google Contact Tracing applications have faced low uptake in users throughout the United States in comparison to other nations where legislative mandates require the use of contact tracing applications to limit transmission of the novel Covid-19 virus amidst global pandemic.  What features of the application designs could have been developed with a higher prioritization of potential users’ trust?  What specters of surveillance, incursions on privacy or narratives compounding power inequity with already vulnerable populations could have been avoided had Google and Apple designers and engineers intentionally collaborated with experts in the humanities from design phase to roll out?  What implications could this have had on the ongoing pandemic and rates of transmission in Western countries like the United States?
\end{abstract}

\section{Introduction:  The Case of Standards}

In fall 2018 John Havens, author of \emph{Heartificial Intelligence} and Executive Director of the IEEE Global Initiative for Ethics of Autonomous and Intelligent Systems, visited Carnegie Mellon University.  His visit had multiple purposes:  a workshop dinner on responsible design for undergraduate and graduate students; an interview for the \emph{AI \& Humanity Oral Archive}; and a visit to my co-taught first-year undergraduate interdisciplinary seminar, \emph{AI \& Humanity}.  Ethical design and responsibility were front of mind. It was a pivotal moment, where engaging with the next generation of technologists and the institutions that train them was crucial.  It was a time for individual technologists and academics, as well as organizations like IEEE, to provide leadership and guidance as we navigated questions pertaining to social and cultural influences of technology.  The questions were old but the tools’ capabilities and the range of our willingness to relinquish consequential decision-making to these tools, was, and continues to be, new.   

In 2018 we were in the wake of a lethal accident in Tempe, Arizona, where an Uber experimental autonomous vehicle struck a pedestrian.  Another accident with a semi-autonomous Tesla vehicle had left a driver dead.  Concerns in regard to AI and robotic systems replacing wide swaths of the labor force the world over, and increased pressure on the ethical implications of AI in consequential decision making, whether in case law review, medical diagnoses or drone warfare, were in the news.  Surveillance, the protection of data and the dissemination of misinformation via social media, in the context of the Facebook Cambridge Analytica scandal, continued to unfold.  And increasing concern on the use of deadly force, whether in drone warfare abroad or predictive policing at home, also filled mainstream and fringe media coverage.  Things were moving fast.  Culturally and socially speaking, real and perceived AI advances were hot topics, and establishments like IEEE were moving in step with world events to develop standards that could productively slow potentially reckless innovation.  IEEE led conversations and recommendations to incorporate ethical standards and responsible design features that could be carefully integrated into the innovation and development of tools that were increasingly embedded in everyday life.   Educational institutions, governments and corporations alike, formed curricular design teams, ethical boards of review and committees to ensure current technologists and developing practitioners alike, would come to understand the grave responsibility of their roles in developing intelligent technological systems. 

While visiting Pittsburgh, Havens described IEEE’s work and the honor he feels in undertaking his role within the organization.  He shared, “IEEE, it’s the world’s largest technology association, started 130 years ago by Thomas Edison.  It’s a very respected organization (with) 420,000 members in 160 countries.  But really (it’s) the heart of the engineering community.”  He went on to disclaim that he is not an engineer but in regard to his work with IEEE standards, learning from this process as a witness and as a facilitator, he described a sense of wonder at the processes.  He was humbled by the power and the influence of an IEEE standard.  In the AI \& Humanity Oral Archive he states:
\begin{quote}
	I’ve been on Broadway, right.  I can get up in front of two thousand people and sing.  You want to lead a standards group, you’d better have thick skin and be ready to navigate a room full of experts but also people that are, in terms of communicating, there’s a very specific thing called a requirement amongst engineers, which I didn’t know about.  I remember I had to struggle, people kept saying ‘well the requirement for this’ and I was like, ‘Oh, do I check with Bob, you know, in IEEE to make this?’ And they were like, ‘No, it’s a requirement.’  They kind of gave me this face, ‘It’s a requirement’ (AI \& Humanity Oral Archive, \url{www.aiandhumanity.org}).
\end{quote}
Havens’ steep learning curve on the influence of IEEE standards on curricula in education and industry practices is perhaps a humorous anecdote.  But the power of these standards, especially in crucial moments of delicate innovation that can deeply influence the lives of a few or many, are poignant reminders of the implications for such efforts.  These standards help to ensure advancement that mitigates bias or harm, they help to uphold expectations for such ethical responsibility from design phase to manufacturing.  Havens’ disclaimer that he is not an engineer is wittily shared in the story to demonstrate both his own unfamiliarity with IEEE practices and to highlight the spheres of influence amongst technologists that an IEEE standard might reach.  But his own involvement with IEEE came about because he was an outsider to IEEE, a humanist, whose work happened to waywardly step onto a path that was unfamiliar but betrayed his own predilection for inquiry.  His outsider status, in the context of his own work with IEEE, turned out to be an asset. 

John Havens’ ability to bring basic though powerful questions pertaining to ethical expectations to IEEE is valuable and perhaps speaks to the poignancy of IEEE as an organization, its membership in practitioners the world over, to engage meaningful collaborations as teachers, designers and engineers.  In describing his initiation as a practitioner in the AI and intelligent systems areas, Havens states: 
\begin{quote}
	My work in AI began out of straight up fear.  I was doing a series of interviews for Mashable.  I’ve written for Mashable, and the Guardian, and Slate, and I wasn’t in the AI space.  But about eight years ago I started interviewing people saying, ‘what’s the code of ethics for AI?’ And thinking, everyone would refer to like, ‘Oh, it’s the Smithton Code written in 1985.’  And more and more what happened is people said, ‘Well, we use the Asimov’s Three Laws of Robotics as our kind of code to ask questions.’  And initially, I was like that’s a short story from the fifties.  I’m a big fan of the story [but] it started from fear (AI \& Humanity Oral Archive, \url{www.aiandhumanity.org}).
\end{quote}
Although collaborative development of codes of ethics and standards are still in process, efforts have come a long way from Haven’s initial involvement as a reporter for Mashable in 2010.  That said, considerable progress is still needed.  Havens describes fear, or perhaps horror, in learning that a science fiction novel series served as a foundational concept for vetting new systems and safeguarding against the prospect of harm, bias or unintended ill consequences for new technologies’ integration into everyday life.  These systems can range from algorithms for mortgage approval processes to filters for Human Resources examination of resumes for open job postings to experimental driverless vehicles, each of which have small and enormous effects on the lives of individuals and groups when biases or faults occur and propagate at scale.  As Havens opened up lines of inquiry as a journalist, to hold technologists accountable, he underscored the importance of harnessing expertise in a variety of fields to partner with engineers who design systems that infiltrate many more aspects of daily life.  In his commitment to these initial curiosities, Havens converts these lines of inquiry from sexy news article pitches into meaningful engagement with IEEE members and leaders to develop standards for responsible design, as the Executive Director of IEEE Global Initiative for Ethics of Autonomous and Intelligent Systems.  This leadership role is a testament to both IEEE’s recognition of the value of interdisciplinary leadership but also to the thoroughness and collaboration needed for future standards to hold the necessary influence and adherence to ethical expectations for responsibility.  

Ethical design has become a priority in principled discourse pertaining to advancing autonomous and intelligent systems with work extending in a myriad of directions. One example is Dorian Peters, Karina Vold, Diana Robinson and Rafael A. Calvo’s ``Responsible AI --- Two Frameworks for Ethical Design Practice'' (IEEE Transactions on Technology and Society, Vol. 1, No. 1, March 2020).  In this recent publication, Peters et al., articulate the concerns of moving from the P7000 standards project principles to actual practice\footnote{For details on Standard P7000 see:  \url{https://development.standards.ieee.org/myproject-web/public/view.html\#pardetail/5799}.  Synopsis in this context includes: 
	
	\noindent \textbf{The scope of proposed standard:}  The standard establishes a process model by which engineers and technologists can address ethical consideration throughout the various stages of system initiation, analysis and design.  Expected process requirements include management and engineering view of new IT product development, computer ethics and IT system design, value-sensitive design, and, stakeholder involvement in ethical IT system design.  
	
	\noindent \textbf{Purpose:}  Engineers, technologists and other project stakeholders need a methodology for identifying, analyzing and reconciling ethic concerns of end users at the beginning of systems and software life cycles.  The purpose of this standard is to enable the pragmatic application of this type of Value-Based System Design methodology which demonstrates that conceptual analysis of values and an extensive feasibility analysis can help to refine ethical system requirements in systems and software life cycles.  This standard will provide engineers and technologists with an implementable process aligning innovation management processes, IS system design approaches and software engineering methods to minimize ethical risk for their organizations, stakeholders and end users.  
}.  Their work illustrates the concerns and challenges of such moves from principle to practice, as Havens expressed, but it is also emblematic of the value of the IEEE standards.  Without this guidance, it is virtually impossible to move to collective responsible practices.  A key finding in ``Responsible AI –-- Two Frameworks for Ethical Design Practice,'' as it recounts the practice of developing digital mental health technologies, hinges on the role of collaboration across disciplines to meaningfully achieve the scope of P7000.  If the standard’s scope is “to establish a process model by which engineers and technologists can address ethical consideration throughout the various stages of system initiation, analysis and design” then the practice of such goals in specific device and tool development is crucial to communicate and illustrate in practice, not just in aspiration. In this dynamic publication the case study, as much as the practices leading up to the development of the case study, carry close to equal weight.  It is an object lesson in moving from principle to practice, which delineates the steps articulated in the purpose of Standard P7000 as it: ``provide(s) engineers and technologists with an implementable process aligning innovation management processes, IS system design approaches and software engineering methods to minimize ethical risk for their organizations, stakeholders and end users'' (IEEE P7000).  Havens’ advocacy for bringing experts in various disciplines to the essential design to scale manufacturing or adoption of new devices and systems is embodied in this work.  It serves as a useful model as we consider other cases like recent contact tracing applications in a pandemic, and the adoption or lack thereof of this tool, due to varying levels of trust and distinct cultural and political contexts.  

\section{A Case:  Contact Tracing in the Time of Covid}

By mid-March, 2020 the world was brought to a relative stand-still.  Covid-19 had made its way through parts of China, Italy and Iran.  It had landed in the United States, Japan, Germany, the United Kingdom, South Africa, Thailand, India and other parts of the world.  What looked like a short-term epidemic that could be readily handled by developed governments and public health professionals, was quickly shaping into a pandemic.  From March onward the World Health Organization, and its member states, were brought to their respective knees.  Several months into the pandemic there are suggested ‘success’ states, nations whose governmental management of the pandemic rivals other states’ relative mismanagement of virus transmission and mitigation against its citizens’ death.  Leading the world in infection rates and Covid-19 related deaths is the United States (as of December 2020).  With over 299,000 deaths and more than 16,258,000 infected, the United States presently leads the world in fatalities and infections (Johns Hopkins Coronavirus Resource Center \url{https://coronavirus.jhu.edu/}).  By comparison, an often-cited case for standards in virus transmission management, South Korea has logged 43,000 cases of infection and 587 deaths.  While controversial in regard to governmental surveillance of citizens, compromised privacy and compounding prejudice and marginalization of already vulnerable populations, South Korea’s contact tracing efforts have yielded tremendous success.  But what questions arise in regard to surveillance and compromise of privacy in the case of South Korea’s efforts to mitigate transmission of Covid-19?  How do contact-tracing applications compound marginalization already faced by vulnerable populations?  How might we learn from past lessons where temporary tools are introduced in the name of public health but continue in their use well-after the public health crisis into other areas of surveillance that can exacerbate power differentials between citizens and their government?

The Google and Apple recently launched contact tracing application serves as a useful object lesson in rapidly developed tools that can have unintended consequences if not carefully used, monitored and understood, within a specific time frame and context.  The new applications, which can scale to all Google and Apple users with a simple “opt-in” selection, allows the tech giants to make a contribution to alleviating the implications of an ongoing pandemic by giving local, state or national governments a basic tool kit to build more specific applications for contact tracing in their local environment.  According to Russell Brandom at The Verge,
\begin{quote}
	The exposure notification system was initially designed to avoid excess data collection, but the introduction of out-of-the-box apps means slightly more data will be collected by Apple and Google. iOS will still collect general device analytics and crash information (if the users have opted in). The auto-generated Android app will collect de-identified system info including API error calls, but the team says there’s still no collection of data that could identify which specific users have been exposed. Google has also committed to publishing the source code of the auto-generated Android app to enable third-party audits (Brandom).
\end{quote}
While these “out-of-the box apps” can prove a crucial contribution from the tech-sector to alleviate some of the crushing economic and social implications of rolling shutdowns and challenges in manual contact tracing in the Covid-19 pandemic, how are Google and Apple users to trust a system that has already fallen down on the “slightly more data to be collected” detail of the new app?  Google and Apple claim that their system offers public health officials, governments and other entities, overrun in triage efforts in recent months, an opportunity to tailor a basic application system to meet the needs of their particular community to control outbreak and community transmission.  While the “out-of-the box app” is perhaps a valuable contribution to public good, how can Apple and Google garner trust in a public that is already wary of their size, power and influence on individuals and nation-states?  If governmental agencies and public health officials wish to garner trust, confidence and adherence to strict behavioral guidelines to prevent further transmission of Covid-19, how can they assure users that data gathered will only be used for the emergency contact tracing needed presently?  What emergency concessions are individuals willing to make and what assurances do they have that once the pandemic diminishes Google, Apple and governmental entities will not all use these same emergency applications for other more sinister but equally powerful agendas like political coercion, surveillance of population movement or relentless advertising?  How can the current design features of the app be better explained to users before they ‘opt in,’ so that they can readily describe both the capabilities and limitations of these devices before deciding to use them?

Unfortunately, media coverage even in recent months already suggest reasons for concern.  Following the recent roll out of the shell applications for Android and iOS, Forbes Magazine’s Zak Doffman reported on a Serge Vaudenay and Martin Vuagnoux’s video on Hackaday that ``claims to show a flaw in the secure exposure tracing framework that allows users to be tracked.  The POC targeted Switzerland’s SwissCovid app, but the researchers say it works on other apps leveraging Apple and Google’s exposure notification framework'' (Doffman)\footnote{  For further detail on Serge Vaudenay’s and Martin Vuagnoux’s concerns in regard to SwissCovid see: \url{https://lasec.epfl.ch/people/vaudenay/swisscovid.html} }.  As the prospect of user tracking negatively impacts the user take-up of the application, the tool is rendered close to useless.  If a critical number of community members are reticent to opt-in to use the application, then its use-function in tracing contacts is rendered obsolete.  Trust matters.  And the prospect of individual and community trust is compromised when tools are designed without explicit considerations of user trust, amidst a myriad of other values, in ethical and responsible design. 
 
Doffman states, ``if not enough people download and adhere to the apps, then the system doesn’t work.''  But should we be surprised that in Western countries there are significant examples of apprehension in signing up for this level of prospective tracking?  How have Google and Apple garnered trust with prospective users to ensure that the contact tracing app will do only what it is supposed to do? I.e. Serve as a tool to control outbreak of disease amidst pandemic?  What assurances are the public given in the tools’ design and the safeguards in its recommended uses by Apple, Google and the municipalities or governmental entities that use this application, to protect the data and civil rights of those who opt-in to use the tool only in the context of our current health crisis?    Rather than offering a solution to a complex and runaway health crisis, the application’s roll out and description by its designers undermine user trust.  As evidenced in Richard Bird’s op-ed in Forbes on September 10th, the contact tracing app appears to cause almost as much consternation and discourse on legislative regulation of big tech in regard to privacy concerns, as there is recommendation for its use in Covid-19 hotspots to curb transmission.  He writes,
\begin{quote}
	Google has addressed privacy concerns related to location tracking by announcing that with the release of Android 11, devices won’t need to have location settings on to use ENS.  But that doesn’t solve all the issues these apps pose.  While the technology may help slow the spread of coronavirus, it comes at a big social cost and poses what I see as the biggest ethics quandary in my 20 years in the infosec industry.  These apps will force citizens to rely on big tech companies ---whose business is enabled by monetizing data--- to protect the privacy of their sensitive data.  These apps play on humanity’s greatest fear:  our mortality (Bird).
\end{quote}
In the midst of pandemic, the existential threat of the contagion is real.  Its effects are a poignant reminder of our individual and collective vulnerability as we witness record setting transmission rates and death rates in the United States.  That said, the pandemic will eventually end.  And what can individual citizens do to protect their data and privacy rights if the government and big tech have converged to track movement, buying patterns or any myriad of information based on a social contract undertaken in the context of our present emergency?  What features of the design could have embedded these concerns in regard to wellbeing from the beginning, to garner the trust needed in societies where the population must opt-in, rather than abide by legislative mandate, to yield widespread use of these valuable public health tools?\footnote{The primary focus of this discussion on wellbeing and the social contract of collective wellbeing, underscores the importance of broader discourse on AI and trust.  For extended discussion on trust and developing technology pertaining to the existential threats of surveillance, weaponry and military use of AI in consequential decision making, see \underline{AI \& Humanity} by Illah Nourbakhsh and Jennifer Keating, MIT Press 2020.}

A counter example to the lack of uptake in regard to contact tracing apps in the United States is the national contact tracing app used in South Korea.  Although a successful model in public health as the tool assists in expedient tracing of contacts associated with developing outbreaks, it has also raised concerns in regard to tracking locations of some of society’s marginalized or vulnerable populations.  In May, an outbreak associated with gay clubs in the Itaewon neighborhood of Seoul went public and led to tracking down individuals who frequented the clubs.  Although many filed false names on club registers and guest books for fear of being outed in a relatively conservative culture that upholds traditional expectations of gender roles and sexuality, South Korea’s public health laws allow for searches into other means of tracking individuals ranging from ``credit card statements, security footage and smartphone data'' (Yoon \& Martin).   The national laws, rather than individuals’ decisions to opt-in to contact tracing apps or other mechanisms to safeguard public health, align population behaviors with governmentally sanctioned regulations to curb transmission in the midst of pandemic.  As the government synthesized data from club guest records with credit card statements, security footage and smartphone data, they could then publicly announce who they tracked as implicated in the localized outbreak, all under the premise of protecting public health.  But how does this social contract bear out after the pandemic passes?  What vestiges of blanketed surveillance in South Korea are likely to remain outside the purview of public health legislation when the pandemic ends?  And what recourse do individual citizens have to protest such translations of an application’s use after the crisis has passed? 

\section{Principles \& Practice}

In their discussion of ``Responsible Design Process'' in ``Responsible AI --– Two Frames for Ethical Design Practice,'' Peters, Vold et al. lay out a dynamic interrogation of well-being and its role in responsible design.  They write:
\begin{quote}
	An important aspect of responsible innovation is the concept of human wellbeing, which is also at the center of many current ethical frameworks.  For example, the IEEE centers its ethics specification on human wellbeing.  So too do several government frameworks [4], [5].
	
	As such, we argue that a responsible technology development process will need to incorporate evidence-based methods for evaluating the impact on, and designing for, human wellbeing by drawing on psychology (see [32], [33]).
	
	However, the promotion of human wellbeing is not a complete solution.  After all, decisions must be made as to whose wellbeing is being considered.  When technology makers are forced to make tradeoffs that increase the wellbeing of some but at the expense of others, at the cost of long-term ecological impacts, or in spite of other negative side effects, then issues to do with justice, equality and other values arise.  This is where ethical analysis, drawing on philosophy and other disciplines, must come in. 
	
\end{quote}
The concept of wellbeing is situated within a complex context when considering responsible and ethical design of tools that will have scaled use.  ``When technology makers are forced to make tradeoffs that increase the wellbeing of some but at the expense of others \ldots then issues to do with justice, equality and other values arise.''   Peters, Vold et al, go on to claim that ``drawing on philosophy and other disciplines, must come in.''   As practitioners adhering to the goal of translating Standard P7000 principles into practice, technologists have identified colleagues in philosophy, psychology and design as reliable collaborators who can inform and influence their work.  Such collaborations open up the opportunity for technologists and designers to meaningfully integrate social concerns from device inception through manufacturing or scaled uptake of applications into their work.  But what gains might be made if the scope of collaborators were widened further?  What can humanists bring to the process, as exemplified by John Havens’ work, with lines of inquiry that are endemic to methods and practices in regard to communication, veracity of language and cultural theory in the humanities?  How can humanists guide engineers and computer scientists to layer expertise in social and political context into their device development to ensure greater care and strong intuitions to safeguard against unintended consequences that force ``tradeoffs that increase the wellbeing of some but at the expense of others?''

The unintended social and cultural implications of contact tracing applications in South Korea, in tandem with the legislative purview of public health legislation, open the likelihood that location tracking can “out” the private sexual lives of South Korean citizens in the name of urgent public health concerns articulated as localized outbreak.  In the context of the United States, citizen distrust seems to proliferate in their relationships with Apple, Google, state and federal governments.  There is concern that sensitive data, ranging from location tracing to other features of habit like consumer practices and community connections, can be gathered through emergency contact tracing applications, stored, and then used for more sinister purposes when the health emergency has ended.  These are the concerns in the American public that can compromise the prospect of an application’s use.  They are also the concerns that South Korean citizens might share but are explicitly undermined due to legislative mandates that ensure citizens and foreign visitors use the contact tracing applications (Shin).   While a myriad of rationales in the present moment indicate these tensions and reticence to adopt the contact tracing apps in the U.S. or in South Korea, there are also historic precedents that influence citizens’ reluctance to forego privacy in the name of public good.  Emergency tools like the passport at the turn of the twentieth century indicate the manner in which a temporary solution to a short-term political and public health crisis (in the context of World War I and the Spanish Flu Pandemic) can be co-opted into mass adoption and remain as an institutional feature in a society.   By learning more about social and cultural influence in the present and the past, technologists might better prepare future emergency tools that are needed for rapid design and implementation.  In reaching out to a wider variety of practitioners across the disciplines, to identify collaborators who can assist with laying out predictable distrust or concern with a prospective tool, technologists can more successfully integrate deeper cultural concerns into any form of responsible design for tools with widespread use.

In ``Immunity Passports:  A ``New'' Old Idea with Baggage,'' Emilian Kavalski and Nicholas Ross Smith offer insight on the movement for specific tools from an emergency context in the name of ``wellbeing,'' to permanent fixtures in a society.  In the example of the passport, now ubiquitous for confirmation of membership in virtually any nation state, and needed to move across any border, they remind us that these tools were once temporary.  At the outbreak of World War I, the passport was a novel, temporary tool to regulate movement across borders that were in flux and contention, in that period’s rise of nationalism. Their utility shifted again in the context of pandemic.   Kavalski and Smith write:
\begin{quote}
	The idea of immunity passports is not a new concept, however.  Before the First World War, essentially one did not need a passport to travel.  If a person had the means to pay for their fare and the ability to procure work and accommodation, they could travel (largely) unhindered across national borders.
	
	It was only the start of the war that led European countries to begin closely monitoring their borders for security reasons.  At the end of the war, the intention of the signatories of the 1919 Treaty of Versailles, however, was a return to the pre-war ``freedom of communications and of transit.''  The preamble to the resolution adopted at the 1920 Paris Conference on Passports and Customs Formalities and Through Tickets suggested that passports were only a temporary measure until ``the pre-war conditions [are] gradually re-established.''
	
	But, the onset of the Spanish Flu pandemic put a spanner in the works.  The death toll, which surpassed that of the war itself, revealed the vulnerability of modern states linked by globalization to pandemics.  Thus, in the wake of the Paris Conference, the concept of passports mutated to also regulate the movement of people owing to ``considerations of health or national security.''
	
	Furthermore, the demands of post-war reconstruction and recovery put a premium on healthy populations.  It was decided that one of the best ways to ensure the wellbeing of the citizenry was through regulating who could enter the territory of the state and who could not. 	
\end{quote}
The implications for the necessity of passports was exacerbated in the context of World War II, as European refugees sought safe harbor in their flight from German National Socialists’ rapid expansion throughout the region.  In the present moment, however, contact tracing applications, immunity passports and other modes to confirm health status speak to governmental ``considerations of health,'' primarily.  But in the political context of social unrest in the United States, and in various locations throughout the world presently, what prevents this health measure’s translation into a tool to ensure ``national security'' instead?  Just like the passport and its history?  Could a latent familiarity with such social and political slippage inherently influence citizens’ mistrust of these applications if the location tracking elements used in contract tracing applications were re-tooled to track locations of known protestors in Portland, Oregon, Washington, D.C. or Atlanta, Georgia?  And how might the design, undertaken by technologists at Google and Apple, have instilled better trust of these systems had such considerations been integrated into the earliest iterations of their development?

\section{Engaging Principles \& Practice}
In the opening of the third chapter of \underline{Discipline and Punish}, Michel Foucault considers pandemic in the context of the plague.  He describes the societal implication of rudimentary surveillance in the name of contact tracing as he writes: 
\begin{quote}
	This enclosed, segmented space, observed at every point, in which the individuals are inserted in a fixed place, in which the slightest movements are supervised, in which all events are recorded, in which an uninterrupted work of writing links the center and periphery, in which power is exercised without division, according to a continuous hierarchical figure, in which each individual is constantly located, examined, and distributed among the living beings, the sick, and the dead –-- all this constitutes a compact model of the disciplinary mechanism.  The plague is met by order, its function is to sort out every possible confusion:  that of the disease, which is transmitted when bodies are mixed together; that of the evil, which is increased when fear and death overcome prohibitions.  It lays down for each individual his place, his body, his disease and his death, his well-being, by means of an omnipresent and omniscient power that subdivides itself in a regular, uninterrupted way even to the ultimate determination of the individual, of what characterizes him, of what belongs to him, or what happens to him.  Against the plague, which is a mixture, discipline brings into play its power, which is one of analysis.  A whole literary fiction of the festival grew up around the plague:  suspended laws, lifted prohibitions, the frenzy of passing time, bodies mingling together without respect, individuals unmasked, abandoning their statutory identity and the figure under which they had been recognized, allowing a quite different truth to appear.  But there was also a political dream of the plague, which was exactly its reverse:  not the collective festival, but strict divisions; not laws transgressed, but the penetration of regulation into even the smallest details of everyday life through the mediation of the complete hierarchy that assured the capillary functioning of power; not masks that were put on and taken off, but the assignment to each individual of his ``true'' name, his ``true'' place, his ``true'' body, his ``true'' disease.  The plague as a form, at once real and imaginary, of disorder had as its medical and political correlative discipline.  Behind the disciplinary mechanisms can be read the haunting memory of “contagion,” of the plague, of rebellions, crimes, vagabondage, desertions, people who appear and disappear, live and die in disorder. (Foucault 197--198).
\end{quote}
The human will to execute power over existential threats like disease, to bring order to the chaotic, is imbued in our contemporary tools as well. Foucault cites the response to plague as “medical and political correlative discipline.”  We can see features of these reactions in the context of contract tracing applications in our current pandemic.  But as individuals and groups square up to the discipline needed to control the chaos of a viral threat, we also witness the range of reactions and their effects.  In South Korea, governmental strides to preserve individual and collective “wellbeing” is achieved through legislative reach that ensure governmental “omnipresent and omniscient power that subdivides itself in a regular, uninterrupted way even to the ultimate determination of the individual, of what characterizes him, of what belongs to him, or what happens to him.”   Relinquishment of such individual privacy and agency preserves the lives of the collective, to the tune of 587 deaths to Covid-19 in South Korea.    By comparison, without such centralized power wielded by a federal government perhaps there were periods of festival in the midst of the pandemic in the United States?  Perhaps there were moments of “suspended laws, lifted prohibitions, the frenzy of passing time, bodies mingling together without respect, individuals unmasked” in the name of independence and freedom?  And perhaps these betrayed a deep and poignant resistance to even a modicum of “the penetration of regulation into even the smallest details of everyday life through the mediation of the complete hierarchy that assured the capillary functioning of power; not masks that were put on and taken off, but the assignment of each individual of his “‘true’ name, his ‘true’ place his ‘true’ body, his ‘true’ disease.”  The prioritization of such independence, such resistance to a carefully orchestrated hierarchy of discipline and power held by a local municipality, a state or the federal government in the United States has at least inadvertently led to the deaths of over 299,000 due to Covid-19.  But it also indicates the political, social and cultural influences that undermine and co-opt even the best-intentioned public health outreach efforts in the name of “well-being.”  In the current circumstances we witness how contact tracing applications in varied political and social contexts can only go so far in their efficacy without responsible design paired with either deep trust on its limited use in the current public emergency to encourage users to opt-in or legislative mandate for its use.  

As Peters, Vold, et al. suggest, ``the promotion of human wellbeing is not a complete solution \ldots When technology makers are forced to make tradeoffs that increase the wellbeing of some but at the expense of others, at the cost of long-term ecological impacts, or in spite of other negative side effects, then issues to do with justice, equality and other values arise.  This is where ethical analysis, drawing on philosophy and other disciplines, must come in.''  What gains might have been made in adoption of the Apple and Google development of a contact tracing application had they truly consulted with practitioners outside of their organizations in meaningful ways not only in their tool’s design but also in careful communication about the applications’ capabilities, its limitations or perhaps the narrow window of time and circumstance in which they would allow its use?  As he extends an exploration of a ``whole literary fiction of the festival [that] grew up around the plague,'' Foucault argues that the surveillance state formulated to safeguard against the existential threat of plague was momentarily conceded or tolerated in the name of well-being or survival.  It survived in many manifestations in the name of containing political contagions to safeguard against rebellion, resistance and revolution.  Its vestiges extend, he argues, into the ordering of academic disciplines as well.  

In a deep and detailed argument that traces the surveillance state erected to mitigate effects of pandemic to an analysis of Bentham’s panopticon to its literal and figurative features in contemporary juridical and political power, Foucault extends the discussion to academic disciplines.  He writes,  

\begin{quote}
	The minute disciplines, the panopticism of every day may well be below the level of emergence of the great apparatuses and the great political struggles.  But, in the genealogy of modern society, they have been, with the class domination that traverses it, the political counterpart of the juridical norms according to which powered was redistributed.  Hence, no doubt, the importance that has been given for so long to the small techniques of discipline, to those apparently insignificant tricks that it has invented, and even to those ``sciences'' that give it a respectable face; hence the fear of abandoning them if one cannot find any substitute; hence the affirmation that they are at the very foundation of society, and an element in its equilibrium, whereas they are a series of mechanisms for unbalancing power relations definitively and everywhere; hence the persistence in regarding them as the humble, but the concrete form of every morality, whereas they are a set of physio-political techniques (Foucault 223).  
\end{quote} 
As we consider these disciplines in relation to ethical standards, cross-disciplinary collaborations and the need to consider how seemingly inert tools are woven deeply in the fabric of society, perhaps Peters, Vold et al. indicate just how important cross-disciplinary work will be to reinscribing the deeply rooted power systems that Foucault also explores.  There are certainly the practicalities of cross-disciplinary practices that can uphold or translate principles into practice as technologists strive to find meaningful device design and development that can indeed privilege wellbeing for all parties and not just for some.  And as it becomes clear that prioritization of wellbeing for some will be at the cost of others, then perhaps a deep and meaningful interrogation of how the “small techniques” of a discipline, which are perhaps at the “very foundation of society,” can also serve as the techniques and practices that can be reshuffled to inform alterations and potential improvements to particular features of society through interdisciplinary collaboration in various sectors of society?  Perhaps if we can attune engineers and technologists to the very issues and concerns in society that indicate the need for particular tools, these tools can be developed and designed to more carefully meet these needs?  Perhaps deep and meaningful engagement with experts in domains like rhetoric, composition, literature and cultural studies, history and political science, can enable technologists to better parse the needs and concerns in society that lead to requests or indeed, demands, for particular tools to attend to emergent needs and wants?\footnote{For further discussion on such collaboration, see \underline{AI \& Humanity} by Jennifer Keating and Illah Nourbakhsh, MIT Press 2020.}    

Narrative, a mode of making and an object of study in my own discipline, is a useful conveyance of information, messaging and testimonies that express the messiness of human experience.  It is a sequencing of events, a relationship to temporality and a conveyance of information that other humans often respond to with emotion, empathy or solidarity as they fall into the experience of hearing a story.  As Havens recounts, science fiction novels like “Asimov’s Three Laws of Robotics” can even be used “as our kind of code to ask questions” in a discipline that slowly finds their devices increasingly circulating in the wilds of humanity.  But what if IEEE standard developers and practitioners in industry and the academy alike, deeply engaged with the possibility of meaningful and layered interaction and collaboration with humanists?  What if exploration and examination of narratives, in addition to ethics and design, were integrated into responsible design practices and early educational practices and curricular designs?  

Uneven success of devices and applications like the Google and Apple contact tracing application could have been avoided for a myriad of reasons: cultural, political, social and otherwise.  But what if the designers had to read a novel like Ann Burns' 2018 novel Milkman before they set about designing the application or decided on language for rolling out the device in summer 2020?  What if they were attuned to the turmoil, reticence and deeply-held fear of surveillance that is both explicitly expressed or implicitly manifested in what has led to limited opting-in in the tool’s use throughout the United States because they were sensitized to such concerns through the distance afforded through reading and examining fictional narrative?  Milkman, which was awarded the Booker Prize, is described by the Chair of Judges, Kwame Anthony Appiah, as a novel that
\begin{quote}
	\ldots delineates brilliantly the power of gossip and societal pressure in a tight-knit community, and shows how both rumour and political loyalties can be put in the service of a relentless campaign of individual sexual harassment.  Burns draws on the experience of Northern Ireland during the Troubles to portray a world that allows individuals to abuse the power granted by a community to those who resist the state on their behalf (Appiah).  
\end{quote}
In this clever novel, Burns presents the short-term and long-term effects of the surveillance state on each of the characters, which is readily captured in playful banter identifiable to its location in Northern Ireland.  In a relatively early passage, Burns embodies the blanket of surveillance and its figurative soaking qualities on all those who inhabit such a state through dialogue between Middle Sister and Brother-in-Law, as Middle Sister laments:
\begin{quote}
	\ldots I decided to forgive brother-in-law for his out-of-character criticism, which was what I did, then a tree by the top reservoir took a picture of us as we ran by.  This hidden camera clicked, just one click, a state-forces click, in the similar way to how that bush, positioned along this same reservoir, had done a week earlier.  O dear, I thought.  I hadn’t considered that.  What I meant was I hadn’t considered that the state would now associate anyone I was associating with also with the milkman as they were associating me now with the milkman.  Already within a week of that first click, I’d been clicked again four times.  Once had been in town, once when walking into town, then twice coming out of town.  I’d been photographed from a car, from a seemingly disused building, also from other bits of greenery; perhaps too, there’s been other clicks I hadn’t picked up on at the time.  Each occasion when I did hear them, the camera would snap as I passed and so, yes, it seemed I’d fallen into some grid, maybe the central grid, as part of the disease, the rebel-infection.  And now, others in my company, such as poor, innocent brother-in-law, were to be implicated also as associates of an associate.  Brother-in-law, however, just as had the milkman, completely ignored the click.  ‘Why are you ignoring that click?’ I asked.  ‘I always ignore the clicks,’ he said.  ‘What do you expect me to do?  Get outraged?  Write letters?  Keep a diary? Put in a complaint?  Get one of my personal secretaries to contact the United Nations Amnesty International Ombudsman Human Rights peaceful demonstration people?  Tell me, sister, who do I contact and what do I say, and while you’re about it, what are you going to do about the click yourself?’  Well, I was going to have amnesia of course.  In fact, here I was, already having it.  ‘I don’t know what you mean,’ I said.  ‘I’ve forgotten it,’ his forthrightness having sent me immediately into \emph{jamais vu} (Burns 66).
\end{quote}
While a playful yet serious account of varied responses to the surveillance state, we see in this short excerpt the small and large implications of prolonged exposure to devices that track location and collate information or even offer the semblance of such collation on individuals and their psyche.  In Middle Sister’s ``jamais vu'' or Brother-In-Law’s decision to ignore the ‘click,’ both characters offer a myriad of responses that must be decided upon each time they are rendered conscious of tracking. Whether it is once a day, once a run or once a week, each character illustrates the individual and collective effect of constant watch in a surveillance state.  What if engineers and technologists could be reminded of such comic and tragic reactions to tracking?  What if serious conversation could be undertaken with the safe veil of distance afforded through examination of fictional narrative?

As John Havens discussed the significance of IEEE standards in our interview back in 2018, neither of us could have imagined the world we would inhabit in fall 2020.  But the concerns associated with responsible design and the power of IEEE standards are more crucial now than ever.  As we consider fairness, susceptibility to bias and the challenges that technologists are asked to attend to through device design and application creation, possibilities abound for meaningful solutions as well as misses.  From IEEE standards, to translation of such standard principles to practice to curricular design at universities that train the next generation of engineers and computer scientists, we each have our role to play in this work.  The next step in responsible design might be a deeper engagement with next iterations of meaningful cross-disciplinary collaboration.

 
\vspace{-.1cm}
\bibliographystyle{ACM-Reference-Format}
\begin{thebibliography}{10}
\begin{small}
\itemsep=-.5pt

\bibitem{1}
Appiah, Kwame Anthony.  ``Comments: Milkman (Booker Prize),'' 2018. \\ \url{https://thebookerprizes.com/books/milkman-by} 

\bibitem{2}
Barry, John M.  \underline{The Great Influenza:  The Story of the Deadliest Pandemic in History}.  New York:  Penguin Books, 2018.

\bibitem{3}
Bird, Richard.  \emph{Contact Tracing Apps Reinforce the Need For A Federal Data Privacy Standard}.  Forbes Magazine, September 10, 2020.

\bibitem{4}
Brandom, Russell.  \emph{Apple and Google Announce New Automatic App System to Track COVID Exposures}.  The Verge, September 1, 2020.

\bibitem{5}
Burns, Anna.  \underline{Milkman}.  London:  Faber \& Faber, 2018.

\bibitem{6}
Doffman, Zak.  \emph{Why Your Apple / Google Covid-19 Contact Tracing App Has an Awkward New Problem}.  Forbes Magazine, September 4, 2020.

\bibitem{7}
Keating, Jennifer \& Illah Nourbakhsh. \emph{John Havens:  AI \& Humanity Oral Archive.} (\url{www.aiandhumanity.org}) 

\bibitem{8}
Foucault, Michel.  \underline{Discipline \& Punish:  The Birth of the Prison} (2nd Edition). New York:  Vintage Books, 1995. 

\bibitem{9}
IEEE Standard P7000:   \url{https://development.standards.ieee.org/myproject-web/public/view.html\#pardetail/5799}

\bibitem{10}
Johns Hopkins University, Covid-19 Dashboard by the Center for Systems Science and Engineering (CSSE).  \url{https://coronavirus.jhu.edu/map.html} 

\bibitem{11}
Kavalski, Emilian \& Nicolas Ross Smith.  \emph{Immunity Passports:  A “New” Old Idea with Baggage}.  Global Policy: Opinion, April 27, 2020.  Durham University, School of Government and International Affairs \& Wiley-Blackwell.

\bibitem{12}
Mason, Rowena, Rajeev Syal and Dan Sabbagh.  \emph{No 10 Seeks to End Coronavirus Lockdown with ‘Immunity Passports.’} The Guardian, April 2, 2020.

\bibitem{13}
Nourbakhsh, Illah \& Jennifer Keating.  \underline{AI \& Humanity}.  Cambridge:  MIT Press, 2020.

\bibitem{14}
Peters, Dorian, Karina Vold, Dianoa Robinson, and Rafael A.. Calvo.  \emph{Responsible AI --- Two Frameworks for Ethical Design Practice}.  IEEE Transactions on Technology and Society.  Vol. 1, No. 1, March 2020.

\bibitem{15}
Procter, Kate, Ian Sample \& Philip Oltermann.  \emph{‘Immunity Passports’ Could Speed Up Return to Work After Covid-19.}  The Guardian, March 30, 2020.

\bibitem{16}
Shin, Sally.  \emph{How South Korea Has Eliminated Coronavirus Risk From Foreign Travelers}.  NBC News, September 27, 2020. 

\bibitem{17}
Spinney, Laura.  \underline{Pale Rider}.  New York:  Public Affairs, 2017.

\bibitem{18}
The Guardian \emph{Editorial.  The Guardian View on Immunity Passports:  An Idea Whose Time Has Not Come.}  The Guardian, April 3, 2020.

\bibitem{19}
Yoon, Dasl \& Timothy W. Martin. \emph{‘What if My Family Found Out?’: Korea’s Coronavirus Tracking Unnerves Gay Community}.  Wall Street Journal, May 12, 2020. 

\end{small}
\end{thebibliography}

\end{document}
