\documentclass[11pt]{article}

\usepackage{deauthor,times,graphicx}
%\usepackage{url}

\begin{document}

Knowledge graphs, which were originally branded and popularized by Google in 2012, have attracted a lot of attention in both academia and industry. A knowledge graph is generally a graph-structured knowledge base that can leverage many graph processing and storage tools to perform knowledge representation and reasoning. Recently, machine learning, especially deep learning, has been widely used in many problems, including knowledge graph representation and reasoning. Thus, after more than ten years the term knowledge graph has been used, there are many new developments that are based on machine learning. First, machine learning models, particularly, graph representation learning, can be used to learn the representations of knowledge graph entities and relations. With the new representations, many reasoning tasks such as complex knowledge graph query, rule induction, knowledge base completion, and knowledge base population can be built based on learning models. Machine learning models can generalize better on knowledge graphs, where open-world assumption usually applies. Second, many new knowledge graph construction methods are based on machine learning. Information extraction and the recent ``language model as a knowledge base'' are all much improved with the development of scalable deep learning. With strong machine learning models, much less annotated data are required to construct many domain-specific knowledge graphs. Thus, many new types of knowledge graphs are recently developed. In this issue, we included several papers on learning and reasoning on knowledge graphs and applications.


The first paper {\it Logical Queries on Knowledge Graphs: Emerging Interface of Incomplete Relational Data} and the second paper {\it Knowledge Graph Comparative Reasoning for Fact Checking: Problem Definition and Algorithms} discussed the recent development of machine learning-based reasoning on knowledge graphs and its generalization ability to tackle the open world assumption problem of existing knowledge graphs. The following two papers, {\it A Perspective Survey on Industrial Knowledge Graphs: Recent Advances, Open Challenges, and Future Directions} and {\it Harnessing Knowledge and Reasoning for Human-Like Natural Language Generation: A Brief Review} reviewed the recent development of knowledge graph construction, where the former one surveyed new technologies on domain-specific knowledge graph construction, in particular, industrial knowledge graphs, while the latter surveyed the recent popular idea on  ``language model as a knowledge base'' which leverages the power of natural language generation to acquire knowledge for knowledge graph construction. Then the following three papers {\it College-Related Question Answering based on Knowledge Graph}, {\it College-Related Question Answering based on Knowledge Graph}, and {\it Implicit Sentiment Analysis of Chinese Texts based on Contextual Information and Knowledge Enhancement} studied applications of knowledge representation learning, knowledge-based question answering, and knowledge enhanced natural language processing problems. Finally, the last paper {\it Distilling Causal Metaknowledge from Knowledge Graphs} discussed how to distill causal metaknowledge from existing knowledge graphs, which is a very interesting and promising new direction of knowledge graph-related research.

I would like to thank all the authors for their contributions to make this issue an interesting discussion about present and future research directions related to knowledge graph representation learning and reasoning.


\end{document}
