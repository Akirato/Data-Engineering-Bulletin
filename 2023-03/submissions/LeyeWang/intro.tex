\section{Introduction}

With the popularity of smart mobile devices, such as smartphones, pads, and vehicles, crowdsensing has become one promising paradigm for sensing urban dynamics \citep{ganti2011mobile}. A typical crowdsensing process first recruits participants and then asks them to upload the data of interest to the central server. Afterward, the server aggregates the data from participants toward a synthetic sensed result \citep{zhang20144w1h,ma2014opportunities}. While each participant's sensed data may include noise, an important issue is how to ensure the accuracy of the aggregated sensed result, often called \textit{truth discovery} \citep{wang2012truth,meng2015truth,Wang2014SurrogateMS}.

Many research studies have been devoted to the truth discovery for crowdsensing applications. Generally, most relevant studies model participant trustworthiness and sensed data confidence iteratively to obtain the final aggregated sensed result \citep{yin2008truth}. The basic idea is that a high-credit participant's sensed data should be assigned with high confidence; a user whose sensed data are more confident should be more trustworthy. While this has been verified to be effective, the iterative computation process needs a central server to collect every participant's raw sensed data, which may bring privacy threats to crowdsensing participants. For example, crowdsensing usually asks participants to do sensing tasks at specific locations, and thus most sensed data are associated with detailed location information \citep{zhang20144w1h}. The traditional truth discovery process would inevitably leak crowdsensing participants' visited locations during sensing periods, which may be exploited by malicious third parties to conduct serious location privacy breaches such as physical stalking \citep{Primault2019TheLR}. With the user privacy and personal data regularization (e.g., General Data Protection Regulation\footnote{\url{https://gdpr.eu/eu-gdpr-personal-data}}) becoming more and more important nowadays, we believe that a privacy-preserving truth discovery algorithm is urgently required for facilitating more extensive crowdsensing campaigns in practice.

Privacy-preserving truth discovery has been recently studied in crowdsensing.  Existing studies are usually based on some hardly realized assumptions such as every participant being always online and/or non-colluding \citep{Miao2015CloudEnabledPT,Miao2017ALP,Miao2019PrivacyPreservingTD}\footnote{Some participants' relations can be very close such as family members, and thus it is non-reasonable to assume that they will not collude with each other.}, or two non-colluding servers (or fog nodes) are required \citep{Tang2018NonInteractivePT,Zheng2018LearningTT,Zhang2021ReliableAP,ZHANG2020101848}. These assumptions hinder the practical applications of the prior mechanisms. 
More importantly, almost all the prior studies do not discuss two fundamental issues in privacy-preserving truth discovery.

i) \textbf{Participants' Completed Tasks Protection.} Existing mechanisms focus on protecting participants' sensed data, but most assume that participants' completed tasks are known to the crowdsensing server \citep{Xu2019EfficientAP,Miao2015CloudEnabledPT,Miao2019PrivacyPreservingTD,Zheng2018LearningTT}. However, sometimes task information is more sensitive than sensed data. Suppose the tasks are air quality sensing at certain points of interest. If a participant's task completion information is disclosed (e.g., finish a sensing task at the Times Square NYC), then her location is revealed without the need to know her sensed air quality value.

ii)  \textbf{Participants' Trustworthiness Assessment.} Trustworthiness assessment is a key part of crowdsensing for participant recruitment and incentive design \citep{Peng2018DataQG}, while privacy-preserving truth discovery needs to hide participants' trustworthiness scores for privacy protection. To address the dilemma, a privacy-preserving trustworthiness assessment method needs to be proposed.

In this paper, we aim to design a novel and practical privacy-preserving truth discovery mechanism for crowdsensing to overcome the pitfalls of prior studies. In particular, our design follows the federated learning (FL) paradigm \citep{konevcny2016federated,yang2019federated}. We thus call our method as \textit{FedTruthFinder}. In general, FL requires user clients to do some local computation (e.g., learning the gradients for updating the parameters of the model) on their devices and then only upload the computation results instead of raw data. For a specific algorithm, the local computation and uploading process usually incorporates certain secure mechanisms (e.g., homomorphic encryption and secure multi-party computation) to ensure that no user privacy is leaked theoretically \citep{chai2020secure,liu2020secure}. 
Based on FL, we aim to consider the following specific issues in the design of FedTruthFinder.


\textbf{No Accuracy Loss}: We expect that FedTruthFinder will not hurt the accuracy of the aggregated sensed results compared to the centralized truth discovery. Without the loss of accuracy, crowdsensing organizers would be likely to adopt the method in practice.

\textbf{No Third Party}: Crowdsensing involves a central server and a set of participants' clients. To make FedTruthFinder easy to deploy, we do not want to introduce any more third parties which are usually hard to find in reality \citep{Bonawitz2017PracticalSA,Wang2017LocationPT}.


\textbf{Robustness against Unpredictable Connection Loss}: While crowdsensing participants travel around the whole city, their device connection with the central server is not always stable. Hence, it is necessary to make FedTruthFinder effective when some participants lose connections suddenly.



With the above issues in consideration, this paper makes the following contributions:

(1) To the best of our knowledge, this paper is the first study that addresses the problem of privacy-preserving crowdsensing truth discovery with (i) \textit{participants' completed task protection}, and (ii) \textit{participants' trustworthiness assessment}.

(2) We propose \textit{FedTruthFinder}, a novel privacy-preserving truth discovery mechanism following the federated learning paradigm \citep{yang2019federated}. FedTruthFinder does not need any third party and can tolerate participants' unpredictable connection loss. The two key components of FedTruthFinder are (i) \textit{federated confidence computation} to learn the probability of a sensed event, and (ii) \textit{federated trustworthiness ranking} to assess participants' sensed data quality.

(3) We have conducted both theoretical analysis and empirical evaluations for FedTruthFinder. In particular, FedTruthFinder can reduce the system failure probability significantly compared to state-of-the-art privacy-preserving truth discovery approaches~\citep{Bonawitz2017PracticalSA,Xu2019EfficientAP}, and achieve good detection accuracy.
