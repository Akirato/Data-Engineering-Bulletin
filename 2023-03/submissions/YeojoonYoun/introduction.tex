\section{Introduction}

Federated learning (FL) has attracted much attention from both academia and industry due to the increasing demand for large-scale distributed machine learning systems and preserving privacy-sensitive data on local devices such as smartphones and IoT devices. In federated learning, a number of clients collaboratively learn the global objective function by communicating with a central server without sharing any locally stored data in each local device. The research in Federated learning has identified four major challenges: communication efficiency, systems heterogeneity, statistical heterogeneity, and privacy \citep{li2020federated}. In this paper, we focus on communication efficiency that is of primary interest in cross-device settings when there is a heavy communication burden with many edge computing devices and limited network bandwidth. Two of the most widely used methods to reduce the communication cost are federated averaging optimization and randomized compression techniques.

\begin{table*}[!htbp]
\caption{Summary of Results on the Convergence Rate and Communication Required for Linear Speedup. $M$ is the number of devices, $T$ is the number of total parallel iterations, and $K$ is the number of communication rounds, $q$ is a quantization parameter (Assumption \ref{assumption1}), $d_{\text{quant}}$ is the number of bits used to quantize, $d_{\text{full}}$ is the number of bits required when there is no quantization ($d_{\text{full}} \gg d_{\text{quant}}$). \citet{yuan2020federated} and FedAQ send two iterates per communication round as other algorithms to achieve acceleration (See line 11 in Algorithm \ref{algorithm1}), we multiply $d_{\text{full}}$ and $d_{\text{quant}}$ by 2 for bits communicated for a linear speedup. The presented results of \citet{haddadpour2021federated} are newly obtained (\cref{app:fedcomgate}).}
\label{table:comparison}
\centering\footnotesize
% Vertical size of the table
\renewcommand\arraystretch{1} %1
% Set tab size
\renewcommand{\tabcolsep}{12pt}
\begin{tabularx}{\textwidth}{p{0.22\linewidth}p{0.16\linewidth}rr}
\toprule
\thead[l]{Algorithm}
& \thead[l]{Convergence rate}
& \thead[r]{Communication rounds for $\Tilde{\mathcal{O}}(\frac{1}{T})$\\ convergence with linear speedup}
& \thead[r]{Bits communicated for \\linear speedup} \\ 
\midrule
\citet{reisizadeh2020fedpaq}
& $\mathcal{O}(\frac{1+q}{K} + \frac{T}{K^2})$ 
& Not possible 
& Not possible \\
%\midrule
\citet{haddadpour2021federated}
& $\Tilde{\mathcal{O}}(\frac{1+q}{MT}+\frac{1}{TK})$ 
& $\Tilde{\mathcal{O}}(\frac{M}{1+q})$ & $\Tilde{\mathcal{O}}(\frac{M}{1+q}) \cdot d_{\text{quant}}$\\ 
%\midrule

\citet{yuan2020federated}
& $\Tilde{\mathcal{O}}(\frac{1}{MT}+\frac{1}{TK^3})$ & $\Tilde{\mathcal{O}}(M^{\frac{1}{3}})$  & $\Tilde{\mathcal{O}}(M^{\frac{1}{3}})\cdot 2d_{\text{full}}$\\ 
%\midrule

\midrule
\textbf{FedAQ} (Corollary \ref{corollary2}) & $\Tilde{\mathcal{O}}(\frac{1+q}{MT}+\frac{1+q}{TK^3})$ & $\Tilde{\mathcal{O}}(M^{\frac{1}{3}})$ & $\Tilde{\mathcal{O}}(M^{\frac{1}{3}})\cdot 2d_{\text{quant}}$ \\
\bottomrule
\end{tabularx}
\end{table*}

In federated averaging (FedAvg) \citep{mcmahan2017communication}, also called \textit{local SGD}, each client locally updates its model with multiple stochastic gradient descent (SGD) steps, and a server aggregates model updates of clients. The server updates its own model parameters by averaging client models and then broadcasts the server parameters to all clients. This enables FL systems to achieve high communication efficiency with infrequent synchronization while showing better performance than distributed large mini-batch SGD \citep{lin2018don}. Due to the significant empirical success of FedAvg, researchers have proposed an interesting theoretical question: To what extent can we minimize the number of synchronizations in order to both guarantee convergence and achieve linear speedup in the number of workers $M$\footnote{Linear speedup in the number of workers is a desirable property in parallel computing which implies that the task takes half as much time if the number of workers are doubled.}? For the strongly-convex and homogeneous settings, \citet{khaled2020tighter} was able to achieve a linear speedup in $M$ with $\Tilde{\mathcal{O}}(M)$ communication rounds, which is the state-of-the-art result for FedAvg convergence analysis. However, even with this progress on theoretical guarantees of FedAvg, it remains unclear whether further improvements on convergence time and communication efficiency can be achieved.

Applying acceleration methods to FL has led to improved convergence, with \citet{yuan2020federated} providing a faster version of FedAvg with provably stronger bounds. For the strongly-convex and homogeneous setting, their algorithm achieves a linear speedup in $M$ with only $\Tilde{\mathcal{O}}(M^{\frac{1}{3}})$ communication rounds. Hence, the accelerated version of federated averaging requires a much smaller number of communication rounds than FedAvg to achieve the same accuracy. At present, this remains the best result for strongly-convex and homogeneous local data distribution settings.
In addition to reducing the required number of communication rounds, another powerful way to build communication-efficient FL systems is to reduce the number of bits that need to be transmitted at each synchronization. \citet{reisizadeh2020fedpaq, haddadpour2021federated} have shown that such compression techniques, which include \textit{quantization}, reduce communication costs and guarantee convergence (See Table \ref{table:comparison}). 

In this work, we provide a novel algorithm, \textbf{Fed}erated optimization algorithm with \textbf{A}cceleration and \textbf{Q}uantization (FedAQ), to solve the severe communication bottleneck problem in FL systems. FedAQ is the first federated optimization algorithm that successfully incorporates \emph{multiple local update schemes}, \emph{acceleration}, and \emph{quantization} for master-worker topology. Although these three key desiderata of Federal Learning systems have individually been shown to build communication-efficient FL systems, it is not obvious if or how acceleration techniques can lead to faster convergence even for quantization-based methods. We answer this question by showing that FedAQ converges for strongly-convex and homogeneous local data distribution settings without any additional strong assumptions.

 Let $T$ be the number of total parallel iterations, $K$ be the number of total communication rounds. We compare our results to previous methods in Table \ref{table:comparison}, and highlight the following contributions:
 \begin{enumerate}

     \item FedAQ has a convergence rate of $\Tilde{\mathcal{O}}(\frac{1+q}{MT}+\frac{1+q}{TK^3})$ which is better than the $\Tilde{\mathcal{O}}(\frac{1+q}{MT}+\frac{1}{TK})$ convergence of \citet{haddadpour2021federated}, the state of the art in quantization based methods. Here $q$ is a parameter that measures the effectiveness of the quantization scheme (see Assumption \ref{assumption1}). This allows FedAQ to obtain linear speedup with only $\Tilde{\mathcal{O}}(M^{\frac{1}{3}})$ communication rounds whereas \citet{haddadpour2021federated} requires $\Tilde{\mathcal{O}}(\frac{M}{1+q})$ rounds. The faster convergence in number of communication rounds also implies that FedAQ can achieve better convergence than \citet{haddadpour2021federated} by using many fewer communication rounds. Thus, although FedAQ sends two iterates in each communication round, that is the bits communicated in each round are twice many compared to \citet{haddadpour2021federated} for the same level of quantization, FedAQ requires much smaller total communication costs due to the large reduction in synchronization rounds.
     
     %a much smaller number of synchronization rounds which leads to smaller total communication costs.
     %synchronization needs twice as much per-round communication costs as \citet{haddadpour2021federated}, FedAQ requires much less communication overall due to the large reduction $\Tilde{\mathcal{O}}(\frac{1+q}{M^{\frac{2}{3}}})$ in synchronization rounds. % That is, FedAQ requires much less communication overall because the difference between the per-round communication costs of FedAQ and \citet{haddadpour2021federated} is negligible compared to the large reduction in synchronization rounds of FedAQ.
    
    \item \label{contribution2} When comparing FedAQ to Accelerated Federated learning, we observe that FedAQ has similar convergence and requires the same number of communication rounds as \citet{yuan2020federated}. In each communication round of \citet{yuan2020federated}, every client sends the complete iterates to the server without any quantization. To effectively obtain a convergence rate of $\Tilde{\mathcal{O}}(\frac{1}{MT})$, it needs to send each value with a precision of $\Tilde{\mathcal{O}}(\frac{1}{MT})$, requiring $d_{\text{full}} = {\mathcal{O}}(\log{(MT)})$ bits. In comparison, if we use the low precision quantizer (See \cref{problem_setup} Example 1) given by \citet{alistarh2017qsgd}, FedAQ needs to send only $d_{\text{quant}} = O(\log \frac{1}{q})$ bits \footnote{More details on this are discussed in \cref{app:quantization_noise}} for each value. Since $q$ is a constant, $d_{\text{quant}} \ll d_{\text{full}}$. The extra $1+q$ term in the convergence for FedAQ can be offset by scaling the number of local updates by $1+q$, which is cheaper than expensive data communication. Thus, FedAQ obtains the same convergence as \citet{yuan2020federated} using as many communication rounds but by sending many fewer bits per round.
 

 \end{enumerate}
 
 Finally, we empirically verify that our algorithm exhibits better performance than baselines, FedPAQ \citep{reisizadeh2020fedpaq}, FedCOMGATE \citep{haddadpour2021federated}, FedAC \citep{yuan2020federated}, and FedAvg \citep{mcmahan2017communication} on classical vision datasets such as MNIST~\citep{lecun1998mnist} and CIFAR-10~\citep{krizhevsky2009learning}.