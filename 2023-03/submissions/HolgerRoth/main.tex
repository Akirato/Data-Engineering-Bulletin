%\documentclass[11pt,dvipdfm]{article}
\documentclass[11pt]{article}



\begin{document}

%\title{NVFlare: Federated Learning Application Runtime Environment for Developing Robust AI Models}
\title{NVIDIA FLARE:\\ Federated Learning from Simulation to Real-World}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

% authors with email
% Holger R. Roth <hroth@nvidia.com> \\
% Yan Cheng <yanc@nvidia.com> \\
% Yuhong Wen <yuhongw@nvidia.com> \\
% Isaac Yang <isaacy@nvidia.com> \\
% Ziyue Xu <ziyuex@nvidia.com> \\
% Yuan-Ting Hsieh <yuantingh@nvidia.com> \\
% Kristopher Kersten <kkersten@nvidia.com> \\
% Ahmed Harouni <aharouni@nvidia.com> \\
% Can Zhao <canz@nvidia.com> \\
% Kevin Lu <kevlu@nvidia.com> \\
% Zhihong Zhang <zhihongz@nvidia.com> \\
% Wenqi Li <wenqil@nvidia.com> \\
% Andriy Myronenko <amyronenko@nvidia.com> \\
% Dong Yang <dongy@nvidia.com> \\
% Sean Yang <seanyang@berkeley.edu> \\
% Nicola Rieke <nrieke@nvidia.com> \\
% Abood Quraini <AQuraini@nvidia.com> \\
% Chester Chen <chesterc@nvidia.com> \\
% Daguang Xu <daguangx@nvidia.com> \\
% Nic Ma <nicm@nvidia.com> \\
% Prerna Dogra <pdogra@nvidia.com> \\
% Mona Flores <mflores@nvidia.com> \\
% Andrew Feng <andyf@nvidia.com> \\


\author{%
  Holger R. Roth\quad
  Yan Cheng\quad
  Yuhong Wen\quad
  Isaac Yang\quad
  Ziyue Xu\quad
  Yuan-Ting Hsieh\quad\\
  Kristopher Kersten\quad
  Ahmed Harouni\quad
  Can Zhao\quad
  Kevin Lu\quad
  Zhihong Zhang\quad
  Wenqi Li\quad\\
  Andriy Myronenko\quad
  Dong Yang\quad
  Sean Yang\quad
  Nicola Rieke\quad
  Abood Quraini\quad
  Chester Chen\quad\\
  Daguang Xu\quad
  Nic Ma\quad
  Prerna Dogra\quad
  Mona Flores\quad
  Andrew Feng\\
  % Affiliation \\
  \\
  NVIDIA Corporation\thanks{Contact: \texttt{\{hroth,yanc,chesterc,daguangx,pdogra,andyf\}@nvidia.com}}\\
  Shanghai, China\\
  Munich, Germany\\
  Bethesda, Santa Clara, USA\\
}


% please enter real date, vol no, issue no
%\bulletindate{\today}
%\bulletinvolume{41}
%\bulletinnumber{3}
%\bulletinyear{2018}

% these are files that I have- but your part of the issue can be done without
% them
%\IEEElogo{../../debpub/logos/cs.eps}
%\insidefrontcover{../../debpub/editors/incvA2.ps}
%\insidebackcover[ICDE Conference]{./calls/icde-new-a.ps}


\maketitle

\setcounter{footnote}{0}
\begin{abstract}
Federated learning (FL) enables building robust and generalizable AI models by leveraging diverse datasets from multiple collaborators without centralizing the data. We created NVIDIA FLARE\footnote{Code is available at \url{https://github.com/NVIDIA/NVFlare}.} as an open-source software development kit (SDK) to make it easier for data scientists to use FL in their research and real-world applications.
The SDK includes solutions for state-of-the-art FL algorithms and federated machine learning approaches, which facilitate building workflows for distributed learning across enterprises and enable platform developers to create a secure, privacy-preserving offering for multiparty collaboration utilizing homomorphic encryption or differential privacy.
The SDK is a lightweight, flexible, and scalable Python package. It allows researchers to apply their data science workflows in any training libraries (PyTorch, TensorFlow, XGBoost, or even NumPy) in real-world FL settings. This paper introduces the key design principles of NVFlare and illustrates some use cases (e.g., COVID analysis) with customizable FL workflows that implement different privacy-preserving algorithms.
\end{abstract}


\section{Introduction}
Federated learning (FL) has become a reality for many real-world applications~\cite{rieke2020future}. It enables multinational collaborations on a global scale to build more robust and generalizable machine learning and AI models.
%
In this paper, we introduce NVIDIA FLARE (NVFlare), an open-source software development kit (SDK) that makes it easier for data scientists to collaborate to develop more generalizable and robust AI models by sharing model weights rather than private data.
%
While FL is attractive in many industries, it is particularly beneficial for healthcare applications where patient data needs to be protected. For example, FL has been used for predicting clinical outcomes in patients with COVID-19~\cite{dayan2021federated} or to segment brain lesions in magnetic resonance imaging~\cite{sheller2018multi,sheller2020federated}. NVFlare is not limited to applications in healthcare and is designed to allow cross-silo FL~\cite{kairouz2019advances} across enterprises for different industries and researchers.

In recent years, several efforts (both open-source and commercial) have been made to bring FL technology into the healthcare sector and other industries, like TensorFlow Federated~\cite{abadi2016tensorflow}, PySyft~\cite{ziller2021pysyft}, FedML~\cite{he2020fedml}, FATE~\cite{liu2021fate}, Flower~\cite{beutel2020flower}, OpenFL~\cite{reina2021openfl}, Fed-BioMed~\cite{silva2020fed}, IBM Federated Learning~\cite{ludwig2020ibm}, HP Swarm Learning~\cite{warnat2021swarm}, FederatedScope~\cite{xie2022federatedscope}, FLUTE~\cite{dimitriadis2022flute}, and more. Some focus on simulated FL settings for researchers, while others prioritize production settings. NVFlare aims to be useful for both scenarios: 1) for researchers by providing efficient and extensible simulation tools and 2) by providing an easy path to transfer research into real-world production settings, supporting high availability and server failover, and by providing additional productivity tools such as multi-tasking and admin commands.

\section{NVIDIA FLARE Overview}

NVIDIA FLARE -- or short NVFlare -- stands for ``\textbf{NV}IDIA \textbf{F}ederated \textbf{L}earning \textbf{A}pplication \textbf{R}untime \textbf{E}nvironment''.
The SDK enables researchers and data scientists to adapt their machine learning and deep learning workflows to a federated paradigm. It enables platform developers to build a secure, privacy-preserving offering for distributed multiparty collaboration.

NVFlare is a lightweight, flexible, and scalable FL framework implemented in Python that is agnostic to the underlying training library. Developers can bring their own data science workflows implemented in PyTorch, TensorFlow, or even in pure NumPy, and apply them in a federated setting.
%
A typical FL workflow such as the popular federated averaging (FedAvg) algorithm~\cite{mcmahan2017communication}, can be implemented in NVFlare using the following main steps. Starting from an initial global model, each FL client trains the model on their local data for a while and sends model updates to the server for aggregation. The server then uses the aggregated updates to update the global model for the next round of training. This process is iterated many times until the model converges.

Though used heavily for federated deep learning, NVFlare is a generic approach for supporting collaborative computing across multiple clients. NVFlare provides the \textit{Controller} programming API for researchers to create workflows for coordinating clients for collaboration. FedAvg is one such workflow. Another example is cyclic weight transfer~\cite{chang2018distributed}.
%
The central concept of collaboration is the notion of ``task''. An FL controller assigns tasks (e.g., deep-learning training with model weights) to one or more FL clients and processes results returned from clients (e.g., model weight updates). The controller may assign additional tasks to clients based on the processed results and other factors (e.g., a pre-configured number of training rounds). This task-based interaction continues until the objectives of the study are achieved.

The API supports typical controller-client interaction patterns like broadcasting a task to multiple clients, sending a task to one or more specified clients, or relaying a task to multiple clients sequentially. Each interaction pattern has two flavors: wait (block until client results are received) or no-wait. A workflow developer can use these interaction patterns to create innovative workflows. For example, the \textit{ScatterAndGather} controller (typically used for FedAvg-like algorithms) is implemented with the \textit{broadcast\_and\_wait} pattern, and the \textit{CyclicController} is implemented with the \textit{relay\_and\_wait pattern}. The controller API allows the researcher to focus on the control logic without needing to deal with underlying communication issues. Figure~\ref{fig:job} shows the principle.
%
Each FL client acts as a worker that simply executes tasks assigned to it (e.g., model training) and returns execution results to the controller. At each task interaction, there can be optional filters that process the task data or results before passing it to the \textit{Controller} (on the server side) or task executor (client side). The filter mechanism can be used for data privacy protection (e.g., homomorphic encryption/decryption or differential privacy) without having to alter the training algorithms.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{submissions/HolgerRoth/fig/controller_worker_flow.png}
    \caption{NVFlare job execution. The \textit{Controller} is a Python object that controls or coordinates the \textit{Workers} to get a job done. The controller is run on the FL server. A \textit{Worker} is capable of performing tasks. \textit{Workers} run on FL clients. \label{fig:job}}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Key Components}
NVFlare is built on a componentized architecture that allows FL workloads to move from research and simulation to real-world production deployment. Some of the key components of this SDK include:

\begin{itemize}%[leftmargin=*]
    \item \textbf{FL Simulator} for rapid development and prototyping.
    \item \textbf{NVFlare Dashboard} for simplified project management, secure provisioning, and deployment, orchestration.
    \item \textbf{Reference FL algorithms} (e.g., FedAvg, FedProx, SCAFFOLD) and workflows, like scatter and gather, cyclic, etc.
    \item \textbf{Privacy preservation} with differential privacy, homomorphic encryption, and more.
    \item \textbf{Specification-based API} for extensibility, allowing customization with plug-able components.
    \item \textbf{Tight integration} with other learning frameworks like MONAI~\cite{cardoso2022monai}, XGBoost~\cite{Chen:2016:XST:2939672.2939785}, and more.
\end{itemize}

\paragraph{High-Level Architecture} NVFlare is designed with the idea that less is more, using a specification-based design principle to focus on what is essential.
%
This allows other people to be able to do what they want to do in real-world applications by following clear API definitions. FL is an open-ended space. The API-based design allows others to bring their implementations and solutions for various components. Controllers, task executors, and filters are just examples of such extensible components.
%
NVFlare provides an end-to-end operation environment for different personas. It provides a comprehensive provisioning system that creates security credentials for secure communications to enable the easy and secure deployment of FL applications in the real world. It also provides an FL Simulator for running proof-of-concept studies locally.
%
In production mode, the researcher conducts an FL study by submitting jobs using admin commands using Notebooks or the NVFlare Console -- an interactive command tool. NVFlare provides many commands for system operation and job management. With these commands, one can start and stop a specific client or the entire system, submit new jobs, check the status of jobs, create a job by cloning from an existing one, and much more.

%
With NVFlare's component-based design, a job is just a configuration of components needed for the study. For the control logic, the job specifies the controller component to be used and any components required by the controller.
%
\section{System Concepts}
%
A NVFlare system is a typical client-server communication system that comprises one or more FL server(s), one or more FL client(s), and one or more admin clients. The FL Servers open two ports for communication with FL clients and admin clients. FL clients and admin clients connect to the opened ports. FL clients and admin clients do not open any ports and do not directly communicate with each other.
%
The following is an overview of the key concepts and objects available in NVFlare and the information that can be passed between them.

\paragraph{Workers and Controller} NVFlare’s collaborative computing is achieved through the \textit{Controller}/\textit{Worker} interactions.

\paragraph{Shareable} Object that represents a communication between server and client. Technically, the \textit{Shareable} is implemented as a Python dictionary that could contain different information, e.g., model weights.

\paragraph{Data Exchange Object (DXO)} Standardizes the data passed between the communicating parties. One can think of the \textit{Shareable} as the envelope and the \textit{DXO} as the letter. Together, they comprise a message to be shared between communicating parties.

\paragraph{FLComponent} The base class of all the FL components. Executors, controllers, filters, aggregators, and their subtypes are all \textit{FLComponents}.
\textit{FLComponent} comes with some useful built-in methods for logging, event handling, auditing, and error handling.

\paragraph{Executors} Type of \textit{FLComponent} for FL clients that has an execute method that produces a \textit{Shareable} from an input \textit{Shareable}. NVFlare provides both single- and multi-process executors to implement different computing workloads.

\paragraph{FLContext} One of the most important features of NVFlare is to pass data between the FL components. \textit{FLContext} is available to every method of all common FLComponent types. Through \textit{FLContext}, the component developer can get services provided by the underlying infrastructure and share data with other components of the FL system.

\paragraph{Communication Drivers}
NVFlare abstracts the communication layers out so that different deployment scenarios can implement customizable communication drivers. By default, we use GRPC for data communication in task-based communication. However, the driver can be replaced to run other communication protocols, for example, TCP. The customizable nature of communication in NVFlare allows for both server-centric and peer-to-peer communication patterns. This enables the user to utilize both scatter and gather-type workflows like FedAvg~\cite{mcmahan2017communication}, decentralized training patterns like swarm learning~\cite{warnat2021swarm}, or direct peer-to-peer communication as in split learning~\cite{gupta2018distributed}.

Fig.~\ref{fig:cloud_comm} compares the times for model upload and download from the client's perspective using different communication protocols available in NVFlare using a model of $\sim$18MB in size.

The experiment runs in a multi-cloud environment with the server and eight clients running on Azure, while two clients run on AWS. One can observe that the global model download is slower as all clients are trying to download the global model at the same time, and hence the server is more busy. In contrast, the clients' model uploads happen at slightly different times and therefore are faster. One can also see how this multi-cloud setup causes the clients on AWS to take slightly longer during model download due to communication across different cloud infrastructures.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.90\textwidth]{submissions/HolgerRoth/fig/comm_protocols1.pdf}
    \caption{Comparison of GRPC and TCP communication drivers in NVFlare. The server is running on Azure. The clients are distributed between Azure and AWS. The message size is $\sim$18MB. Communication times were measured over 100 rounds of FedAvg. Error bars indicate the 95\% confidence intervals. \label{fig:cloud_comm}}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Filters} Filters in NVFlare are a type of \textit{FLComponent} that have a process method to transform the \textit{Shareable} object between the communicating parties. A Filter can provide additional processing to shareable data before sending or after receiving from a peer. Filters can convert data formats and a lot more and are NVFlare's primary mechanism for data privacy protection~\cite{li2019privacy,hatamizadeh2022gradient}:
\begin{itemize}
\item \textit{ExcludeVars} to exclude variables from shareable.
\item \textit{PercentilePrivacy} for truncation of weights by percentile.
\item \textit{SVTPrivacy} for differential privacy through sparse vector techniques.
\item Homomorphic encryption filters used for secure aggregation.
\end{itemize}
%
As an example, we show the average encryption, decryption, and upload times when using homomorphic encryption for secure aggregation\footnote{\url{https://developer.nvidia.com/blog/federated-learning-with-homomorphic-encryption}}. We compare raw data to encrypted model gradients uploaded in Table~\ref{tab:he} when hosting the server on AWS\footnote{For reference, we used an \href{https://aws.amazon.com/ec2/instance-types}{m5a.2xlarge} instance with eight vCPUs, 32-GB memory, and up to 2,880 Gbps network bandwidth.} and connecting 30 client instances using an on-premise GPU cluster. One can see the longer upload times due to the larger message sizes needed by homomorphic encryption.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{figure}[htbp]
    %\centering
 %\includegraphics[width=0.75\textwidth]{fig/average-encryption-decryption-upload-1.png}
    %\caption{Running federated learning with 30 clients and the server on AWS. \label{fig:he}}
%\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[htbp]
\centering
\captionsetup{width=.45\textwidth}
\caption{Federated learning exchanging homomorphic encrypted vs. raw model updates. \label{tab:he}}
\footnotesize
 \begin{tabular}{||l r r||}
 \hline
\textbf{Time in seconds}	& \textbf{Mean} & \textbf{Std. Dev.} \\ [0.5ex]
 \hline\hline
Encryption & 5.01 & 1.18 \\
Decryption & 0.95 & 0.04 \\
Enc. upload & 38.00 & 71.17 \\
Raw upload & 21.57 & 74.23 \\ [1ex]
 \hline
 \end{tabular}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\paragraph{Event Mechanism} NVFlare comes with a powerful event mechanism that allows dynamic notifications to be sent to all event handlers. This mechanism enables data-based communication among decoupled components: one component fires an event when a certain condition occurs, and other components can listen to that event and processes the event data. Each \textit{FLComponent} is automatically an event handler. To listen to and process an event, one can simply implement the \textit{handle\_event()} method and process desired event types. Events represent some important moments during the execution of the system logic. For example, before and after aggregation or when important data becomes available, e.g., a new ``best'' model was selected.
%
\subsection{Productivity Features}
NVFlare contains features that enable efficient, collaborative, and robust computing workflows.

\paragraph{Multi-tasking} For systems with a large capacity, computing resources could be idle most of the time. NVFlare implements a resource-based multi-tasking solution, where multiple jobs can be run concurrently when overall system resources are available.
Multi-tasking is made possible by a job scheduler on the server side that constantly tries to schedule a new job.
For each job to be scheduled, the scheduler asks each client whether they can satisfy the required resources of the job (e.g., number of GPU devices) by querying the client's resource manager. If all clients can meet the requirement, the job will be scheduled and deployed to the clients.

\paragraph{High Availability and Server Failover} To avoid the FL server as a single point of failure, a solution has been implemented to support multiple FL servers with automatic cut-over when the currently active server becomes unavailable.
Therefore, a component called \textit{Overseer} is added to facilitate automatic cut-over. The \textit{Overseer} provides the authoritative endpoint info of the active FL server. All other system entities (FL servers, FL clients, admin clients) constantly communicate (i.e., every 5 seconds) with the Overseer to obtain and act on such information.
%
If the server cutover happens during the execution of a job, then the job will continue to run on the new server. Depending on how the controller is written, the job may or may not need to restart from the beginning but can continue from a previously saved snapshot.

\paragraph{Simulator} NVFlare provides a simulator to allow data scientists and system developers to easily write new \textit{FLComponents} and novel workflows.
The simulator is a command line tool to run a NVFlare job. To allow simple experimentation and debugging, the FL server and multiple clients run in the same process during simulation. A multi-process option allows efficient use of resources, e.g., training multiple clients on different GPUs. The simulator follows the same job execution as in real-world NVFlare deployment. Therefore, components developed in simulation can be directly deployed in real-world federated scenarios.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Secure Provisioning in NVFlare}
Security is an important requirement for FL systems. NVFlare provides security solutions in the following areas: authentication, communication confidentiality, user authorization, data privacy protection, auditing, and local client policies.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{figure}[htbp]
    %\centering
    %\includegraphics[width=0.6\textwidth]{fig/nvflare-provision-start-operate-768x378.png}
    %\caption{NVFlare Provision, start, operate (PSO) components, and their APIs. %\label{fig:pso}}
%\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[tbp]
    \centering
    \includegraphics[width=0.8\textwidth]{submissions/HolgerRoth/fig/provisioning.pdf}
    \caption{High-level steps for running a real-world study with secure provisioning with NVFlare. \label{fig:provisioning}}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%\paragraph{Security, Data Privacy, and Client-policies}
\paragraph{Authentication} NVFlare ensures the identities of communicating peers using mutual Transport Layer Security (TLS). Each participating party (FL Servers, Overseer, FL Clients, Admin Clients) must be properly provisioned. Once provisioned, each party receives a startup kit containing TLS credentials (public cert of the root, the party's own private key and certificate) and system endpoint information, see Fig.~\ref{fig:provisioning}. Each party can only connect to the NVFlare system with the startup kit.
%
Communication confidentiality is also achieved with the use of TLS-based messaging.

\paragraph{Federated Authorization} NVFlare's admin command system is very rich and powerful. Not every command is for everyone. NVFlare implements a role-based user authorization system that controls what a user can or cannot do. At the time of provision, each user is assigned a role. Authorization policies specify which commands are permitted for which roles.
Each FL client can define its authorization policy that specifies what a role can or cannot do to the client. For example, one client could allow a role to run jobs from any researchers. In contrast, another client may only allow jobs submitted by its researchers (i.e., the client and the job submitter belong to the same organization).

NVFlare automatically records all user commands and job events in system audit files on both the server and client sides. In addition, the audit API can be used by application developers to record additional events in the audit files.

\paragraph{Client-Privacy} NVFlare enhances the overall system security by allowing each client to define its policies for authorization, data privacy (filters), and computing resource management. The client can change its policies at any time after the system is up and running without having to be re-provisioned. For example, the client could require all jobs running on it to be subject to a set of filters. The client could also change the number of computing resources (e.g., GPU devices) to be used by the FL client.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Federated Data Science}
As a general distributed computing platform, NVFlare can be used for various applications in different industries. Here we describe some of the most common use cases where NVFlare was deployed.

\subsection{Federated Deep Learning} A go-to example dataset for benchmarking different FL algorithms is CIFAR-10~\cite{krizhevsky2009learning}. NVFlare allows users to experiment with different algorithms and data splits using different levels of heterogeneity based on a Dirichlet sampling strategy~\cite{wang2020federated}. Figure~\ref{fig:fl_alpha} shows the impact of varying alpha values, where lower values cause higher heterogeneity on the performance of the FedAvg.

Apart from FedAvg, currently available in NVFlare include FedProx~\cite{li2020federated}, FedOpt~\cite{reddi2020adaptive}, and SCAFFOLD~\cite{karimireddy2020scaffold}. Figure~\ref{fig:fl_algos} compares an $\alpha$ setting of 0.1, causing a high data heterogeneity across clients and its impact on more advanced FL algorithms, namely FedProx, FedOpt, and SCAFFOLD.
FedOpt and SCAFFOLD show markedly better convergence rates and achieve better performance than FedAvg and FedProx with the same alpha setting.
SCAFFOLD achieves this by adding a correction term when updating the client models, while FedOpt utilizes SGD with momentum to update the global model on the server. Therefore, both perform better with the same number of training steps as FedAvg and FedProx.

Other algorithms available in or coming soon to NVFlare include federated XGBoost~\cite{Chen:2016:XST:2939672.2939785}, Ditto~\cite{li2021ditto}, FedSM~\cite{xu2022closing}, Auto-FedRL~\cite{guo2022auto}, and more.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[htbp]
\centering
\begin{subfigure}[\footnotesize FedAvg with increasing levels of heterogeneity (smaller $\alpha$ values). \label{fig:fl_alpha}]{
    \includegraphics[width=0.45\textwidth]{submissions/HolgerRoth/fig/fedavg_alpha.png}
    }
\end{subfigure}\qquad
\begin{subfigure}[\footnotesize FL algorithms with a heterogeneous data split ($\alpha$=0.1). \label{fig:fl_algos}]{
    \includegraphics[width=0.45\textwidth]{submissions/HolgerRoth/fig/fedopt_fedprox_scaffold.png}
    }
\end{subfigure}
\caption{Federated learning experiments with NVFlare. \label{fig:fl}}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Federated Machine Learning}
Traditional machine learning methods, such as linear models, support vector machine (SVM), and k-means clustering, can be formulated under a federated setting.

With certain libraries, the federated machine learning algorithms need to be designed considering two factors: algorithm-wise, each of these models has distinct training schemes and model representations; and implementation-wise, popular libraries providing these functionalities (e.g., scikit-learn, XGBoost) have different APIs and inner logics. Hence, when developing an FL variant of a particular traditional machine learning method, several questions need to be answered at these two levels:

First, at the algorithm level, we need to break down the optimization process into individual steps/rounds (if possible) and have answers to three major questions:
\begin{enumerate}
    \item What information should clients share with the server?
    \item How should the server aggregate the collected information from clients?
    \item What should clients do with the global aggregated information received from the server?
\end{enumerate}

Second, at the implementation level, we need to know what APIs are available and how to utilize them in a federated pipeline to implement a distributed version of the algorithm.

A major difference between federated traditional machine learning and federated deep learning is that, for traditional machine learning methods, the boundary between ``federated'' and ``distributed'', or even ``ensemble'', can be much more vague than for deep learning. Due to the characteristics of a given algorithm and its API design, the concepts can be equivalent. Take XGBoost and SVM, for example:
Algorithm-wise, XGBoost can distribute the training samples to several workers and construct trees based on the collected histograms from each worker. Such a process can be directly adopted under a federated setting because the communication cost is affordable. In this case, ``federated'' is equivalent to ``distributed'' learning.
API-wise, some algorithms can be constrained by their implementation. Take scikit-learn's SVM for instance. Although theoretically SVM can be formulated as an iterative optimization process, the API only supports one-shot ``fitting'' without the capability of separately calling the optimization steps. Hence a federated SVM algorithm using the scikit-learn library can only be implemented as a two-step process. In this case, ``federated'' is equivalent to ``ensemble''.

For clarification, we provide the full formulation for tree-based federated XGBoost, illustrated in Fig.~\ref{fig:tree_xgboost}:
\begin{enumerate}
\item XGBoost, by definition, is a sequential optimization process: each step adds one extra tree to the model to reduce the residual error. Hence, federated XGBoost can be formulated as follows: each round of FL corresponds to one boosting step at the local level. Clients share the newly added tree trained on local data with the server at the end of local boosting.
\item The model representation is a decision/regression tree. To aggregate the information from all clients, the server will bag all received trees to form a ``forest'' to be added to the global boosting model.
\item With the updated global model from the server, each client will continue the boosting process by learning a new tree starting from the global model of the boosted forest.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.99\textwidth]{submissions/HolgerRoth/fig/TreeXGBoost.pdf}
    \caption{Tree-based federated XGBoost: a ``boosting of forests.'' \label{fig:tree_xgboost}}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Split learning}
Split learning assumes a vertical data partitioning~\cite{yang2019federated} that can be useful in many distributed learning scenarios involving neural network architectures~\cite{gupta2018distributed}.

As an introductory example, we can assume that one client holds the images, and the other holds the labels to compute losses and accuracy metrics. Activations and corresponding gradients are being exchanged between the clients using NVFlare, as illustrated in Fig.~\ref{fig:split_learning}.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[htbp]
%%%%%%%%%%%%%
\centering
\includegraphics[width=0.35\textwidth]{submissions/HolgerRoth/fig/split_learning.pdf}
\hspace{2em}
%%%%%%%%%%%%%
\footnotesize
\begin{tabular}[b]{||l r||}
\hline
\textbf{Setup} & \textbf{Training Time [min]} \\ [0.5ex]
\hline\hline
Simulated PyTorch & 19 \\
Routing through server (TCP) & 27  \\
Peer-to-peer (TCP) & 25  \\ [1ex]
\hline
\end{tabular}
%%%%%%%%%%%%%
\caption{Simple split learning scenario using CIFAR-10. The table compares multiple communication patterns. Using 50,000 training samples and 15,625 rounds of communication with a batch size of 64. \label{fig:split_learning}}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
We use a cryptographic technique called private set intersection (PSI)~\cite{enwiki:1131516757} to compute the alignment between images and labels on both clients. NVFlare's implementation of PSI can be extended to multiple parties and applied to other use cases than split learning, e.g., requiring a secure and privacy-preserving alignment of different databases.

Using NVFlare's capability to implement different communication patterns, we can investigate the communication speed-ups one can achieve by implementing split learning using direct peer-to-peer communication as opposed to routing the messages between the two clients through a central server.

The table in Fig.~\ref{fig:split_learning} compares the training speeds of split learning on the CIFAR-10 dataset in a local simulation scenario. First, we use the same PyTorch script to simulate split learning. Then, we implement two distributed solutions using NVFlare. One that routes the messages through the server and one using a direct peer-to-peer connection between the clients. As expected, the direct peer-to-peer connection is more efficient, achieving only a slight overhead in total training time compared to the standalone PyTorch script, which could not be translated to real-world scenarios.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{figure}[htbp]
%    \centering
%    \includegraphics[width=0.3\textwidth]{fig/split_learning.pdf}
%    \caption{Simple split learning scenario using CIFAR-10. %\label{fig:split_learning}}
%\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{table}[htbp]
%\centering
%\captionsetup{width=.75\textwidth}
%\caption{Split learning on CIFAR-10 with multiple communication %patterns. Using 50,000 training samples and 15,625 rounds of %communication with a batch size of 64. \label{tab:split_learning}}
%\footnotesize
% \begin{tabular}{||l r||}
% \hline
%\textbf{Setup} & \textbf{Training Time [min]} \\ [0.5ex]
% \hline\hline
%Simulated PyTorch & 19 \\
%Routing through server (TCP) & 27  \\
%Peer-to-peer (TCP) & 25  \\ [1ex]
% \hline
% \end{tabular}
%\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Federated Statistics} NVFlare provides built-in federated statistics operators (\textit{Controller} and \textit{Executors}) that will generate global statistics based on local client statistics.
Each client could have one or more datasets, such as ``train'' and ``test'' datasets. Each dataset may have many features.
NVFlare will calculate and combine the statistics for each feature in the dataset to produce global statistics for all the numeric features. The output gathered on the server will be the complete statistics for all datasets in clients and global, as illustrated in Fig.~\ref{fig:fedstats}.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[htbp]
\centering
\begin{subfigure}[\footnotesize Federated statistics. Note the data of ``site-4'' violates the client's privacy policy and therefore does not share its statistics with the server. \label{fig:fedstats_table}]{
    \includegraphics[width=0.55\textwidth]{submissions/HolgerRoth/fig/covid_stats.png}
    }
\end{subfigure}\qquad
\begin{subfigure}[\footnotesize Histogram visualization. \label{fig:fedstats_histo}]{
    \includegraphics[width=0.35\textwidth]{submissions/HolgerRoth/fig/covid_hist.png}
    }
\end{subfigure}
\caption{Federated statistics with NVFlare. \label{fig:fedstats}}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Real-world Use Cases}
NVFlare and its predecessors have been used in several real-world studies exploring FL for healthcare scenarios.
The collaborations between multinational institutions tested and validated the utility of federated learning, pushing the
envelope for training robust, generalizable AI models. These initiatives included FL for breast mammography classification~\cite{roth2020federated}, prostate segmentation~\cite{sarma2021federated}, pancreas segmentation~\cite{wang2020federated}, and most recently, chest X-ray (CXR) and electronic health record (EHR) analysis to predict the oxygen requirement for patients arriving in the emergency department with symptoms of COVID-19~\cite{dayan2021federated}.
%\subsection{MONAI FL Integration}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[htbp]
\centering
\begin{subfigure}[\footnotesize Mammography. \label{fig:breast}]{
    \includegraphics[clip, trim={0.5em 0 0.5em 0}, height=7.5em]{submissions/HolgerRoth/fig/breast.png}
    }
\end{subfigure}\hfill
\begin{subfigure}[\footnotesize Prostate. \label{fig:prostate}]{
    \includegraphics[clip, trim={1em 0 1em 0}, height=7.5em]{submissions/HolgerRoth/fig/prostate.png}
    }
\end{subfigure}\hfill
\begin{subfigure}[\footnotesize Pancreas. \label{fig:pancreas}]{
    \includegraphics[clip, trim={1em 0 1em 0}, height=7.5em]{submissions/HolgerRoth/fig/pancreas.png}
    }
\end{subfigure}\hfill
\begin{subfigure}[\footnotesize CXR \& EHR. \label{fig:cxr}]{
    \includegraphics[clip, trim={0.5em 0 0.5em 0}, height=7.5em]{submissions/HolgerRoth/fig/cxr.png}
    }
\end{subfigure}
\caption{Real-world use cases of NVFlare. \label{fig:use_cases}}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summary \& Conclusion}
We described NVFlare, an open-source SDK to make it easier for data scientists to use FL in their research and to allow an easy transition from research to real-world deployment.
As discussed above, NVFlare's \textit{Controller} programming API supports various interaction patterns between the server and clients over internet connections, which could be unstable.
Therefore, the API design mitigates various failure conditions and unexpected crashes of the client machines, such as allowing developers to process timeout conditions properly.

NVFLare's unique flexibility and agnostic approach towards the deployed training libraries make it the perfect solution for integrating with different deep learning frameworks, including popular ones used for training large language models (LLM). With our dedication to addressing the current limitations of communication protocols, we are working towards supporting the communication of large message sizes, enabling the federated fine-tuning of AI models with billions of parameters, such as those used for ChatGPT~\cite{ouyang2022training} and GPT-4~\cite{openai2023gpt4}.
Moreover, our team is implementing parameter-efficient federated methods to adapt LLM models to downstream tasks~\cite{zhao2022reduce}, utilizing techniques such as prompt tuning~\cite{lester2021power} and p-tuning~\cite{liu2021gpt}, adapters~\cite{houlsby2019parameter,he2021towards}, LoRA~\cite{hu2021lora}, showing promising performance. Our commitment to innovation and excellence in this field ensures that we continue to push the boundaries of what is possible with federated learning.

We did not go into all details of exciting features available in NVFlare, like homomorphic encryption, TensorBoard streaming, provisioning web dashboard, integration with MONAI\footnote{\url{https://monai.io}}~\cite{monai2022github,cardoso2022monai}, etc. However, we hope that this overview of NVFlare gives a good starting point for developers and researchers on their journey to using FL and federated data science in simulation and the real world.

NVFlare is an open-source project. We invite the community to contribute and grow NVFlare. For more information, please visit the code repository at \url{https://github.com/NVIDIA/NVFlare}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% REFERENCES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\clearpage
%\newpage
%\small
%\bibliographystyle{abbrv}
%\bibliography{submissions/HolgerRoth/ref}

\begin{thebibliography}{10}

\bibitem{abadi2016tensorflow}
M.~Abadi, P.~Barham, J.~Chen, Z.~Chen, A.~Davis, J.~Dean, M.~Devin,
  S.~Ghemawat, G.~Irving, M.~Isard, et~al.
\newblock $\{$TensorFlow$\}$: a system for $\{$Large-Scale$\}$ machine
  learning.
\newblock In {\em 12th USENIX symposium on operating systems design and
  implementation (OSDI 16)}, pages 265--283, 2016.

\bibitem{abadi2016deep}
M.~Abadi, A.~Chu, I.~Goodfellow, H.~B. McMahan, I.~Mironov, K.~Talwar, and
  L.~Zhang.
\newblock Deep learning with differential privacy.
\newblock In {\em Proceedings of the 2016 ACM SIGSAC conference on computer and
  communications security}, pages 308--318, 2016.

\bibitem{beutel2020flower}
D.~J. Beutel, T.~Topal, A.~Mathur, X.~Qiu, T.~Parcollet, P.~P. de~Gusm{\~a}o,
  and N.~D. Lane.
\newblock Flower: A friendly federated learning research framework.
\newblock {\em arXiv preprint arXiv:2007.14390}, 2020.

\bibitem{cardoso2022monai}
M.~J. Cardoso, W.~Li, R.~Brown, N.~Ma, E.~Kerfoot, Y.~Wang, B.~Murrey,
  A.~Myronenko, C.~Zhao, D.~Yang, et~al.
\newblock Monai: An open-source framework for deep learning in healthcare.
\newblock {\em arXiv preprint arXiv:2211.02701}, 2022.

\bibitem{chang2018distributed}
K.~Chang, N.~Balachandar, C.~Lam, D.~Yi, J.~Brown, A.~Beers, B.~Rosen, D.~L.
  Rubin, and J.~Kalpathy-Cramer.
\newblock Distributed deep learning networks among institutions for medical
  imaging.
\newblock {\em Journal of the American Medical Informatics Association},
  25(8):945--954, 2018.

\bibitem{Chen:2016:XST:2939672.2939785}
T.~Chen and C.~Guestrin.
\newblock {XGBoost}: A scalable tree boosting system.
\newblock In {\em Proceedings of the 22nd ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, KDD '16, pages 785--794, New York,
  NY, USA, 2016. ACM.

\bibitem{dayan2021federated}
I.~Dayan, H.~R. Roth, A.~Zhong, A.~Harouni, A.~Gentili, A.~Z. Abidin, A.~Liu,
  A.~B. Costa, B.~J. Wood, C.-S. Tsai, et~al.
\newblock Federated learning for predicting clinical outcomes in patients with
  covid-19.
\newblock {\em Nature medicine}, 27(10):1735--1743, 2021.

\bibitem{dimitriadis2022flute}
D.~Dimitriadis, M.~H. Garcia, D.~M. Diaz, A.~Manoel, and R.~Sim.
\newblock Flute: A scalable, extensible framework for high-performance
  federated learning simulations.
\newblock {\em arXiv preprint arXiv:2203.13789}, 2022.

\bibitem{dwork2006calibrating}
C.~Dwork, F.~McSherry, K.~Nissim, and A.~Smith.
\newblock Calibrating noise to sensitivity in private data analysis.
\newblock In {\em Theory of cryptography conference}, pages 265--284. Springer,
  2006.

\bibitem{geiping2020inverting}
J.~Geiping, H.~Bauermeister, H.~Dr{\"o}ge, and M.~Moeller.
\newblock Inverting gradients-how easy is it to break privacy in federated
  learning?
\newblock {\em Advances in Neural Information Processing Systems},
  33:16937--16947, 2020.

\bibitem{guo2022auto}
P.~Guo, D.~Yang, A.~Hatamizadeh, A.~Xu, Z.~Xu, W.~Li, C.~Zhao, D.~Xu,
  S.~Harmon, E.~Turkbey, et~al.
\newblock Auto-fedrl: Federated hyperparameter optimization for
  multi-institutional medical image segmentation.
\newblock {\em arXiv preprint arXiv:2203.06338}, 2022.

\bibitem{gupta2018distributed}
O.~Gupta and R.~Raskar.
\newblock Distributed learning of deep neural network over multiple agents.
\newblock {\em Journal of Network and Computer Applications}, 116:1--8, 2018.

\bibitem{hatamizadeh2022gradient}
A.~Hatamizadeh, H.~Yin, P.~Molchanov, A.~Myronenko, W.~Li, P.~Dogra, A.~Feng,
  M.~G. Flores, J.~Kautz, D.~Xu, et~al.
\newblock Do gradient inversion attacks make federated learning unsafe?
\newblock {\em arXiv preprint arXiv:2202.06924}, 2022.

\bibitem{he2020fedml}
C.~He, S.~Li, J.~So, X.~Zeng, M.~Zhang, H.~Wang, X.~Wang, P.~Vepakomma,
  A.~Singh, H.~Qiu, et~al.
\newblock Fed{ML}: A research library and benchmark for federated machine
  learning.
\newblock {\em arXiv preprint arXiv:2007.13518}, 2020.

\bibitem{he2021towards}
J.~He, C.~Zhou, X.~Ma, T.~Berg-Kirkpatrick, and G.~Neubig.
\newblock Towards a unified view of parameter-efficient transfer learning.
\newblock {\em arXiv preprint arXiv:2110.04366}, 2021.

\bibitem{houlsby2019parameter}
N.~Houlsby, A.~Giurgiu, S.~Jastrzebski, B.~Morrone, Q.~De~Laroussilhe,
  A.~Gesmundo, M.~Attariyan, and S.~Gelly.
\newblock Parameter-efficient transfer learning for nlp.
\newblock In {\em International Conference on Machine Learning}, pages
  2790--2799. PMLR, 2019.

\bibitem{hu2021lora}
E.~J. Hu, Y.~Shen, P.~Wallis, Z.~Allen-Zhu, Y.~Li, S.~Wang, L.~Wang, and
  W.~Chen.
\newblock Lora: Low-rank adaptation of large language models.
\newblock {\em arXiv preprint arXiv:2106.09685}, 2021.

\bibitem{kairouz2019advances}
P.~Kairouz, H.~B. McMahan, B.~Avent, A.~Bellet, M.~Bennis, A.~N. Bhagoji,
  K.~Bonawitz, Z.~Charles, G.~Cormode, R.~Cummings, et~al.
\newblock Advances and open problems in federated learning.
\newblock {\em arXiv preprint arXiv:1912.04977}, 2019.

\bibitem{karimireddy2020scaffold}
S.~P. Karimireddy, S.~Kale, M.~Mohri, S.~Reddi, S.~Stich, and A.~T. Suresh.
\newblock Scaffold: Stochastic controlled averaging for federated learning.
\newblock In {\em International Conference on Machine Learning}, pages
  5132--5143. PMLR, 2020.

\bibitem{krizhevsky2009learning}
A.~Krizhevsky, G.~Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{lester2021power}
B.~Lester, R.~Al-Rfou, and N.~Constant.
\newblock The power of scale for parameter-efficient prompt tuning.
\newblock {\em arXiv preprint arXiv:2104.08691}, 2021.

\bibitem{li2021ditto}
T.~Li, S.~Hu, A.~Beirami, and V.~Smith.
\newblock Ditto: Fair and robust federated learning through personalization.
\newblock In {\em International Conference on Machine Learning}, pages
  6357--6368. PMLR, 2021.

\bibitem{li2020federated}
T.~Li, A.~K. Sahu, M.~Zaheer, M.~Sanjabi, A.~Talwalkar, and V.~Smith.
\newblock Federated optimization in heterogeneous networks.
\newblock {\em Proceedings of Machine Learning and Systems}, 2:429--450, 2020.

\bibitem{li2019privacy}
W.~Li, F.~Milletar{\`\i}, D.~Xu, N.~Rieke, J.~Hancox, W.~Zhu, M.~Baust,
  Y.~Cheng, S.~Ourselin, M.~J. Cardoso, et~al.
\newblock Privacy-preserving federated brain tumour segmentation.
\newblock In {\em International workshop on machine learning in medical
  imaging}, pages 133--141. Springer, 2019.

\bibitem{liu2021gpt}
X.~Liu, Y.~Zheng, Z.~Du, M.~Ding, Y.~Qian, Z.~Yang, and J.~Tang.
\newblock Gpt understands, too.
\newblock {\em arXiv preprint arXiv:2103.10385}, 2021.

\bibitem{liu2021fate}
Y.~Liu, T.~Fan, T.~Chen, Q.~Xu, and Q.~Yang.
\newblock Fate: An industrial grade platform for collaborative learning with
  data protection.
\newblock {\em J. Mach. Learn. Res.}, 22(226):1--6, 2021.

\bibitem{ludwig2020ibm}
H.~Ludwig, N.~Baracaldo, G.~Thomas, Y.~Zhou, A.~Anwar, S.~Rajamoni, Y.~Ong,
  J.~Radhakrishnan, A.~Verma, M.~Sinn, et~al.
\newblock Ibm federated learning: an enterprise framework white paper v0. 1.
\newblock {\em arXiv preprint arXiv:2007.10987}, 2020.

\bibitem{mcmahan2017communication}
B.~McMahan, E.~Moore, D.~Ramage, S.~Hampson, and B.~A. y~Arcas.
\newblock Communication-efficient learning of deep networks from decentralized
  data.
\newblock In {\em Artificial intelligence and statistics}, pages 1273--1282.
  PMLR, 2017.

\bibitem{monai2022github}
{MONAI Consortium}.
\newblock {MONAI: Medical Open Network for AI}, 9 2022.

\bibitem{openai2023gpt4}
OpenAI.
\newblock Gpt-4 technical report, 2023.

\bibitem{ouyang2022training}
L.~Ouyang, J.~Wu, X.~Jiang, D.~Almeida, C.~Wainwright, P.~Mishkin, C.~Zhang,
  S.~Agarwal, K.~Slama, A.~Ray, et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock {\em Advances in Neural Information Processing Systems},
  35:27730--27744, 2022.

\bibitem{reddi2020adaptive}
S.~Reddi, Z.~Charles, M.~Zaheer, Z.~Garrett, K.~Rush, J.~Kone{\v{c}}n{\`y},
  S.~Kumar, and H.~B. McMahan.
\newblock Adaptive federated optimization.
\newblock {\em arXiv preprint arXiv:2003.00295}, 2020.

\bibitem{reina2021openfl}
G.~A. Reina, A.~Gruzdev, P.~Foley, O.~Perepelkina, M.~Sharma, I.~Davidyuk,
  I.~Trushkin, M.~Radionov, A.~Mokrov, D.~Agapov, et~al.
\newblock Openfl: An open-source framework for federated learning.
\newblock {\em arXiv preprint arXiv:2105.06413}, 2021.

\bibitem{rieke2020future}
N.~Rieke, J.~Hancox, W.~Li, F.~Milletari, H.~R. Roth, S.~Albarqouni, S.~Bakas,
  M.~N. Galtier, B.~A. Landman, K.~Maier-Hein, et~al.
\newblock The future of digital health with federated learning.
\newblock {\em NPJ digital medicine}, 3(1):1--7, 2020.

\bibitem{roth2020federated}
H.~R. Roth, K.~Chang, P.~Singh, N.~Neumark, W.~Li, V.~Gupta, S.~Gupta, L.~Qu,
  A.~Ihsani, B.~C. Bizzo, et~al.
\newblock Federated learning for breast density classification: A real-world
  implementation.
\newblock In {\em Domain Adaptation and Representation Transfer, and
  Distributed and Collaborative Learning}, pages 181--191. Springer, 2020.

\bibitem{rothchild2020fetchsgd}
D.~Rothchild, A.~Panda, E.~Ullah, N.~Ivkin, I.~Stoica, V.~Braverman,
  J.~Gonzalez, and R.~Arora.
\newblock Fetchsgd: Communication-efficient federated learning with sketching.
\newblock In {\em International Conference on Machine Learning}, pages
  8253--8265. PMLR, 2020.

\bibitem{sarma2021federated}
K.~V. Sarma, S.~Harmon, T.~Sanford, H.~R. Roth, Z.~Xu, J.~Tetreault, D.~Xu,
  M.~G. Flores, A.~G. Raman, R.~Kulkarni, et~al.
\newblock Federated learning improves site performance in multicenter deep
  learning without data sharing.
\newblock {\em Journal of the American Medical Informatics Association},
  28(6):1259--1264, 2021.

\bibitem{sheller2020federated}
M.~J. Sheller, B.~Edwards, G.~A. Reina, J.~Martin, S.~Pati, A.~Kotrotsou,
  M.~Milchenko, W.~Xu, D.~Marcus, R.~R. Colen, et~al.
\newblock Federated learning in medicine: facilitating multi-institutional
  collaborations without sharing patient data.
\newblock {\em Scientific reports}, 10(1):1--12, 2020.

\bibitem{sheller2018multi}
M.~J. Sheller, G.~A. Reina, B.~Edwards, J.~Martin, and S.~Bakas.
\newblock Multi-institutional deep learning modeling without sharing patient
  data: A feasibility study on brain tumor segmentation.
\newblock In {\em International MICCAI Brainlesion Workshop}, pages 92--104.
  Springer, 2018.

\bibitem{silva2020fed}
S.~Silva, A.~Altmann, B.~Gutman, and M.~Lorenzi.
\newblock Fed-biomed: A general open-source frontend framework for federated
  learning in healthcare.
\newblock In {\em Domain Adaptation and Representation Transfer, and
  Distributed and Collaborative Learning}, pages 201--210. Springer, 2020.

\bibitem{wang2020federated}
H.~Wang, M.~Yurochkin, Y.~Sun, D.~Papailiopoulos, and Y.~Khazaeni.
\newblock Federated learning with matched averaging.
\newblock {\em arXiv preprint arXiv:2002.06440}, 2020.

\bibitem{warnat2021swarm}
S.~Warnat-Herresthal, H.~Schultze, K.~L. Shastry, S.~Manamohan, S.~Mukherjee,
  V.~Garg, R.~Sarveswara, K.~H{\"a}ndler, P.~Pickkers, N.~A. Aziz, et~al.
\newblock Swarm learning for decentralized and confidential clinical machine
  learning.
\newblock {\em Nature}, 594(7862):265--270, 2021.

\bibitem{enwiki:1131516757}
{Wikipedia contributors}.
\newblock Private set intersection --- {Wikipedia}{,} the free encyclopedia,
  2023.
\newblock [Online; accessed 27-April-2023].

\bibitem{xie2022federatedscope}
Y.~Xie, Z.~Wang, D.~Chen, D.~Gao, L.~Yao, W.~Kuang, Y.~Li, B.~Ding, and
  J.~Zhou.
\newblock Federatedscope: A comprehensive and flexible federated learning
  platform via message passing.
\newblock {\em arXiv preprint arXiv:2204.05011}, 2022.

\bibitem{xu2022closing}
A.~Xu, W.~Li, P.~Guo, D.~Yang, H.~R. Roth, A.~Hatamizadeh, C.~Zhao, D.~Xu,
  H.~Huang, and Z.~Xu.
\newblock Closing the generalization gap of cross-silo federated medical image
  segmentation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 20866--20875, 2022.

\bibitem{yang2019federated}
Q.~Yang, Y.~Liu, T.~Chen, and Y.~Tong.
\newblock Federated machine learning: Concept and applications.
\newblock {\em ACM Transactions on Intelligent Systems and Technology (TIST)},
  10(2):1--19, 2019.

\bibitem{zhao2022reduce}
H.~Zhao, W.~Du, F.~Li, P.~Li, and G.~Liu.
\newblock Reduce communication costs and preserve privacy: Prompt tuning method
  in federated learning.
\newblock {\em arXiv preprint arXiv:2208.12268}, 2022.

\bibitem{ziller2021pysyft}
A.~Ziller, A.~Trask, A.~Lopardo, B.~Szymkow, B.~Wagner, E.~Bluemke, J.-M.
  Nounahon, J.~Passerat-Palmbach, K.~Prakash, N.~Rose, et~al.
\newblock Pysyft: A library for easy federated learning.
\newblock In {\em Federated Learning Systems}, pages 111--139. Springer, 2021.

\end{thebibliography}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\appendix


%\section{Appendix}


%Optionally include extra information (complete proofs, additional experiments, and plots) in the appendix.
%This section will often be part of the supplemental material.


\end{document}
