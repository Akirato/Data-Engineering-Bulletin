\section{Conclusions}
\label{sec:conclusion}
In this survey, we have provided a comprehensive overview of explanation methods for Graph Neural Networks (GNNs). Besides outlining some background on GNNs and explainability, we have presented a detailed taxonomy of the papers from the literature. By categorizing and discussing these methods, we have highlighted their strengths, limitations, and applications in understanding GNN predictions. Moreover, we have highlighted some widely used datasets and evaluation metrics in assessing the explainability of GNNs. As GNNs continue to play a significant role in various fields, such as healthcare, recommendation systems, and natural language processing, the need for interpretable and transparent models becomes increasingly important. Overall, we believe this survey serves as a valuable resource for researchers and practitioners interested in the explainability of GNNs and provides a foundation for further advancements in interpretable graph representation learning. %and fosters the development of more reliable GNN models in the future.
%The explanation of AI methods including GNNs is a growing and exciting field and 
%we believe that many AI and machine learning methods will benefit immensely from the existing literature.


%Explanation methods offer insights into the inner workings of GNN models, allowing users to gain a deeper understanding of the factors driving predictions and facilitating decision-making processes.
 


