\section{Introduction}\label{sec:ali_intro}

Knowledge graphs (KGs) are the backbone of applications such as question answering in virtual assistants and recommendation systems in. These applications require a broad range of knowledge that is continuously updated with recent facts from disparate data sources~\cite{apple_kp, industry_kgs}. Reasoning about the importance of facts in an industry-scale KG with billions of entities and facts across diverse domains is a challenging problem. An automated and scalable solution scalable across entity types and domains in a KG has obvious benefits.

Here, we focus on the problem of \emph{fact ranking}. Fact ranking provides an importance-based ranking over facts for a given real-world entity. For example, given the question \emph{``What is the occupation of LeBron James?''}, the answer \emph{``basketball player''} should be ranked higher than \emph{``television actor''} or \emph{``screenwriter''} despite the fact that these two are also LeBron James's occupations. Fact ranking generalizes the problem of \emph{recommendation generation}~\cite{bouraga2014knowledge} over KGs. We are interested in facts that cannot be ranked using a simple importance or popularity score. For example, ranking occupation of entities as described earlier. Another example is to generate recommendation for entities that are relevant within users' search context. For example, for the user query \emph{``How tall is LeBron James''}, we want to recommend a ranked list of top KG entities that are related to the query entity ``LeBron James'' and are aligned with users' search intent, \ie, they are ``Person'' entities with a ``height'' attribute. Fact ranking is important during rendering these enriching entity-centric experiences in intelligent assistants. 



In this paper, we propose a solution to fact ranking based on modern Knowledge Graph Embedding (KGE) models and present an experimental evaluation in large-scale settings. Our solution adopts state-of-the-art \emph{multi-hop reasoning} models. Specifically, we build on the recent Query2Box model~\cite{ren2020query2box} and demonstrate how the embeddings obtained by this model can address fact ranking over large-scale KGs. A major challenge in employing KGE models for fact ranking in real-world applications is to reason about the importance score and the rank of a facts obtained by an embedding model. We address this challenge by proposing a new metric for measuring the stability of embedding models across different rounds, namely, an adaptive version of Kendall's Tau that also takes into account the importance scores obtained by the embedding models. In this way, we can better measure the effects of the learned embeddings on the downstream use cases. Our approach is in contrast to using the standard forms of Kendall's Tau or Rank-based Overlap metrics, which measure the consistency across two ranked lists by considering only the number of discordant pairs/swaps between the two lists. We demonstrate that the reasoning-based Query2Box model leads to significantly more stable embeddings compared to one-hop embedding models such as DistMult~\cite{distmult}. We also propose a new indexing scheme and apply multi-query optimization for efficient search over the generated embedding vectors for supporting use-cases such as vector similarity-based related entity search.


Finally, we compare Query2Box against modern generative natural language (NL) models~\cite{liu2019roberta} and demonstrate that NL models require significant fine-tuning of the prompt to obtain similar fact ranking results as the Query2Box model.
