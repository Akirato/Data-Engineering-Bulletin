\section{Conclusion}\label{sec:conclusion}
In this work, we studied fact ranking over large-scale knowledge graphs. We evaluated to what extent modern knowledge graph embedding (KGE) models provide a solution for addressing the problem of fact ranking. We highlighted unique challenges associated with solving this task in industrial settings and evaluated different KGE and text-based embedding models. Our work demonstrated that, in contrast to neural language models or shallow KGE models, multi-hop reasoning models such as Query2Box can better meet user satisfaction.

% compared to  more stable than shallow KGE models with the latter not satisfying the stability properties required for stable fact ranking and fact verification services. We also showed that reasoning embedding models can be used to effectively prioritize facts to be verified by human graders. Finally, we evaluated the performance of modern generative natural language models on the tasks for fact ranking and verification and found that KG embedding models are competitive without requiring careful fine-tuning of the prompt that is used during inference.