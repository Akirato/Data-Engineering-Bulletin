%!TEX root = data-validation-ml-systems.tex
\section{Conclusion}
\label{sec:conclusion}

Validation of input and output data in ML production systems has many facets that require competencies often distributed across a heterogeneous team of engineers and scientists, as illustrated in \autoref{fig:ml-system}. While some of the data validation challenges, such as schema validation or data consistency, can be tackled with traditional data profiling methods established the DBMS community, other validation dimensions are specific to ML systems. These ML model dependent validation challenges include aspects like accuracy and robustness under data shifts, fairness of ML model predictions and privacy concerns. 

In \autoref{sec:solutions} we highlight a number of solutions to validate single aspects. Many of these approaches are typically tailored to specific use cases and often require considerable integration efforts in production ML systems. 
A good example are the various solutions from both the ML community as well as the DMBS community for checking simple data properties, such as the data types, and also more complex dimensions like data consistency. Many of these approached allow for automating the generation of validation checks. Yet in practice it is not trivial to automate the generation of validations for a new ML system that ingests and produces millions of rows and columns. For instance, there are many cases when simple validation checks on input data will lead to false alarms when shifts or errors in a single feature do not impact the output of a downstream ML model -- maybe because that feature was neglected by the ML model, when strong regularization during the ML model training phase taught the model to ignore that feature. 

Despite the rapid progress in recent years to automate and monitor ML systems: to the best of our knowledge there exists no data validation system that has reached broad adoption and which takes into account all of the data validation dimensions sketched in \autoref{sec:dimensions}. One reason for this is the difficulty of combining the multitude of validation strategies listed in \autoref{sec:solutions} into one unified framework. Considering the rapid pace of research at the intersection of ML and DBMS, see for instance \cite{Dong2018}, it is fair to assume that it is merely a matter of a few years until one framework or some open standard for data validation in the context of ML systems will have reached broad adoption. 

There are many data validation challenges in ML systems that go beyond technical aspects. Many of them are due to the complex nature of the data transformations induced by ML models. For instance identifying unfair biases often requires domain knowledge or access to grouping variables, which are often not available. And even if those are available, it is not always clear how fairness in the context of ML systems can be defined  \cite{Zhang2020}. A conceptual challenge related to privacy is for instance the trade-off between utility and differential privacy of a ML system \cite{Jayaraman2019}: how much predictive accuracy should be sacrificed to ensure privacy? Sacrificing accuracy against privacy in domains like health care or jurisdiction is a difficult question for which ethical and legal dimensions are more important than technical aspects. Next to these ethical and legal aspects, there is one key factor hindering adoption of comprehensive data validation in ML systems and that more related to cultural aspects. Many scientists like to build new models and tools, but writing tests, integrating monitoring and validation stages in an ML system are not exactly the most popular tasks amongst researchers. But often the competencies of the scientists who built a model is required to build well functioning monitoring and validation solutions in ML systems. 

Based on these observations we derive some suggestions for how to drive innovation and adoption of data validation in the context of ML systems. First, we hope that the current trend for research at the intersection of ML and DBMS communities will continue to grow and identify more synergies leveraging and complementing each others expertise. We have seen some great examples of constructive but vivid discussion between the two communities, for instance that sparked by Kraska and colleagues around their work on learning index structures \cite{Kraska2018}. This work is unrelated to data validation and mentioned merely as an example of transdisciplinary research debates. 
Second, when building ML systems there is a broad spectrum of operational challenges and seamless integration with cloud infrastructure is key to reaching broad adoption. 

\newpage
We conclude that establishing data validation in ML systems will require a stronger focus on usability and simple APIs. Third we believe that data validation in ML systems will reach broad adoption once the research community will have found better ways of automating the validation workflow, most importantly the generation of checks for each of the data validation dimensions listed in \autoref{sec:dimensions}. 

In the past years we have seen great examples of automated tooling for tracking ML experiments \cite{Schelter2017}, experimentation in ML production systems \cite{Bose2017a}, input data validation \cite{Schelter2018,Breck2019} and validation strategies for predictions of ML systems \cite{Rabanser2018,Schelter2020,DAmour2020}. One example of how some of these data validation techniques could be integrated into an automated workflow would be that presented in \cite{Rukat2020}, where the authors propose to iterate through a sequence of data validation~\cite{Schelter2018}, data cleaning\cite{Biessmann2018a} and quantification of downstream impact on ML predictive performance~\cite{Schelter2020} to achieve an automated ML workflow. We believe that increasing the level of usability through automation in data validation will enable researchers to focus on more important questions like the conceptual, ethical and legal questions and ultimately lead to more responsible usage of ML systems in production systems.